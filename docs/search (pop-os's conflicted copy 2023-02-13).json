[
  {
    "objectID": "datorlab/lab5/DatorLab5.html",
    "href": "datorlab/lab5/DatorLab5.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "I den h√§r datorlabben kommer vi att arbeta med f√∂rdelningar i R, bland annat l√§ra oss g√∂ra sannolikhetsber√§kningar och simulera fr√•n olika f√∂rdelningar, dvs dra slumptal fr√•n f√∂rdelningar.\n\n\n\n\n\n\n\nInstallera paket\n\n\n\nDen h√§r labben f√∂ruts√§tter inga installerade paket.\n\n\n\n\n\n\n\n\nSkapa mapp f√∂r labben\n\n\n\nSkapa en mapp Lab5 i din kursmapp SDA1. Ladda ner Quarto-filen f√∂r denna lab genom att h√∂gerklicka h√§r och v√§lj ‚ÄòSpara l√§nk‚Äô eller n√•got likande fr√•n menyn som dyker upp. Spara filen i din Lab5 mapp. √ñppna Quarto-filen i RStudio och forts√§tt med denna laboration direkt i Quarto-dokumentet, d√§r du ocks√• fyller i svaren p√• dina laborations√∂vningar.\n\n\n\n\nR har en massa statistiska f√∂rdelningar inbyggda fr√•n start, och ytterligare m√•nga, m√•nga mer i olika R-paket. F√∂r varje f√∂rdelning finns det fyra typer av funktioner:\n\nr-funktionen som genererar slumptal fr√•n f√∂rdelningen, t ex rnorm(n = 5, mean = 2, sd = 3) genererar 5 slumptal fr√•n normalf√∂rdelningen \\(X\\sim N(2,3^2)\\). Argumentet sd betyder standard deviation, dvs standardavvikelse. Tio slumptal fr√•n Poissonf√∂rdelningen \\(\\mathrm{Pois}(\\lambda = 2)\\) f√•r man med rpois(n = 10, lambda = 2) osv. r-funktionen har f√•tt sitt namn fr√•n random.\np-funktionen som ber√§knar sannolikheten att slumpvariabeln √§r mindre √§n ett visst tal, dvs \\(P(X\\leq x)\\) f√∂r n√•got \\(x\\). p-funktionen har f√•tt sitt namn fr√•n engelskans probability.\npnorm(q = 1, mean = 2, sd = 3) ber√§knar sannolikheten att \\(X\\sim N(2,3^2)\\) √§r mindre √§n 1.\nd-funktionen som f√∂r en diskret variabel \\(X\\) ber√§knar sannolikheten \\(P(X=x)\\). F√∂r en kontinuerlig variabel ber√§knar d-funktionen t√§thetsfunktionen \\(f(x)\\) i en given punkt \\(x\\). Det √§r fr√•n det kontinuerliga fallet som d-funktionen f√•tt sitt namn, d som i density. Kommandot dnorm(x = 1, mean = 2, sd = 3) ber√§knar t√§thetsfunktionens v√§rde i punkten \\(x=0\\), dvs \\(f(0)\\) f√∂r en \\(X\\sim N(2,3^2)\\) variabel.\nq-funktionen ber√§knar \\(p\\)-kvantilen f√∂r en f√∂rdelning, dvs det v√§rde \\(x\\) d√§r \\(P(X \\leq x)=p\\). Vi kan t ex ber√§kna 25% eller 0.25-kvantilen f√∂r en normalf√∂rdelad variabel \\(X\\sim N (2,3^2)\\) med kommandot qnorm(p = 0.25, mean = 2, sd = 3).\n\n\nVisa mig koden!\nm = 2       # mean for the normal distribution\ns = 3       # standard deviation for the normal distribution\nx = -1      # point where the density is evaluated\nx_grid = seq(-10, 10, by = 0.1) # a vector of x-values for which we evaluate the density f(x)\nx_sample = rnorm(n = 1000, mean = m, sd = s)\ndens_norm = dnorm(x_grid, mean = m, sd = s)  # density (x) for all values in vector xgrid\nquantile10 = qnorm(0.1, mean = m, sd = s)    # 10% percentile\n\n# Plotting - a lot of code because I want pretty colors and legends. Sorry.\nhist(x_sample, breaks = 50, freq = F, main = \"X ~ N(2,3¬≤)\", ylim = c(0,0.15), \n     xlim = c(-10,10), xlab = \"x\", ylab = \"f(x)\", col = \"cornflowerblue\") # freq = F gives us proportions\nlines(x_grid, dens_norm, lwd = 3, col = \"orange\")\ndensity_at_x = dnorm(x, mean = m, sd = s)\npoints(x, density_at_x)\nlines(x = c(x,x), c(0,density_at_x), col = \"gray\", lty = 2, lwd = 3)\nlines(x = c(-10,x), c(density_at_x,density_at_x), col = \"gray\", lty = 2, lwd = 2)\nx_lower = x_grid[x_grid < quantile10]\npolygon(x = c(x_lower, rev(x_lower)), border = NA,\n        y = c(rep(0, length(x_lower)), rev(dnorm(x_lower, mean = m, sd = s))), \n        col = rgb(1,0.8431373,0, alpha = 0.7)\n)\nlegend(\"topleft\", inset=.01, \n       legend=c(\"histogram data\", \"density function\", \"density evaluation\", \"P(X<=-1)\"),\n       col=c(\"cornflowerblue\", \"orange\", \"gray\"), \n       lty = c(NA, 1, 3, NA), \n       lwd = c(NA, 2, 2, NA), \n       fill = c(\"cornflowerblue\", NA, NA, rgb(1,0.8431373,0, alpha = 0.7)), \n       border = c(1,0,0,1), cex=1\n)\n\n\n\n\n\n\n\n\ndnorm to compute density at -1: f(x) = 0.0806569081730478\n\n\npnorm to compute prob that X is lower than -1: P(X<=x) = 0.158655253931457\n\n\nqnorm to compute 10% quantile of X as  -1.8446546966338\n\n\n\n\n\n\n\n\nGl√∂m inte Rs hj√§lp!\n\n\n\nSkriv t ex ?rnorm i Console f√∂r att se hj√§lpfilen f√∂r normalf√∂rdelningen.\n\n\n\n\n\n\n\n\nObservera\n\n\n\nJag har skrivit ut namnen p√• alla funktionsargumenten ovan, t ex n=5, mean = 2 och sd = 3 i rnorm(n = 5, mean = 2, sd = 3). Det hade dock g√•tt lika bra att skriva rnorm(5, 2, 3), d√• f√∂rst√•r R att jag menar n=5, mean = 2 och sd = 3 . Det fungerar dock bara om man anv√§nder exakt den ordning p√• argumenten som man ser n√§r man skriver ?rnorm. Annars kan R inte veta vilka argument som ska matchas mot vilka siffror. Om man skriver ut argumentens namn s√• kan man ha vilken ordning som helst, t ex rnorm(mean = 2, sd = 3, n = 5).\n\n\n\n\n\n\n\n\nVektorisera mera\n\n\n\nKommandot dnorm(0, mean = 0, sd = 1) r√§knar ut t√§thetsfunktionens v√§rde i punkten x=0 f√∂r en standard normalf√∂rdelning. Om man vill r√§kna ut t√§theten i flera punkter? Ett s√§tt √§r att anv√§nda en for-loop som upprepar dnorm(x, mean = 0, sd = 1) f√∂r olika x-v√§rden (se Lab1). Men det finns ett enklare s√§tt! M√•nga av Rs funktioner √§r vektoriserade. Det betyder att du kan r√§kna ut funktionen f√∂r alla v√§rden i en vektor ‚Äòp√• en g√•ng‚Äô. üòç\nS√• h√§r ber√§knar man t ex t√§thetsfunktionen f√∂r tre olika x-v√§rden -1, 0, och 1:\n\ndnorm(x = c(-1,0,1), mean = 0, sd = 1)\n\n[1] 0.2419707 0.3989423 0.2419707\n\n\nOk, snyggt, men om man vill ha olika v√§ntev√§rden f√∂r var och ett av x-v√§rdena, d√•? Yep, funkar:\n\ndnorm(x = c(-1,0,1), mean = c(0, 0.5, 3), sd = 1)\n\n[1] 0.24197072 0.35206533 0.05399097\n\n\n\n\n\n\n\n\n\n\nNormalf√∂rdelning med varians eller standardavvikelse?\n\n\n\nI funktionen rnorm() anger man f√∂rdelningens spridning som en standardavvikelse med argumentet sd. Det skulle motsvara att man skrev \\(N(\\mu,\\sigma)\\) f√∂r en normalf√∂rdelning i matematisk/symbolisk notation. Men vanligtvis skriver vi normalf√∂rdelningen med variansen som andra argument i den symboliska beskrivningen: \\(N(\\mu,\\sigma^2)\\), men alla b√∂cker g√∂r inte s√•. Man f√•r helt enkelt se upp och kontrollera om en normalf√∂rdelning skrivs med en standardavvikelse eller varians. I formelsamlingen och p√• tentan kommer jag skriva \\(N(\\mu,\\sigma^2)\\).\n\n\n\n\n\nVi ska nu f√∂rs√∂ka g√∂ra ett stapeldiagram f√∂r sannolikhetsf√∂rdelningen f√∂r en binomialf√∂rdelad variabel med parametrarna \\(n=10\\) och \\(p=0.4\\), dvs f√∂r slumpvariabeln \\(X\\sim \\mathrm{Binom}(n,p)\\). Vi har ju just sett att vi kan ber√§kna sannolikheterna \\(P(X=x)\\) f√∂r en massa olika \\(x\\)-v√§rden genom vektorisering, s√• l√•t oss b√∂rja d√§r:\n\nn = 10\np = 0.4\nxvalues = seq(0,n) # en vektor med alla m√∂jliga utfall p√• X, dvs 0,1,2,...,n\nprobs = dbinom(x = xvalues, size = n, prob = p) # vektoriserat \nprobs\n\n [1] 0.0060466176 0.0403107840 0.1209323520 0.2149908480 0.2508226560\n [6] 0.2006581248 0.1114767360 0.0424673280 0.0106168320 0.0015728640\n[11] 0.0001048576\n\n\nNotera hur jag f√∂rst skapade en vektor med alla x-v√§rden (xvalues) mellan \\(0\\) och \\(n=10\\) (vilket ju √§r alla m√∂jliga x-v√§rden f√∂r en \\(\\mathrm{Bin}(10,p)\\)-f√∂rdelad variabel). Den vektorn matade jag sen in i dbinom() funktionen f√∂r att f√• sannolikheten \\(P(X=x)\\) f√∂r varje x-v√§rde. Vi ser att sannolikheten f√∂r \\(x=0\\) √§r v√§ldigt l√•g \\(P(X=0)=0.0060466176\\). Den sannolikheten √§r l√§tt att r√§kna f√∂r hand som kontroll: det enda s√§tt vi kan f√• 0 lyckade f√∂rs√∂k i 10 Bernoullif√∂rs√∂k √§r om vi misslyckas (vars sannolikhet √§r \\(q=1-p=1-0.4=0.6\\)) p√• alla 10 f√∂rs√∂k: \\(0.6^{10}=0.006046618\\). Yes, checks out.\nKoden nedan g√∂r nu ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen. Notera att vi m√•ste anv√§nda names() funktionen f√∂r s√§tta ett ‚Äúnamn‚Äù p√• varje sannolikhet (dvs det x-v√§rde som sannolikheten h√∂r ihop med) f√∂r att vi ska f√• \\(x\\)-v√§rdena utskrivna p√• \\(x\\)-axeln.\n\nnames(probs) <- xvalues\nbarplot(probs, col = \"cornflowerblue\", ylab = \"P(X=x)\", xlab = \"x\", main = \"X ~ Binom(10,0.4)\")\n\n\n\n\nHur g√∂r man om slumpvariabeln kan anta ett o√§ndligt antal v√§rden, som t ex Poissonf√∂rdelningen d√§r \\(x=0,1,2,‚Ä¶.\\) utan √∂vre gr√§ns? L√∂sningen √§r att l√•ta vektorn med x-v√§rden inneh√•lla alla x-v√§rden d√§r sannolikheten \\(P(X=x)\\) √§r tillr√§ckligt stor f√∂r att spela roll i figuren. H√§r kan prova sig fram, dvs √∂ka p√• antalet x-v√§rden tills sannolikheten f√∂r st√∂rre x-v√§rden √§r n√§ra noll. S√• h√§r kan vi t ex g√∂ra ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen f√∂r en \\(\\mathrm{Pois}(\\lambda = 2)\\) variabel:\n\nxvalues = 0:5\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"orange\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lite f√∂r f√• x-v√§rden\")\n\n\n\n\nSom du ser var jag lite f√∂r sn√•l med antal x-v√§rden, det verkar som om x-v√§rden st√∂rre √§n 5 borde ha varit med i plotten eftersom sannolikheten f√∂r x=5 √§r inte riktigt n√§ra noll. L√•t oss prova med v√§rden fr√•n 0 till 10:\n\nxvalues = 0:10\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"yellow\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lagom m√•nga x-v√§rden\")\n\n\n\n\n\n\n\nHur kan man rita upp sannolikheterna f√∂r en kontinuerlig variabel? Kontinuerliga variabler antar ju alla v√§rden, √§ven decimaltal, s√• h√§r m√•ste vi g√∂ra lite annorlunda. En kontinuerlig variabel har ju ocks√• sannolikhet noll f√∂r alla \\(x\\): \\(P(X=x)=0\\). Vi anv√§nder oss d√§rf√∂r av t√§thetsfunktionen \\(f(x)\\), d√§r arean under t√§thetsfunktionen mellan tv√• x-v√§rden \\(a\\) och \\(b\\) √§r sannolikheten \\(P(a \\leq X \\leq b)\\). Den s k d-funktionen (t ex dnorm f√∂r normalf√∂rdelning) ger t√§theten f√∂r en kontinuerlig variabel. F√∂r att plotta upp en t√§thetsfunktion:\n\nskapa en vektor med en massa x-v√§rden med ganska litet avst√•nd mellan v√§rdena\nber√§kna d-funktionen f√∂r vektorn med x-v√§rden\nplotta t√§thetsfunktionen som en kurva med kommandot plot() eller lines() (anv√§nds om det inte redan finns n√•got uppritat i grafen).\n\nH√§r plottar vi t√§thetsfunktionen f√∂r en standard normalf√∂rdelningen:\n\nxvalues = seq(-3, 3, by = 0.01) # by=0.01 talar om att vi vill ha avst√•nd 0.01 mellan v√§rdena.\ndensity_values = dnorm(xvalues, mean = 0, sd = 1)\nplot(xvalues, density_values, type = \"l\", xlab = \"x\", ylab = \"density\", main = \"N(0,1)\",\n     col = \"steelblue\", lwd = 2) # lwd √§r line width, dvs tjocklek p√• linje.\n\n\n\n\nI det h√§r fallet var det ganska l√§tt att v√§lja start- och slutpunkt f√∂r x-v√§rdena: vi vet ju fr√•n 68-95-99.7 regeln att 99.7% av sannolikhetsmassan ligger mellan -3 och 3 f√∂r standard normalf√∂rdelning. I andra fall kan det vara sv√•rare att best√§mma l√§mpliga x-v√§rden och man f√•r prova sig fram (om man har en q-funktion, dvs kvantilfunktion, f√∂r f√∂rdelningen kan man anv√§nda den f√∂r att ber√§kna l√§mpliga start- och slutv√§rden p√• x). Hur v√§ljer man avst√•ndet mellan olika x-v√§rden (dvs by = 0.01 i min kod)? Det brukar spela mindre roll. V√§ljer man f√∂r stora avst√•nd blir kurvan hackig. V√§ljer man verkligt sm√• avst√•nd blir det m√•nga olika x-v√§rden och det kan ta tid f√∂r R ber√§kna alla t√§thetsv√§rden."
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#introduktion",
    "href": "datorlab/lab5/DatorLab5.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den h√§r datorlabben kommer vi att arbeta med f√∂rdelningar i R, bland annat l√§ra oss g√∂ra sannolikhetsber√§kningar och simulera fr√•n olika f√∂rdelningar, dvs dra slumptal fr√•n f√∂rdelningar.\n\n\n\n\n\n\n\nSkapa mapp f√∂r labben\n\n\n\nSkapa en mapp Lab5 i din kursmapp SDA1. Ladda ner Quarto-filen f√∂r denna lab genom att h√∂gerklicka h√§r och v√§lj ‚ÄòSpara l√§nk‚Äô eller n√•got likande fr√•n menyn som dyker upp. Spara filen i din Lab5 mapp. √ñppna Quarto-filen i RStudio och forts√§tt med denna laboration direkt i Quarto-dokumentet, d√§r du ocks√• fyller i svaren p√• dina laborations√∂vningar.\n\n\n\nF√∂rdelningar i R: r, p, d och q-funktionerna üòç\nR har en massa statistiska f√∂rdelningar inbyggda fr√•n start, och ytterligare m√•nga, m√•nga mer i olika R-paket. F√∂r varje f√∂rdelning finns det fyra typer av funktioner:\n\nr-funktionen som genererar slumptal fr√•n f√∂rdelningen, t ex rnorm(n = 5, mean = 2, sd = 3) genererar 5 slumptal fr√•n normalf√∂rdelningen \\(X\\sim N(2,3^2)\\). Argumentet sd betyder standard deviation, dvs standardavvikelse. Tio slumptal fr√•n Poissonf√∂rdelningen \\(\\mathrm{Pois}(\\lambda = 2)\\) f√•r man med rpois(n = 10, lambda = 2) osv. r-funktionen har f√•tt sitt namn fr√•n random.\np-funktionen som ber√§knar sannolikheten att slumpvariabeln √§r mindre √§n ett visst tal, dvs \\(P(X\\leq x)\\) f√∂r n√•got \\(x\\). p-funktionen har f√•tt sitt namn fr√•n engelskans probability.\npnorm(q = 1, mean = 2, sd = 3) ber√§knar sannolikheten att \\(X\\sim N(2,3^2)\\) √§r mindre √§n 1.\nd-funktionen som f√∂r en diskret variabel \\(X\\) ber√§knar sannolikheten \\(P(X=x)\\). F√∂r en kontinuerlig variabel ber√§knar d-funktionen t√§thetsfunktionen \\(f(x)\\) i en given punkt \\(x\\). Det √§r fr√•n det kontinuerliga fallet som d-funktionen f√•tt sitt namn, d som i density. Kommandot dnorm(x = 1, mean = 2, sd = 3) ber√§knar t√§thetsfunktionens v√§rde i punkten \\(x=0\\), dvs \\(f(0)\\) f√∂r en \\(X\\sim N(2,3^2)\\) variabel.\nq-funktionen ber√§knar \\(p\\)-kvantilen f√∂r en f√∂rdelning, dvs det v√§rde \\(x\\) d√§r \\(P(X \\leq x)=p\\). Vi kan t ex ber√§kna 25% eller 0.25-kvantilen f√∂r en normalf√∂rdelad variabel \\(X\\sim N (2,3^2)\\) med kommandot qnorm(p = 0.25, mean = 2, sd = 3).\n\n\nVisa mig koden!\nm = 2   # mean for the normal distribution\ns = 3   # standard deviation for the normal distribution\nx = -1 # point where the density is evaluated\nx_grid = seq(-10, 10, by = 0.1) # a vector of x-values for which we evaluate the density f(x)\nx_sample = rnorm(n = 1000, mean = m, sd = s)\ndens_norm = dnorm(x_grid, mean = m, sd = s) # density (x) for all values in vector xgrid\nquantile10 = qnorm(0.1, mean = m, sd = s)  # 10% percentile\n\n# Plotting - a lot of code because I want pretty colors and legends. Sorry.\nhist(x_sample, breaks = 40, freq = F, main = \"X ~ N(2,3¬≤)\", ylim = c(0,0.15), \n     xlim = c(-10,10), xlab = \"x\", ylab = \"f(x)\") # freq = F gives us proportions\nlines(x_grid, dens_norm, lwd = 2, col = \"steelblue\")\ndensity_at_x = dnorm(x, mean = m, sd = s)\npoints(x, density_at_x)\nlines(x = c(x,x), c(0,density_at_x), col = \"orange\", lty = 2, lwd = 3)\nlines(x = c(-10,x), c(density_at_x,density_at_x), col = \"orange\", lty = 2, lwd = 2)\nx_lower = x_grid[x_grid < quantile10]\npolygon(x = c(x_lower, rev(x_lower)), \n        y = c(rep(0, length(x_lower)), rev(dnorm(x_lower, mean = m, sd = s))), \n        col = rgb(0.678, 0.847, 0.902, alpha = 0.5)\n)\nlegend(\"topleft\", inset=.01, \n       legend=c(\"histogram data\", \"density function\", \"density evaluation\", \"P(X<=-1)\"),\n       col=c(\"gray\", \"steelblue\", \"orange\"), \n       lty = c(NA, 1, 3, NA), \n       lwd = c(NA, 2, 2, NA), \n       fill = c(\"gray\", NA, NA, rgb(0.678, 0.847, 0.902, alpha = 0.5)), \n       border = c(1,0,0,1), cex=1\n)\n\n\n\n\n\n\n\n\ndnorm to compute density at -1: f(x) = 0.0806569081730478\n\n\npnorm to compute prob that X is lower than -1: P(X<=x) = 0.158655253931457\n\n\nqnorm to compute 10% quantile of X as  -1.8446546966338\n\n\n\n\n\n\n\n\nGl√∂m inte Rs hj√§lp!\n\n\n\nSkriv t ex ?rnorm i Console f√∂r att se hj√§lpfilen f√∂r normalf√∂rdelningen.\n\n\n\n\n\n\n\n\nObservera\n\n\n\nJag har skrivit ut namnen p√• alla funktionsargumenten ovan, t ex n=5, mean = 2 och sd = 3 i rnorm(n = 5, mean = 2, sd = 3). Det hade dock g√•tt lika bra att skriva rnorm(5, 2, 3), d√• f√∂rst√•r R att jag menar n=5, mean = 2 och sd = 3 . Det fungerar dock bara om man anv√§nder exakt den ordning p√• argumenten som man ser n√§r man skriver ?rnorm. Annars kan R inte veta vilka argument som ska matchas mot vilka siffror. Om man skriver ut argumentens namn s√• kan man ha vilken ordning som helst, t ex rnorm(mean = 2, sd = 3, n = 5).\n\n\n\n\n\n\n\n\nVektorisera mera\n\n\n\nKommandot dnorm(0, mean = 0, sd = 1) r√§knar ut t√§thetsfunktionens v√§rde i punkten x=0 f√∂r en standard normalf√∂rdelning. Om man vill r√§kna ut t√§theten i flera punkter? Ett s√§tt √§r att anv√§nda en for-loop som upprepar dnorm(x, mean = 0, sd = 1) f√∂r olika x-v√§rden (se Lab1). Men det finns ett enklare s√§tt! M√•nga av Rs funktioner √§r vektoriserade. Det betyder att du kan r√§kna ut funktionen f√∂r alla v√§rden i en vektor ‚Äòp√• en g√•ng‚Äô. üòç\nS√• h√§r ber√§knar man t ex t√§thetsfunktionen f√∂r tre olika x-v√§rden -1, 0, och 1:\n\ndnorm(x = c(-1,0,1), mean = 0, sd = 1)\n\n[1] 0.2419707 0.3989423 0.2419707\n\n\nOk, snyggt, men om man vill ha olika v√§ntev√§rden f√∂r var och ett av x-v√§rdena, d√•? Yep, funkar:\n\ndnorm(x = c(-1,0,1), mean = c(0, 0.5, 3), sd = 1)\n\n[1] 0.24197072 0.35206533 0.05399097\n\n\n\n\n\n\n\n\n\n\nNormalf√∂rdelning med varians eller standardavvikelse?\n\n\n\nI funktionen rnorm() anger man f√∂rdelningens spridning som en standardavvikelse med argumentet sd. Det skulle motsvara att man skrev \\(N(\\mu,\\sigma)\\) f√∂r en normalf√∂rdelning i matematisk/symbolisk notation. Men vanligtvis skriver vi normalf√∂rdelningen med variansen som andra argument i den symboliska beskrivningen: \\(N(\\mu,\\sigma^2)\\), men alla b√∂cker g√∂r inte s√•. Man f√•r helt enkelt se upp och kontrollera om en normalf√∂rdelning skrivs med en standardavvikelse eller varians. I formelsamlingen och p√• tentan kommer jag skriva \\(N(\\mu,\\sigma^2)\\).\n\n\n\n\nRita upp sannolikhetsf√∂rdelningen f√∂r en diskret variabel\nVi ska nu f√∂rs√∂ka g√∂ra ett stapeldiagram f√∂r sannolikhetsf√∂rdelningen f√∂r en binomialf√∂rdelad variabel med parametrarna \\(n=10\\) och \\(p=0.4\\), dvs f√∂r slumpvariabeln \\(X\\sim \\mathrm{Binom}(n,p)\\). Vi har ju just sett att vi kan ber√§kna sannolikheterna \\(P(X=x)\\) f√∂r en massa olika \\(x\\)-v√§rden genom vektorisering, s√• l√•t oss b√∂rja d√§r:\n\nn = 10\np = 0.4\nxvalues = seq(0,n) # en vektor med alla m√∂jliga utfall p√• X, dvs 0,1,2,...,n\nprobs = dbinom(x = xvalues, size = n, prob = p) # vektoriserat \nprobs\n\n [1] 0.0060466176 0.0403107840 0.1209323520 0.2149908480 0.2508226560\n [6] 0.2006581248 0.1114767360 0.0424673280 0.0106168320 0.0015728640\n[11] 0.0001048576\n\n\nNotera hur jag f√∂rst skapade en vektor med alla x-v√§rden (xvalues) mellan \\(0\\) och \\(n=10\\) (vilket ju √§r alla m√∂jliga x-v√§rden f√∂r en \\(\\mathrm{Bin}(10,p)\\)-f√∂rdelad variabel). Den vektorn matade jag sen in i dbinom() funktionen f√∂r att f√• sannolikheten \\(P(X=x)\\) f√∂r varje x-v√§rde. Vi ser att sannolikheten f√∂r \\(x=0\\) √§r v√§ldigt l√•g \\(P(X=0)=0.0060466176\\). Den sannolikheten √§r l√§tt att r√§kna f√∂r hand som kontroll: det enda s√§tt vi kan f√• 0 lyckade f√∂rs√∂k i 10 Bernoullif√∂rs√∂k √§r om vi misslyckas (vars sannolikhet √§r \\(q=1-p=1-0.4=0.6\\)) p√• alla 10 f√∂rs√∂k: \\(0.6^{10}=0.006046618\\). Yes, checks out.\nKoden nedan g√∂r nu ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen. Notera att vi m√•ste anv√§nda names() funktionen f√∂r s√§tta ett ‚Äúnamn‚Äù p√• varje sannolikhet (dvs det x-v√§rde som sannolikheten h√∂r ihop med) f√∂r att vi ska f√• \\(x\\)-v√§rdena utskrivna p√• \\(x\\)-axeln.\n\nnames(probs) <- xvalues\nbarplot(probs, col = \"cornflowerblue\", ylab = \"P(X=x)\", xlab = \"x\", main = \"X ~ Binom(10,0.4)\")\n\n\n\n\nHur g√∂r man om slumpvariabeln kan anta ett o√§ndligt antal v√§rden, som t ex Poissonf√∂rdelningen d√§r \\(x=0,1,2,‚Ä¶.\\) utan √∂vre gr√§ns? L√∂sningen √§r att l√•ta vektorn med x-v√§rden inneh√•lla alla x-v√§rden d√§r sannolikheten \\(P(X=x)\\) √§r tillr√§ckligt stor f√∂r att spela roll i figuren. H√§r kan prova sig fram, dvs √∂ka p√• antalet x-v√§rden tills sannolikheten f√∂r st√∂rre x-v√§rden √§r n√§ra noll. S√• h√§r kan vi t ex g√∂ra ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen f√∂r en \\(\\mathrm{Pois}(\\lambda = 2)\\) variabel:\n\nxvalues = 0:5\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"orange\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lite f√∂r f√• x-v√§rden\")\n\n\n\n\nSom du ser var jag lite f√∂r sn√•l med antal x-v√§rden, det verkar som om x-v√§rden st√∂rre √§n 5 borde ha varit med i plotten eftersom sannolikheten f√∂r x=5 √§r inte riktigt n√§ra noll. L√•t oss prova med v√§rden fr√•n 0 till 10:\n\nxvalues = 0:10\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"yellow\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lagom m√•nga x-v√§rden\")\n\n\n\n\n\n\nRita upp t√§thetsfunktionen f√∂r en kontinuerlig variabel\nHur kan man rita upp sannolikheterna f√∂r en kontinuerlig variabel? Kontinuerliga variabler antar ju alla v√§rden, √§ven decimaltal, s√• h√§r m√•ste vi g√∂ra lite annorlunda. En kontinuerlig variabel har ju ocks√• sannolikhet noll f√∂r alla \\(x\\): \\(P(X=x)=0\\). Vi anv√§nder oss d√§rf√∂r av t√§thetsfunktionen \\(f(x)\\), d√§r arean under t√§thetsfunktionen mellan tv√• x-v√§rden \\(a\\) och \\(b\\) √§r sannolikheten \\(P(a \\leq X \\leq b)\\). Den s k d-funktionen (t ex dnorm f√∂r normalf√∂rdelning) ger t√§theten f√∂r en kontinuerlig variabel. F√∂r att plotta upp en t√§thetsfunktion:\n\nskapa en vektor med en massa x-v√§rden med ganska litet avst√•nd mellan v√§rdena\nber√§kna d-funktionen f√∂r vektorn med x-v√§rden\nplotta t√§thetsfunktionen som en kurva med kommandot plot() eller lines() (anv√§nds om det inte redan finns n√•got uppritat i grafen).\n\nH√§r plottar vi t√§thetsfunktionen f√∂r en standard normalf√∂rdelningen:\n\nxvalues = seq(-3, 3, by = 0.01) # by=0.01 talar om att vi vill ha avst√•nd 0.01 mellan v√§rdena.\ndensity_values = dnorm(xvalues, mean = 0, sd = 1)\nplot(xvalues, density_values, type = \"l\", xlab = \"x\", ylab = \"density\", main = \"N(0,1)\",\n     col = \"steelblue\", lwd = 2) # lwd √§r line width, dvs tjocklek p√• linje.\n\n\n\n\nI det h√§r fallet var det ganska l√§tt att v√§lja start- och slutpunkt f√∂r x-v√§rdena: vi vet ju fr√•n 68-95-99.7 regeln att 99.7% av sannolikhetsmassan ligger mellan -3 och 3 f√∂r standard normalf√∂rdelning. I andra fall kan det vara sv√•rare att best√§mma l√§mpliga x-v√§rden och man f√•r prova sig fram (om man har en q-funktion, dvs kvantilfunktion, f√∂r f√∂rdelningen kan man anv√§nda den f√∂r att ber√§kna l√§mpliga start- och slutv√§rden p√• x). Hur v√§ljer man avst√•ndet mellan olika x-v√§rden (dvs by = 0.01 i min kod)? Det brukar spela mindre roll. V√§ljer man f√∂r stora avst√•nd blir kurvan hackig. V√§ljer man verkligt sm√• avst√•nd blir det m√•nga olika x-v√§rden och det kan ta tid f√∂r R ber√§kna alla t√§thetsv√§rden."
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#ber√§kna-sannolikheter-och-sannolikhetsf√∂rdelningar",
    "href": "datorlab/lab5/DatorLab5.html#ber√§kna-sannolikheter-och-sannolikhetsf√∂rdelningar",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Ber√§kna sannolikheter och sannolikhetsf√∂rdelningar",
    "text": "1. Ber√§kna sannolikheter och sannolikhetsf√∂rdelningar\n\nüí™ Uppgift 1.1\nL√•t \\(X\\sim \\mathrm{Pois}(\\lambda)\\) med \\(\\lambda = 2\\). Ber√§kna \\(P(X=2)\\) och \\(P(X\\leq 3)\\). Hint: ?ppois\n\n# Write your code here\n\n\n\nüí™ Uppgift 1.2\nI valet 2022 fick Liberalerna 4.61% av r√∂sterna. I en unders√∂kning bland totalt 1046 personser angav 30 personer att de skulle r√∂sta p√• Liberalerna om det var val idag. Kan det vara s√• att Liberalernas r√∂stningsandel √§r (ungef√§r) of√∂r√§ndrad p√• 4.61%, eller tyder den nya unders√∂kningen p√• n√•got annat? Unders√∂k detta genom att rita upp ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen \\(P(X=x)\\) f√∂r \\(X \\sim \\mathrm{Binom}\\operatorname{}(n= 1046, p = 0.0461)\\) f√∂r x-v√§rdena xvalues = 0:100. √Ñr resultatet fr√•n valunders√∂kningen ett sannolikt utfall? Om inte, vilket slutsats drar du om Liberalernas faktiska v√§ljarandel?\n\n# Write your code here\n\n\n\nüí™ Uppgift 1.3\nBer√§kna \\(P(X \\leq 30)\\) f√∂r \\(X \\sim \\mathrm{Binom}(n= 1046, p = 0.0461)\\) genom att anv√§nda binomialf√∂rdelningen. J√§mf√∂r svaret med samma sannolikhet fr√•n en normalapproximation (se F15):\n\\[\nX\\sim \\mathrm{Binom}(n,p) \\text{ approximeras med } X\\sim \\mathrm{N}\\Big(\\mu=np, \\sigma = \\sqrt{n p (1-p)}\\Big)\n\\]\nObservera att jag skrivit normalf√∂rdelningen med standardavvikelse som andra argument h√§r. Precis som R g√∂r.\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#simulera-slumpvariabler",
    "href": "datorlab/lab5/DatorLab5.html#simulera-slumpvariabler",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Simulera slumpvariabler",
    "text": "2. Simulera slumpvariabler\n\nüí™ Uppgift 2.1\nSimulera nu 1000 slumptal fr√•n Poissonf√∂rdelningen \\(\\mathrm{Pois}(\\lambda)\\) med \\(\\lambda = 2\\) och spara i variabeln (vektorn) x. Ber√§kna medelv√§rdet (mean(x)) och standardavvikelsen (sd(x)) f√∂r slumptalen. St√§mmer de v√§rdena ungef√§r med vad vi kan f√∂rv√§nta oss? [hint: Poissonf√∂rdelningens teoretiska v√§ntev√§rde]. Simulera nu 10000 slumptal fr√•n samma f√∂rdelning och ber√§kna √•terigen medelv√§rdet. Vad tror du skulle h√§nda om du fortsatte s√• h√§r och simulerade fler och fler slumptal? (bortsett fr√•n att datorns minne skulle ta slut). [Hint: stora talens lag].\n\n# Write your code here\n\n\n\nüí™ Uppgift 2.2\nAntag att du inte k√§nner till funktionen dpois och att det matematiska uttrycket f√∂r Poissonsannolikheterna som ges i SDM boken √§r f√∂r skr√§mmande f√∂r dig. Kan du anv√§nda slumptalen i Uppgift 2.1 f√∂r att uppskatta sannolikheten \\(P(X=3)\\)?\n\n# Write your code here\n\n\n\nüí™ Uppgift 2.3\nSimulera 1000 slumptal fr√•n exponentialf√∂rdelningen med parametern rate = 2 (vilket √§r det som boken kallar \\(\\lambda\\)) och spara i en vektor x. Ber√§kna medelv√§rdet av slumptalen och verifiera att det √§r hyfsat n√§ra det teoretiska v√§ntev√§rdet f√∂r denna exponentialf√∂rdelning.\n\n# Write your code here\n\n\n\nüí™ Uppgift 2.4\nRita ett histogram f√∂r slumptalen fr√•n f√∂rra uppgiften med argumentet breaks = 40 (g√∂r att du f√•r ungef√§r 40 staplar i histogrammet). Plotta ocks√• den teoretiska t√§thetsfunktionen f√∂r \\(\\mathrm{Expon}(\\lambda = 2)\\) i samma figur.\n\n\n\n\n\n\nPlottips\n\n\n\nAnv√§nd lines() n√§r du plottar t√§thetsfunktionen, annars kommer histogrammet att skrivas √∂ver. Anv√§nd argumentet freq = FALSE i hist()-funktionen s√• du f√•r andelen observationer i varje bin, och inte antalet. Annars kommer histogrammet och t√§thetsfunktionen inte att ha samma skala p√• y-axeln.\n\n\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#simulering-f√∂r-att-ber√§kna-nya-f√∂rdelningar",
    "href": "datorlab/lab5/DatorLab5.html#simulering-f√∂r-att-ber√§kna-nya-f√∂rdelningar",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Simulering f√∂r att ber√§kna nya f√∂rdelningar",
    "text": "3. Simulering f√∂r att ber√§kna nya f√∂rdelningar\nEn mycket trevlig egenskap med simulering √§r att det √§r v√§ldigt enkelt att ber√§kna f√∂rdelningen f√∂r en funktion av slumpvariabler. Vi vet ju t ex att om \\(X\\sim \\operatorname{N}(\\mu,\\sigma^2)\\) s√• √§r f√∂rdelningen f√∂r linj√§rkombinationen \\(Y=c+aX\\) ocks√• normalf√∂rdelad: \\(Y\\sim \\operatorname{N}(c+a\\mu, a^2 \\sigma ^2)\\). Men det √§r l√•ngt ifr√•n alla fall d√§r vi matematiskt kan bevisa s√•dana goa resultat. Med simulering kan vi f√• fram f√∂rdelningen f√∂r alla funktioner och √§ven f√∂rdelningen f√∂r en summa av slumpvariabler, och mer. Den kan vi √§ven g√∂ra om f√∂rdelningen f√∂r \\(X\\) √§r n√•got annat √§n normalf√∂rdelad. L√•t oss testa direkt i en √∂vning!\n\nüí™ Uppgift 3.1\nDin v√§n och du ska best√§lla hem mat. Ni har olika smak och du vill best√§lla fr√•n restaurang X, din v√§n vill best√§lla fr√•n restaurang Y. Ni vill s√•klart g√§rna √§ta maten samtidigt och lovar varandra att v√§nta med att √§ta tills b√•da f√•tt maten. L√•t \\(X \\sim \\mathrm{Expon}(\\lambda = 2)\\) vara v√§ntetiden i timmar tills restaurang X levererar mat hem till dig, och \\(Y \\sim \\mathrm{Expon}(\\lambda = 4)\\) √§r v√§ntetiden f√∂r restaurang Y. Antag att \\(X\\) och \\(Y\\) √§r oberoende slumpvariabler. Slumpvariabeln \\(Z=60(X-Y)\\) m√§ter d√• hur m√•nga minuter du m√•ste v√§nta p√• maten efter att din v√§n redan f√•tt maten, dvs hur l√§nge din artiga v√§n m√•ste v√§nta innan hen kan b√∂rja √§ta. Om \\(Z\\) √§r negativ har du allts√• f√•tt maten f√∂re din v√§n. H√§r ser man direkt att \\(Z=60(X-Y)\\) inte kan vara exponentialf√∂rdelad, \\(Z\\) kan ju vara negativ! Anv√§nd simulering f√∂r att simulera fr√•n f√∂rdelningen f√∂r \\(Z\\) och rita upp ett histogram f√∂r att representera t√§thetsfunktionen (anv√§nd argumentet freq = FALSE f√∂r att f√• andelar inom varje bin). Anv√§nd simuleringen f√∂r att uppskatta sannolikheten att du f√•r maten efter din v√§n. [Hint1: Prova att skriva Z>0 i Console. Hint2: R hanterar TRUE som 1 och FALSE som 0, s√• t ex sum(c(TRUE, FALSE, TRUE)) blir 2 i R].\n\n# Write your code here\n\n\n\nüí™ Uppgift 3.2\nUppskatta variansen f√∂r \\(Z\\) genom simulering. Verifiera att uppskattningen √§r hyfsat n√§ra den teoretiska variansen f√∂r f√∂r \\(Z\\). [Hint: F14 gav oss formler f√∂r variansen av en summa och en differens av oberoende variabler och F16 har egenskaper f√∂r exponentialf√∂rdelade variabler, t ex deras varians.]\n\n# Write your code here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Kursens inneh√•ll\n\nData finns numera √∂verallt i samh√§llet. Kursen Statistik och dataanalys I ger dig grunderna f√∂r att f√∂rst√• och anv√§nda data, b√•de som samh√§llsmedborgare och som avancerad dataanalytiker.\n\nKursen ger dig en √∂versikt av metoder f√∂r statistisk dataanalys och dess m√•nga till√§mpningar. En introduktion till dataanalys f√∂ljs av praktisk datahantering i det popul√§ra statistiska programspr√•ket R. Samband mellan variabler analyseras, och du tr√§nas i hur statistiska modeller kan anv√§ndas f√∂r att f√∂ruts√§ga nya data. Slutsatser fr√•n data √§r alltid os√§kra och en viktig del av kursen √§r d√§rf√∂r sannolikhetsber√§kningar. Sannolikhetsteorin anv√§nds sedan i de inferensmetoder som g√∂r det m√∂jligt att dra korrekta slutsatser fr√•n data och fatta optimala beslut under os√§kerhet.\nDu l√§r dig att utf√∂ra dataanalyser i praktiken, bl a genom datorlaborationer och tv√• inl√§mningsuppgifter, men kursen ger dig √§ven en kritisk blick p√• statistik som g√∂r att du kan ifr√•gas√§tta, tolka och s√∂ka ny information f√∂r att b√§ttre svara p√• olika fr√•gest√§llningar.\nKursen best√•r av tv√• delar:\n\nDataanalys och regression, 7.5 hp. I det h√§r momentet ing√•r insamling, bearbetning, visualisering och sammanfattning av data i programspr√•ket R. En stor del av momentet behandlar sambands- och regressionsanalys som utmynnar i metoder f√∂r prediktion.\nSannolikhetsmodeller och inferens, 7.5 hp. I kursens andra momentet behandlas sannolikheter, slumpvariabler och sannolikhetsf√∂rdelningar. En central del i momentet √§r inferens, dvs. statistiska metoder f√∂r att dra slutsatser om olika fenomen fr√•n data. Kursen avslutas med en introduktion till beslutsfattade under os√§kerhet.\n\n\n\nKurslitteratur\n\nDe Veaux, R., Velleman, P. och Bock, D. (2021). Stats: Data and Models, 5:e upplagan, Pearson Global Edition, ISBN 9781292362212. Boken f√∂rkortas SDM nedan. Boken finns att k√∂pa som fysisk bok p√• Akademibokhandeln Frescati eller City, eller online p√• Adlibris och Bokus. En digital version finns att k√∂pa h√§r.\nYtterligare kompletterande material som delas ut under kursens g√•ng.\n\n\n\nKursstruktur\nKursen best√•r av f√∂rel√§sningar, r√§kne√∂vningar och datorlaborationer. Se respektive del av kursen f√∂r detaljer: Dataanalys och regression, 7.5 hp. och Sannolikhetsmodeller och inferens, 7.5 hp..\n\n\n\nSchema\nKursens schema finns p√• TimeEdit. Ett tips √§r att v√§lja Prenumerera i √∂vre h√∂gra h√∂rnet p√• TimeEdit och sen klistra in l√§nken i ditt kalenderprogram p√• mobilen.\n\n\nFormel- och tabellsamlingar\n\nFormel- och tabellsamling inneh√•ller de flesta av kursens formler och tabeller och kommer att delas ut under salstentamen.\nTabellsamling √§r en webb-version av tabellerna i Formel- och tabellsamling.\n\n\n\nInteraktivt material\nP√• vissa delar av kursen anv√§nder vi interaktivt material f√∂r att underl√§tta l√§randet. De interaktiva applikationerna kommer vara l√§nkade fr√•n f√∂rel√§sningsslides och under respektive f√∂rel√§sning. En sida med alla applikationer finns h√§r.\n\n\nL√§rare\n\n\n\n\nMattias VillaniKursansvarig och F√∂rel√§sareProfessor\n\n\n\nMatias QuirozF√∂rel√§sareUniversitetslektor\n\n\n\n\n\nMona Sfaxi√ñvningar, Dator√∂vningar och JourMasterexamen i Statistik\n\n\n\nJon LachmannDator√∂vningarMasterexamen i Statistik\n\n\n\n\n\nGamla tentor med l√∂sningar\n\n2023-02-10 [Obs! visas inte f√∂r studenter!]"
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html",
    "href": "datorlab/lab4/DatorLab4.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Varning\n\n\n\nDen h√§r labben f√∂ruts√§tter att f√∂ljande paket finns installerade:\n\nmosaic\ncorrplot\n\nPaket kan installeras via kommandot install.packages('packagename'), d√§r 'packagename' √§r namnet p√• paketet, t.ex 'mosaic'."
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#introduktion",
    "href": "datorlab/lab4/DatorLab4.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den h√§r datorlabben kommer vi att beskriva samband mellan tv√• numeriska variabler via punktdiagram och korrelation. Vi kommer ocks√• att modellera samband via b√•de enkel och multiple linj√§r regression och l√§ra oss tolka resultaten samt modellvalidering. Vi kommer att l√§ra oss prediktion i linj√§r regression och hur man kan genomf√∂ra modellval genom korsvalidering. N√§r data inte uppvisar ett linj√§rt samband ska vi l√§ra oss hur man kan transformera data och anpassa en icke-linj√§r regression. Icke-linj√§r regression √§r sv√•rare att tolka, men har klart b√§ttre prediktionsf√∂rm√•ga om det finns icke-linj√§ra samband mellan variabler. F√∂r de studenterna som √§r intresserade s√• finns det ett extra avsnitt som dyker lite djupare i R.\n\n\nüí™ Uppgift 0.1\nSe till att paketen ovan √§r installerade innan du forts√§tter med resten.\n\n\nüí™ Uppgift 0.2\nSkapa en mapp Lab4 i din kursmapp SDA1 (s√•som ni gjorde i Lab 1). Ladda ner Quarto-filen f√∂r denna lab genom att h√∂gerklicka h√§r och v√§lj ‚ÄòSpara l√§nk‚Äô eller n√•got likande fr√•n menyn som dyker upp. Spara filen i din nya Lab4 mapp. √ñppna Quarto-filen i RStudio. Du kan nu forts√§tta med denna laboration direkt i Quarto-dokumentet, d√§r du ocks√• fyller i svaren p√• dina laborations√∂vningar. Du kan allts√• l√§mna den h√§r webbsidan nu och forts√§tta arbetet i RStudio.\nV√§l inne i RStudio med √∂ppnat Quarto-dokument i ‚ÄòEditor‚Äô kan ni g√• √∂ver till ‚ÄòSource mode‚Äô genom att klicka p√• ‚ÄòSource‚Äô i det v√§nstra h√∂rnet av din ‚ÄòEditor‚Äô. Source mode √§r detaljerat och bra att skriva kod i eftersom man har full kontroll p√• dokumentet, men det √§r sv√•rt att f√• en √∂versikt av dokumentet. Prova nu att g√• √∂ver till ‚ÄòVisual mode‚Äô genom att klicka p√• ‚ÄòVisual‚Äô i det v√§nstra h√∂rnet av din ‚ÄòEditor‚Äô. Vi rekommenderar att ni mestadels arbetar i Visual mode, men att g√• √∂ver till Source mode n√§r man verkligen vill f√• till n√•gon detalj som √§r sv√•r att √§ndra i Visual mode. ¬¥\n\n\nüí™ Uppgift 0.3\nKlicka p√• knappen Render i Editor-f√∂nstret f√∂r att kompilera filen till en webbsida (html). Webbsidan kommer antingen att visas i Viewer-f√∂nstret i RStudio eller i webbl√§saren p√• din dator. Om din webbsida visas i webbl√§saren rekommenderar vi att du √§ndrar inst√§llningarna i RStudio s√• webbsidan visas i Viewer-f√∂nstret. Du st√§ller in detta p√• menyn Tools/Global Options‚Ä¶ och sen v√§ljer du Viewer Pane vid Show output preview in:\n\n\n\n\n\n\n\nüí™ Uppgift 0.4\nQuarto s√§kerst√§ller att man befinner sig i korrekt arbetsmapp n√§r koden i dokumentet exekveras. Med korrekt arbetsmapp menas den mappen ni sparade .qmd filen i. Vill du komma √•t dataseten via load() kommandot m√•ste dataseten vara sparade i samma mapp.\nEtt vanligt arbetss√§tt √§r att man jobbar i RStudio i en separat .R fil, d√§r man kan testa att k√∂ra kod innan den kopieras √∂ver till Quarto dokumentet. Den .R filen kommer inte att ha samma ‚Äòworking directory‚Äô som Quarto filen. Du m√•ste d√• anv√§nda setwd() funktionen i .R filen f√∂r att st√§lla in ‚Äòworking directory‚Äô. Notera att man ocks√• v√§lja att skriva kod i Console som finns l√§ngst ner i RStudio. D√§r m√•ste du ocks√• st√§lla in r√§tt ‚Äòworking directory‚Äô. Det √§r inte rekommenderat att anv√§nda Console eftersom koden inte sparas d√§r. Du kanske kommer p√• n√•got j√§ttesmart som du gl√∂mmer att kopiera √∂ver till Quarto dokumentet och kan senare inte hitta det du skrev.\n\n\n\n\n\n\nRStudios Editor √§ndras beroende p√• vilken sorts fil du har √∂ppen\n\n\n\nNotera att ikonerna i Editor √§r annorlunda n√§r du har ett Quarto-dokument √∂ppet j√§mf√∂rt med tidigare n√§r vi hade en fil med ren R-kod (dvs en .R fil) √∂ppen.\n\n\nSkapa en ny .R som du d√∂per till Lab4_test_code.R och sparar i din Lab 4 mapp. St√§ll in ‚Äòworking directory‚Äô till den nya mappen genom att f√∂lja anvisningarna fr√•n Lab 1.\n\n\nüí™ Uppgift 0.5\nLadda ner CAPM_data.RData (h√§r), FevChildren.RData (h√§r), RealEstate.RData (h√§r), och Penguins.RData (h√§r). Filerna kommer automatiskt att sparas ner, oftast i download mappen p√• datorn ni sitter vid. Kopiera √∂ver filerna till Lab4 mappen ni skapade ovan.\nSom vi gick igenom i Lab 3 finns det olika s√§tt att l√§sa in .RData filer genom load() funktionen. Ett s√§tt √§r att skriva t.ex load(\"FevChildren.RData\"). Notera att om du g√∂r detta i Lab4_test_code.R f√∂ruts√§tter det att FevChildren.RData ligger i den arbetsmappen man angivit genom setwd() funktionen. Ett annat s√§tt att ladda in en .RData fil √§r att l√§sa in den direkt fr√•n webben med en kombination av load() funktionen och url() funktionen.\n\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true\"))\nFevChildren_from_URL <- FevChildren\n\nArgumentet till url() funktionen √§r en str√§ng som inneh√•ller l√§nken till kurshemsidans git repository d√§r FevChildren.RData finns lagrad. I raden efter har vi sparat dataframen i en variabel som heter FevChildren_from_URL s√• att du i n√§sta uppgift kan j√§mf√∂ra mot den du l√§ser in fr√•n din lokala fil som du sparade ovan i i Lab3 mappen.\n\n\nüí™ Uppgift 0.6\nAnv√§nd load() funktionen (utan url() funktionen) f√∂r att l√§sa in FevChildren.RData lokalt fr√•n din dator. J√§mf√∂r den lokalt inl√§sta filen med den du l√§ste in fr√•n webben (finns sparad i FevChildren_from_URL).\n\n# Write your code here\n\n\n\n\n\n\n\nTips\n\n\n\nF√∂r att j√§mf√∂ra dataseten h√§r r√§cker det att anv√§nda str() och head().\n\n\nDet √§r viktigt att ni vet hur man l√§ser in .RData filer lokalt. Det kan vara s√• att github √§r tillf√§lligt nere, eller att ni tempor√§rt jobbar utan tillg√•ng till internet. I resten av labben s√• l√§ses filerna in fr√•n webben, men nu vet ni hur ni kan g√∂ra om webben av n√•gon anledning skulle vara nere."
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#samband-mellan-tv√•-numeriska-variabler",
    "href": "datorlab/lab4/DatorLab4.html#samband-mellan-tv√•-numeriska-variabler",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Samband mellan tv√• numeriska variabler",
    "text": "1. Samband mellan tv√• numeriska variabler\nNumeriska variabler √§r variabler vars utfall √§r numeriska v√§rden som har betydelse. En kategorisk variabel kan visserligen vara kodad som ett numeriskt v√§rde, men v√§rdet √§r godtyckligt. Ett exempel √§r variabeln smoking i FevChildren.RData, d√§r ja √§r kodat som 1 och nej kodat som 0. Vi skulle lika g√§rna ha kodat ja som 0 och nej som 1. Eller till och med ja som -1 och nej som 1. Det √§r s√•ledes viktigt att f√∂rst√• att √§ven kategoriska variabler kan ha numeriska utfall, men de r√§knas inte som numeriska variabler f√∂r det.\nEtt vanligt sambandsm√•tt mellan tv√• numeriska variabler √§r korrelation. Korrelation m√§ter det linj√§ra sambandet mellan variablerna. Stickprovskorrelationen r√§knas enligt \\[r_{xy}=\\frac{\\sum z_xz_y}{n-1},\\]\nd√§r \\(z_x\\) och \\(z_y\\) √§r z-v√§rden f√∂r \\(x\\) och \\(y\\), respektive. Som vanligt r√§knas dessa som \\[z_x=\\frac{x-\\overline{x}}{s_x}\\,\\,\\text{och} \\,\\,z_y=\\frac{y-\\overline{y}}{s_y},\\] d√§r \\(\\overline{x}\\) och \\(\\overline{y}\\) √§r stickprovsmedelv√§rden samt \\(s_x\\) och \\(s_y\\) √§r stickprovsstandardavvikelser. Boken anv√§nder notationen \\(r\\) ist√§llet f√∂r \\(r_{xy}\\) i ekvationen ovan. Notationen \\(r_{xy}\\) betonar att man r√§knar korrelationen mellan de tv√• variablerna \\(x\\) och \\(y\\).\nI Lab 3 introducerades datasetet CAPM_data.RData, som inneh√•ller tidsserier √∂ver m√•nadsavkastningar f√∂r olika finansiella tillg√•ngar samt makroekonomiska variabler. Lab 3 inneh√•ller detaljerad information om datasetet CAPM_data.RData. Vi ska illustrera korrelationsbegreppet med hj√§lp av det h√§r datasetet, men det √§r viktigt att f√∂rst√• att korrelation √§r ett allm√§nt m√•tt f√∂r det linj√§ra sambandet mellan tv√• variabler, oavsett om variablerna √§r tidsserier eller inte! Den enda f√∂ruts√§ttningen f√∂r att ber√§kna korrelationen √§r att variablerna √§r numeriska.\nL√•t oss r√§kna korrelationen mellan tv√• tillg√•ngar, till exempel IBM och CITCRP med hj√§lp av funktionen cor() i mosaic-paketet.\n\nsuppressMessages(library(mosaic))\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/CAPM_data.RData?raw=true\"))\ncor(IBM ~ CITCRP, data = CAPM)\n\n[1] 0.4237027\n\n\nVi ser att korrelationen √§r positiv och har ett v√§rde runt 0.43.\n\nüí™ Uppgift 1.1\nBer√§kna den omv√§nda korrelationen, dvs korrelationen CITCRP och IBM. Kan du f√∂rklara varf√∂r svaret √§r samma som ovan?\n\n\n\n\n\n\nTips\n\n\n\nBetrakta formeln f√∂r \\(r_{xy}\\) ovan. Vad h√§nder om man ist√§llet r√§knar \\(r_{yx}\\), dvs kastar om ordningen p√• \\(x\\) och \\(y\\)?\n\n\n\n# Write your code here\n\nEftersom korrelation endast beskriver ett linj√§rt samband, antas det att variablerna f√∂rh√•ller sig approximativt linj√§rt till varandra f√∂r att den ska anses vara ett l√§mpligt sambandsm√•tt. Vi kan g√∂ra ett punktdiagram f√∂r att validera antagandet.\n\nplot(IBM ~ CITCRP, data = CAPM, col = \"cornflowerblue\")\n\n\n\n\nVi ser inga tydliga avvikelser fr√•n det linj√§ra antagandet och s√•ledes √§r korrelationen ett rimligt m√•tt p√• sambandet. Figuren visar ett positivt samband mellan variablerna.\nAntag att vi vill r√§kna den parvisa korrelationen mellan flera variabler. Vi skulle kunna repetera koden cor(IBM ~ CITCRP, data = CAPM), d√§r vi byter ut IBM och CITCRP mot alla parvisa kombinationer av de variablerna vi √§r intresserade utav. Mer elegant (och mindre tidskr√§vande!) s√• kan vi skapa en s√•kallad korrelationsmatris. F√∂r att illustrera korrelationsmatrisen, l√•t oss betrakta f√∂ljande variabler: MARKET, RKFREE, WEYER, BOISE, CONED, CITCRP DATGEN, DEC,DELTA och CPI. Alla dessa f√∂rutom MARKET, RKFREE och CPI √§r m√•nadsavkastningar f√∂r stora b√∂rsnoterade f√∂retag. MARKET √§r marknadens m√•nadsavkastning, RKFREE √§r avkastningen p√• en riskfri tillg√•ng (statsobligationsr√§nta) och CPI √§r konsumentprisindex. L√•t oss skapa en ny dataframe d√§r vi enbart beh√•ller variablerna av instresse.\n\nCAPM_10_variables <- CAPM[, c(\"MARKET\", \"RKFREE\", \"WEYER\", \"BOISE\", \"CONED\", \"CITCRP\", \"DATGEN\", \"DEC\", \"DELTA\", \"CPI\")]\nhead(CAPM_10_variables)\n\n  MARKET  RKFREE  WEYER  BOISE  CONED CITCRP DATGEN    DEC  DELTA   CPI\n1 -0.045 0.00487 -0.116 -0.079 -0.079 -0.115 -0.084 -0.100 -0.028 166.7\n2  0.010 0.00494 -0.135  0.013 -0.003 -0.019 -0.097 -0.063 -0.033 167.1\n3  0.050 0.00526  0.084  0.070  0.022  0.059  0.063  0.010  0.070 167.5\n4  0.063 0.00491  0.144  0.120 -0.005  0.127  0.179  0.165  0.150 168.2\n5  0.067 0.00513 -0.031  0.071 -0.014  0.005  0.052  0.038 -0.031 169.2\n6  0.007 0.00527  0.005 -0.098  0.034  0.007 -0.023 -0.021  0.023 170.1\n\n\nVi kan nu skapa och spara korrelationsmatrisen i en variabel correlation_matrix_CAPM genom cor(). Notera att input till funktionen √§r den nya dataframen vi har skapat och att ingen formula-syntax anv√§nds.\n\ncorrelation_matrix_CAPM <- cor(CAPM_10_variables)\nround(correlation_matrix_CAPM, 3)\n\n       MARKET RKFREE  WEYER  BOISE CONED CITCRP DATGEN    DEC  DELTA    CPI\nMARKET  1.000 -0.100  0.656  0.652 0.124  0.564  0.551  0.581  0.349 -0.060\nRKFREE -0.100  1.000 -0.142 -0.176 0.057  0.001 -0.102 -0.139  0.007 -0.456\nWEYER   0.656 -0.142  1.000  0.751 0.158  0.540  0.481  0.590  0.490  0.067\nBOISE   0.652 -0.176  0.751  1.000 0.209  0.590  0.534  0.552  0.454  0.059\nCONED   0.124  0.057  0.158  0.209 1.000  0.269  0.096  0.108  0.092  0.054\nCITCRP  0.564  0.001  0.540  0.590 0.269  1.000  0.533  0.489  0.397  0.090\nDATGEN  0.551 -0.102  0.481  0.534 0.096  0.533  1.000  0.576  0.330 -0.048\nDEC     0.581 -0.139  0.590  0.552 0.108  0.489  0.576  1.000  0.429  0.029\nDELTA   0.349  0.007  0.490  0.454 0.092  0.397  0.330  0.429  1.000 -0.034\nCPI    -0.060 -0.456  0.067  0.059 0.054  0.090 -0.048  0.029 -0.034  1.000\n\n\nOvan har round() funktionen anv√§nts f√∂r avrunda till tre decimaler s√• att utskriften blir tydligare. Korrelationsmatrisen anger korrelationen f√∂r alla parvisa kombinationer av variabeln. Exempelvis, om vi kollar p√• rad 4 och kolumn 7 s√• √•terfinns korrelationen mellan BOISE och DATGEN i den cellen, som har v√§rdet 0.534. Korrelationsmatrisen √§r symmetrisk: om vi kollar p√• rad 7 och kolumn 4 hittar vi ocks√• v√§rdet 0.534, eftersom korrelationen inte tar h√§nsyn till ordningen.\n\n\nüí™ Uppgift 1.2\nVarf√∂r √§r diagonalelementen i korrelationsmatrisen 1?\n\n\nüí™ Uppgift 1.3\nAnv√§nd cor() med formula-syntax f√∂r att ber√§kna korrelationen mellan DELTA och DEC. St√§m av att resultatet √§r densamma som korrelationsmatrisen visar (t√§nk p√• att vi avrundade, s√• resultaten kommer inte st√§mma exakt).\n\n# Write your code here\n\nInformationen i en korrelationsmatris kan vara sv√•r att utl√§sa pga alltf√∂r m√•nga siffror. En korrelationsplot illustrerar korrelationerna med f√§rgskalor och √§r mycket enklare att utl√§sa. Funktionen corrplot() fr√•n corrplot-paketet tar en korrelationsmatris som argument f√∂r att skapa plotten. Vi skapade korrelationsmatrisen ovan (correlation_matrix_CAPM).\n\nsuppressMessages(library(corrplot))\ncorrplot(correlation_matrix_CAPM)\n\n\n\n\n\n\nüí™ Uppgift 1.4\nSvara p√• f√∂ljande fr√•gor:\n\nHitta tv√• variabler som har en svag negativ korrelation p√• ungef√§r -0.2. Anv√§nd plot() f√∂r att plotta variablerna mot varandra.\nHitta tv√• variabler som har en svag positiv korrelation p√• ungef√§r 0.2. Anv√§nd plot() f√∂r att plotta variablerna mot varandra.\nHitta de tv√• variabler som har starkast negativ korrelation. √Ñr det rimligt att dessa variabler √§r negativt korrelerade?\n\n\n# Write your code here\n\nBara f√∂r att en korrelation mellan tv√• variabler √§r n√§ra noll betyder det inte att det inte finns n√•got samband. L√•t oss illustrera detta med ett exempel d√§r vi anv√§nder slumptal f√∂r att skapa tv√• variabler \\(x\\) och \\(y\\) som har ett icke-linj√§rt samband, men en korrelation som √§r n√§ra noll. Simulering av slumptal tas upp i andra delen av kursen. Ni beh√∂ver inte f√∂rst√• koden nu, men det √§r viktigt att ni f√∂rst√•r slutsatsen som snart att presenteras.\n\nset.seed(10) # Same random numbers generated every run\nx <- rnorm(n = 1000, sd = 1) # Simulate a normal variable with standard deviation 1\ny <- -5*x^2 + rnorm(n = 1000)\nplot(x, y, col = \"cornflowerblue\")\n\n\n\n\nDet finns ett uppenbart kvadratiskt samband mellan \\(y\\) och \\(x\\). L√•t oss ber√§kna korrelationen.\n\ncor(x, y)\n\n[1] -0.003297157\n\n\nKorrelationen √§r n√§stan noll! Slutsatsen √§r att om vi bara hade hade fokuserat p√• korrelationen, utan att plotta \\(y\\) mot \\(x\\), s√• hade vi allts√• missat detta uppenbara samband.\nI korrelationsplotten ovan √§r det m√•nga korrelationer som √§r n√§ra noll och vi m√•ste f√∂rs√§kra oss om att vi inte har missat n√•gra uppenbara icke-linj√§ra samband. Vi kan plotta alla parvisa kombinationer av de variablerna vi √§r intresserade utav med hj√§lp av plot() funktionen. Mer elegant (och mindre tidskr√§vande!) s√• kan vi anv√§nda funktionen pairs() som g√∂r punktdiagram av alla parvisa kombinationer av variablerna i en dataframe.\n\npairs(CAPM_10_variables, col = \"cornflowerblue\")\n\n\n\n\n\n\nüí™ Uppgift 1.5\nFinns det uppenbara icke-linj√§ra samband f√∂r de variablerna som hade n√§ra noll korrelation enligt korrelationsplotten?\n\n\nüí™ Uppgift 1.6\nStudera plottarna f√∂r variablerna som var korrelerade enligt korrelationsplotten. Kan ni utl√§sa tecknena p√• korrelationerna (positiva eller negativa) utifr√•n punktdiagrammen?"
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#enkel-linj√§r-regression",
    "href": "datorlab/lab4/DatorLab4.html#enkel-linj√§r-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Enkel linj√§r regression",
    "text": "2. Enkel linj√§r regression\nEn linj√§r regression √§r anv√§ndbar f√∂r att beskriva det linj√§ra sambandet mellan en responsvariabel \\(y\\) och en f√∂rklarande variabel \\(x\\). Med en anpassad linj√§r regressionsmodell kan man, likt Avsnitt 1, ber√§kna korrelationen mellan \\(y\\) och \\(x\\). Men en linj√§r regressionsmodell erbjuder mer √§n s√•. Vi kan t.ex kvantifiera hur en f√∂r√§ndring i \\(x\\) √§r associerad med en f√∂r√§ndring i \\(y\\). Och kanske viktigast (och roligast!) av allt: vi kan givet ett nytt \\(x\\) prediktera det genomsnittliga v√§rdet p√• \\(y\\).\nL√•t oss illustrera enkel linj√§r regression med hj√§lp av datasetet FevChildren.RData som illustrerades i Lab 3. Vi anpassar en enkel linj√§r regression med responsvariabel utandningsvolymen (fev) och f√∂rklarande variabel l√§ngd (height) med hj√§lp av funktionen lm() som st√•r f√∂r linear model och sparar resultatet i en variabel vi d√∂per till lm_fev_vs_height.\n\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true\"))\nlm_fev_vs_height <- lm(fev ~ height, data = FevChildren)\n\nVi ser ovan att lm() funktionen anv√§nder samma alternativa formula-syntax som plot() funktionen, dvs av typen y ~ x.\n\n\n\n\n\n\nExtra material f√∂r de nyfikna studenterna (detta avsnitt kan skippas)\n\n\n\nFunktionen lm() returnerar ett objekt som √§r en instans (en realiserad kopia) av klass lm. En klass √§r enkelt beskrivet en abstrakt kodmall d√§r det anges vilka variabler som lagras i objektet, s√• kallade attribut, och vilka funktioner som g√•r att anv√§nda p√• objektet. Vi kan se klasstypen genom att anropa class() funktionen.\n\nclass(lm_fev_vs_height)\n\n[1] \"lm\"\n\n\nInneh√•llet i objektet kan visas med anropet str(lm_fev_vs_height), som visar objektets struktur p√• ett kompakt s√§tt.\n\nüí™ Extra Uppgift 1\nAnv√§nd str() enligt ovan f√∂r att f√• en √∂versikt av inneh√•llet i objektet lm_fev_vs_height. K√§nner du igen n√•gra av namnen (som f√∂ljer efter $-tecknet) fr√•n f√∂rel√§sningarna?\n\n# Write your code here\n\nVi har st√∂tt p√• $-tecknet i samband med att vi h√§mtade ut en variabel fr√•n en dataframe i Lab 3: Om my_data √§r en dataframe som inneh√•ller en variabel x kommer vi √•t den via my_data$x. Vi √•terkommer snart till $-tecknet, men l√•t oss f√∂rst dyka lite djupare i R.\nVi n√§mnde inte det i Lab 3, men my_data √§r ocks√• ett objekt! Den √§r en instans av klassen dataframe. I sj√§lva verket √§r allt i R objekt! R √§r vad man kallar ett objektorienterat programmeringsspr√•k. Allt vi skapar i R, vare sig det √§r en variabel, funktion eller till och med en tabell, √§r objekt, dvs instanser av olika klasser.\n\nx <- -3\nclass(x)\n\n[1] \"numeric\"\n\nf <- function(x) {x^2} # Simple function that squares a number.\nclass(f)\n\n[1] \"function\"\n\nt <- tally(age.group ~ smoking, data = FevChildren)\nclass(t)\n\n[1] \"table\"\n\n\n\n\nüí™ Extra Uppgift 2\nAnv√§nd funktionen ‚Äòf()‚Äô ovan f√∂r att r√§kna ut \\(3^2\\) och spara resultatet i en variabel y. Vilken klass √§r objektet y en instans av? Fundera p√• svaret innan ni tar reda p√• det med hj√§lp av funktionen class().\n\n# Write your code here\n\nDet g√•r att dyka djupare i Rs objektorienterade v√§rld, men vi l√•ter bli och h√§nvisar ist√§llet till institutionens Introduktionskurs i R-programmering.\n√Öter till anv√§ndandet av $-tecknet. Vi anv√§nder $-tecknet f√∂r att h√§mta ett objekts attribut (en variabel som lagras i objektet). Funktionen attributes() listar namnen p√• de olika attributen.\n\nattributes(lm_fev_vs_height)\n\n$names\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n$class\n[1] \"lm\"\n\n\nExempelvis s√• lagras minsta kvadratskattningarna i attributet coefficients.\n\nlm_fev_vs_height$coefficients\n\n(Intercept)      height \n-5.74145229  0.05380877 \n\n\n\n\nüí™ Extra Uppgift 3\nG√∂r ett histogram f√∂r residualerna f√∂r den anpassade modellen ovan.\n\n# Write your code here.\n\n\n\n\nFunktionen lm() returnerar ett s√•kallat objekt (som vi sparat i variabeln lm_fev_vs_height) av klass lm som f√∂rklaras i extra materialet ovan. Vi beh√∂ver inte veta detaljerna, men en viktig sak att veta √§r att det finns m√•nga anv√§ndbara funktioner vi kan applicera p√• v√•rt objekt. En s√•dan funktion √§r summary() som skriver ut resultaten fr√•n regressionen i ett snyggt format.\n\nsummary(lm_fev_vs_height)\n\n\nCall:\nlm(formula = fev ~ height, data = FevChildren)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76006 -0.25417  0.00064  0.23903  2.10393 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -5.741452   0.210370  -27.29   <2e-16 ***\nheight       0.053809   0.001337   40.25   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4327 on 604 degrees of freedom\nMultiple R-squared:  0.7284,    Adjusted R-squared:  0.7279 \nF-statistic:  1620 on 1 and 604 DF,  p-value: < 2.2e-16\n\n\nEfter Del 2 av kursen kommer ni k√§nna igen i princip allt i utskriften ovan. Det vi har g√•tt p√• Del 1 √§r:\n\nResiduals: Visar f√∂rdelningsm√•tten f√∂r residualerna, samt minsta och st√∂rsta v√§rde.\nCoefficients: Estimate kolumnen visar minsta kvadratskattningarna. Intercept och height betecknar vi med, respektive, \\(b_0\\) och \\(b_1\\) p√• f√∂rel√§sningarna.\nResidual standard error: Residualernas standardavvikelse som vi betecknar med \\(s_e\\) p√• f√∂rel√§sningarna.\nMultiple R-squared: R-kvadrat som vi betecknar med \\(R^2\\) p√• f√∂rel√§sningarna.\nAdjusted R-squared: Justerat R-kvadrat som vi betecknar med \\(R_{\\mathrm{adj}}^2\\) p√• f√∂rel√§sningarna.\n\nL√•t oss tolka resultaten ovan. 72.84% av variationen i forcerad utadningsvolym f√∂rklaras av variabeln l√§ngd. Minsta kvadratanpassningen √§r \\[\\widehat{fev} = b_0 + b_1height =-5.741 + 0.054height.\\] Tolkningen f√∂r \\(b_0=-5.741\\) √§r den predikterade genomsnittliga forcerade utandningsvolymen f√∂r barn och ungdomar som √§r 0 cm l√•nga, vilket inte √§r meningsfullt. Vi kan inte g√∂ra en kausal tolkning f√∂r \\(b_1\\) eftersom det inte √§r s√• att l√§ngden medf√∂r b√§ttre eller s√§mre lugnkapacitet. Ist√§llet s√§ger vi att barn och ungdomar som √§r 1 cm l√§ngre tenderar att i genomsnitt ha \\(b_1=0.054\\) fler enheter forcerad utandningsvolym (√§n de som √§r 1 cm kortare). Vi kan ocks√• anv√§nda oss av \\(b_1\\) f√∂r att till exempel s√§ga att barn och ungdomar som √§r 10 cm l√§ngre tenderar att ha \\(10\\cdot b_1 = 0.54\\) fler enheter forcerad utandningsvolym (√§n de som √§r 10 cm kortare).\nV√•rt dataset inneh√•ller forcerad utandningsvolym och l√§ngd hos 606 individuella barn och ungdomar. V√•r anpassade modell ger oss 606 prediktioner av de genomsnittliga forcerade utandningsvolymerna, dvs en prediktion \\(\\hat{y}_i\\) (fev) f√∂r varje \\(x_i\\) (height) i datasetet. Dessa kan f√•s genom funktionen predict(). L√•t oss plotta data tillsammans med de predikterade v√§rden i samma figur med hj√§lp av funktionen lines() som anv√§ndes i Lab 3. Vi anv√§nder ocks√• funktionen abline() som ritar den r√§ta linjen (minsta kvadratanpassningen).\n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\", ylim = c(0, 7))\ny_hat <- predict(lm_fev_vs_height)\nhead(y_hat)\n\n       1        2        3        4        5        6 \n2.048981 3.484061 1.707295 1.502284 2.048981 2.595678 \n\nlines(FevChildren$height, y_hat, type = \"p\", col = \"lightcoral\")\nabline(lm_fev_vs_height, col = \"lightcoral\")\nlegend(x = \"topleft\", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c(\"cornflowerblue\", \"lightcoral\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\", \"Fitted line\"))\n\n\n\n\nDet enda argumentet ni inte har st√∂tt p√• tidigare √§r pch = c(1, 1, NA) som anger att de tv√• f√∂rsta ska vara cirkelsymboler i legendtexten och anger ingen cirkelsymbol f√∂r den sista. Argumentet lty = c(NA, NA, 1) anger en linje f√∂r den sista men ingen linje f√∂r de tv√• f√∂rsta.\nAntag att vi vill prediktera genomsnittliga forcerade utandningsvolymen f√∂r l√§ngder som inte finns med bland de 606 observationerna, exempelvis \\(x=150\\) och \\(x=160\\). Vi kan anv√§nda predict() funktionens argument newdata som √§r en dataframe med samma variabelnamn som vi anv√§nde n√§r vi anpassade modellen (height) i v√•rt fall. F√∂ljande kod skapar dataframen i en variabel vi v√§ljer att kalla new_x och predikterar de genomsnittliga forcerade utandningsvolymerna f√∂r de nya \\(x\\) v√§rden ovan.\n\nnew_x <- data.frame(height = c(160, 170))\npredict(lm_fev_vs_height, newdata = new_x)\n\n       1        2 \n2.867951 3.406038 \n\n\nExempelvis ser vi att ett barn (eller en ungdom) p√• 170 cm har i genomsnitt ett fev-v√§rde p√• ca 3.4.\n\nüí™ Uppgift 2.1\nPrediktera responsen f√∂r \\(x=180\\) och \\(x=190\\). Tolka resultaten.\n\n# Write your code here\n\nF√∂r att kolla modellens rimlighet kan vi g√∂ra en residualanalys. F√∂ljande tre kriterier √§r viktiga:\n\nResidualerna ska bete sig slumpm√§ssigt, dvs de ska inte uppvisa ett m√∂nster.\nResidualernas varians ska vara konstant, dvs inte bero p√• \\(x\\).\nResidualerna ska vara approximativt normalf√∂rdelade.\n\nDe tv√• senare kriterierna blir viktiga n√§r vi g√∂r inferens i regressionsmodellen (Del 2) av kursen. N√§r f√∂rsta kriterier inte √§r uppfyllt betyder det ofta att sambandet i data √§r icke-linj√§rt.\nResidualerna kan f√•s genom funktionen residuals():\n\nresid <- residuals(lm_fev_vs_height)\nhead(resid)\n\n          1           2           3           4           5           6 \n-0.34098108 -1.76006091  0.01270459  0.05571600 -0.15398108 -0.25967816 \n\n\nF√∂ljande kod g√∂r residualanalysen.\n\nplot(FevChildren$height, resid, xlab= \"height\", ylab='Residuals', col = \"cornflowerblue\") \n\n\n\nqqnorm(resid, col = \"cornflowerblue\") # Create normal probability plot for residuals\nqqline(resid, col = \"red\") # Add a straight line to normal probability plot \n\n\n\n\nF√∂rsta plotten visar att residualerna inte ter sig slumpm√§ssigt ‚Äî de visar ett, om √§n svagt, kvadratiskt samband. Plotten visar ocks√• en tydlig indikation p√• att residualernas varians inte √§r konstant, eftersom de varierar mer ju st√∂rre height blir.\nDessa resultat √§r inte √∂verraskande om vi noga betraktar punktdiagrammet fev mot height igen samt den anpasssade linjen.\n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\")\nabline(lm_fev_vs_height, col = \"lightcoral\")\n\n\n\n\nResidualerna ber√§knas som avst√•ndet mellan observationerna och dess predikterade v√§rden (som ligger p√• linjen). St√∂rre avvikelser f√∂rekommer f√∂r st√∂rre v√§rden p√• height j√§mf√∂rt med mindre v√§rden, d√§rav en h√∂gre residualvarians. Data verkar inte heller f√∂lja den r√§ta linjen eftersom en liten grad av icke-linjaritet verkar finnas. I Avsnitt 3 g√•r vi i igenom hur vi kan anpassa en icke-linj√§r regression f√∂r att f√• b√§ttre resultat.\n\n\nüí™ Uppgift 2.2\nExemplet ovan visar hur man anpassar en enkel linj√§r regression, tolkar resultaten, predikterar responsen f√∂r nya \\(x\\) v√§rden och slutligen hur man validerar modellen. G√∂r en regressionsanalys med responsvariabel IBM och f√∂rklarande variabel MARKET i CAPM_data.RData som inkluderar dessa steg. F√∂r prediktion, antag att vi vill f√∂rutsp√• vad som h√§nder med IBM aktien om det sker en b√∂rskrasch och marknadsportf√∂ljen faller med 15% under en m√•nad. Vad kan man f√∂ruts√§ga om IBM aktiens m√•nadsavkastning i ett s√•dant scenario?\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#enkel-icke-linj√§r-regression",
    "href": "datorlab/lab4/DatorLab4.html#enkel-icke-linj√§r-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel icke-linj√§r regression",
    "text": "3. Enkel icke-linj√§r regression\nI Avsnitt 2 s√•g vi att regressionslinjen \\[\\widehat{fev} = b_0 + b_1height\\] inte var tillr√§cklig. Vi kan anv√§nda icke-linj√§r regression f√∂r att f√• en b√§ttre anpassning till data. Icke-linj√§r regression transformerar data s√• att sambandet blir linj√§rt efter att transformering. Tranformationerna syfte √§r allts√• att ‚Äúr√§ta ut‚Äù data och vi kan visuellt inspektera om s√• √§r fallet. Ett annat syfte med transformationer √§r att de ibland g√∂r antagandet om konstant residualvarians mer troligt, vilket ocks√• kan studeras visuellt.\nVi anv√§nder oss av den s√• kallade ladder of powers (stege av potenstransformationer) f√∂r att ‚Äúr√§ta ut‚Äù data med hj√§lp av potenstransformationer. Stegen av potenstransformationer visas nedan.\n\nPotenstransformationer f√∂r \\(y\\) och \\(x\\).\n\n\nStegniv√•\n\\(y\\)\n\\(x\\)\n\n\n\n\n1\n\\(y^2\\)\n\\(x^2\\)\n\n\n2\n\\(y\\)\n\\(x\\)\n\n\n3\n\\(y^{1/2}\\)\n\\(x^{1/2}\\)\n\n\n4\n\\(\\log(y)\\)\n\\(\\log(x)\\)\n\n\n5\n\\(-y^{-1/2}\\)\n\\(-x^{-1/2}\\)\n\n\n6\n\\(-y^{-1}\\)\n\\(-x^{-1}\\)\n\n\n\nTukeys cirkel √§r en tumregel f√∂r hur vi flyttar oss upp och ner i stegen.\n\n\n\nTukeys cirkel.\n\n\nVi b√∂rjar med att b√•de \\(y\\) och \\(x\\) befinner sig p√• stegniv√• 2 och flyttar sig sedan upp√•t eller ned√•t beroende p√• var i Tukeys cirkel vi befinner oss. Plotten fev mot height indikerar att vi befinner oss i fj√§rde kvadranten i Tukeys cirkel. Vi ska allts√• g√• ner i stegen f√∂r \\(y\\) och/eller upp i stegen f√∂r \\(x\\) tills f√∂rh√•llandet ser mer linj√§rt ut. Och/eller h√§r betyder att man ‚Äúflyttar b√•da‚Äù/‚Äúflyttar enbart en‚Äù. Notera ocks√• att en av variablerna kan stanna i stegen medan man flyttar den andra upp√•t eller ned√•t fler √§n ett steg.\n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\")  # Starting point: Both y and x  untransformed (Step 2 in the ladder of powers) \n\n\n\nplot(sqrt(fev) ~ height, data = FevChildren, col = \"cornflowerblue\") # y down in the ladder of powers\n\n\n\nplot(fev ~ I(height^2), data = FevChildren, col = \"cornflowerblue\") # x up in the ladder of powers\n\n\n\nplot(sqrt(fev) ~ I(height^2), data = FevChildren, col = \"cornflowerblue\") # y down and x up in the ladder of powers\n\n\n\nplot(log(fev) ~ I(height), data = FevChildren, col = \"cornflowerblue\") # y down two steps\n\n\n\n\nVi kommenterar den mystiska funktionen I() som dyker upp i h√∂gerledet p√• formula-syntaxen y ~ I(x^2) i rutan nedan. Man kan hoppa √∂ver rutan, det enda viktiga √§r att veta att funktionen I() beh√∂ver anv√§ndas i h√∂gerledet av formula-syntax om man vill transformera x f√∂r att inga misstolkningar ska ske.\n\n\n\n\n\n\nExtra f√∂rklaring f√∂r de nyfikna studenterna (detta avsnitt kan skippas)\n\n\n\nFormula-syntaxen till√•ter att man applicerar en transformation i v√§nsterledet utan att anv√§nda I(), dvs vi kan skriva till exempel sqrt(y) ~ x ist√§llet f√∂r I(sqrt(y)) ~ x. Detsamma g√§ller inte h√∂gerledet eftersom i formula-syntax s√• har vissa operationer en annan betydelse n√§r de utf√∂rs p√• den f√∂rklarande variabeln. Till exempel anpassar lm(y ~ x*z) en linj√§r regression med s√• kallade interakationseffekter1 mellan de f√∂rklarande variablerna \\(x\\) och \\(z\\), vilket har formen \\[\\hat{y} = b_0 + b_1x + b_2 z  + b_3xz.\\] N√§r man anv√§nder funktionen I() i h√∂gerledet undg√•r man att formula-syntax tolkar fel.\n\n\nVi skulle kunna utv√§rdera vilken av transformationerna √§r att f√∂redra med korsvalidering (se Avsnitt 5). H√§r n√∂jer vi oss med en utv√§rdering baserad p√• grafernas utseende. Vi ser att alla transformationerna resulterar i ett mer linj√§rt f√∂rh√•llande j√§mf√∂rt med ursprungsdatan (innan transformationerna). Visuellt konstaterar vi att de tv√• sista transformationerna verkar r√§tar ut data b√§st. Vi v√§ljer den sista transformationen eftersom den verkar uppn√• en j√§mnare spridning runt linjen, vilket kommer resultera i residualer med en mer konstant varians.\nDen anpassade linjen har formen \\[\\widehat{\\log(fev)} = b_0 + b_1height,\\] d√§r vi snart ska anv√§nda lm() f√∂r att ber√§kna koefficienterna \\(b_0\\) och \\(b_1\\). Men f√∂rst en viktig varning.\n\n\n\n\n\n\nVarning\n\n\n\nI linj√§r regression tolkade vi \\(b_1\\) som f√∂r√§ndringen i responsvariablen \\(y\\) som √§r associerad med en en-enhets f√∂r√§ndring i den f√∂rklarande variabeln \\(x\\).\nN√§r man transformerar \\(x\\) s√• finns det inga enkla tolkningar av \\(b_1\\), oavsett om \\(y\\) √§r transformerad eller inte!\nN√§r man enbart transformerar \\(y\\) men inte \\(x\\) √§r tolkningen i den transformerade skalan. I v√•rt exempel √§r \\(b_1\\) den f√∂r√§ndringen i \\(\\log(y)\\) som √§r associerad med en en-enhets f√∂r√§ndring i den f√∂rklarande variabeln \\(x\\). Man kan ibland, beroende p√• transformationen av \\(y\\), anv√§nda \\(b_1\\) f√∂r att f√• en enkel tolkning √§ven i den originala skalan. Vi g√•r inte igenom s√•dana tolkningar av \\(b_1\\) f√∂r icke-linj√§r regression i den h√§r kursen2.\n\n\n√Ñr det ens v√§rt att anpassa en modell d√§r koefficienterna inte g√•r att tolka p√• ett enkelt s√§tt? Om m√•let med modellen √§r att prediktera b√§ttre (j√§mf√∂rt med en linj√§r regression) s√• √§r svaret definitivt ja3.\nPrecis som i Avsnitt 2 kan vi anv√§nda minsta kvadratmetoden (genom lm()) f√∂r att anpassa modellen p√• de transformerade data. N√§r vi anv√§nder prediktion m√•ste vi t√§nka p√• att vi har transformerat variablerna. I det h√§r specifika exemplet med tranformationen log(fev) kommer funktionen predict() att prediktera den genomsnittliga \\(\\log(fev)\\) niv√•n. Vi vill prediktera i originalskala, dvs responsvariabeln \\(y\\) (fev) och inte \\(\\log(y)\\) (log(fev)). Men vi kan anv√§nda prediktionen f√∂r \\(\\log(y)\\) och ‚Äúreversera transformationen‚Äù, dvs f√• transformationen ogjord, f√∂r att ber√§kna prediktionen f√∂r \\(y\\). En funktion som reverserar en transformation kallas f√∂r en inverstransformation. Tabellen nedan anger inversetransformationerna (kolumnen till h√∂ger) vi kan anv√§nda oss av n√§r vi predikterar i originalskala. Transformationerna motsvarar de i ladder of powers.\n\nPrediktion i originalskala (kolumn till h√∂ger) f√∂r olika transformerade responser (kolumn till v√§nster).\n\n\nTransformation av responsen\nPrediktion i \\(y\\)-skala (\\(\\widehat{y}\\))\n\n\n\n\n\\(y^2\\)\n\\(\\left(\\widehat{y^2}\\right)^{1/2}\\)\n\n\n\\(y\\)\n\\(\\widehat{y}\\)\n\n\n\\(y^{1/2}\\)\n\\(\\left(\\widehat{y^{1/2}}\\right)^2\\)\n\n\n\\(\\log(y)\\)\n\\(\\exp\\left(\\widehat{\\log(y)}\\right)\\)\n\n\n\\(-y^{-1/2}\\)\n\\(\\left(\\widehat{-y^{-1/2}}\\right)^2\\)\n\n\n\\(-y^{-1}\\)\n\\(-\\left(\\widehat{-y^{-1}}\\right)^{-1}\\)\n\n\n\n\n\n\n\n\n\nExtra f√∂rklaring f√∂r de nyfikna studenterna (detta avsnitt kan skippas)\n\n\n\nL√•t transformationen av \\(y\\) betecknas \\(\\tilde{y}\\). Vi kan h√§rleda den inversa transformationen genom att l√∂sa f√∂r \\(y\\) i ekvationen \\(\\tilde{y}=g(y)\\) d√§r \\(g()\\) √§r transformationen.\nL√•t oss h√§rleda den inversa transformationen av log-transformationen. Eftersom \\(\\tilde{y}=\\log(y)\\) s√• √§r \\[\\exp\\left( \\tilde{y} \\right) = \\exp(\\log(y)) \\implies y = \\exp\\left( \\tilde{y} \\right),\\] dvs exponential-funktionen √§r den inversa transformen.\nNotera att n√§r vi predikterar \\(y\\) (responsen i originalskala) s√• sker det i tv√• steg. I det f√∂rsta steget anv√§nder vi regressionen f√∂r att prediktera \\(\\tilde{y}\\) (responsen i transformed skala, log-skala i exemplet ovan), vilket ger prediktionen \\(\\widehat{\\tilde{y}}\\) (\\(\\widehat{\\log(y)}\\) i exemplet ovan). I andra steget applicerar vi den inversa transformen (\\(\\exp()\\) f√∂r log-transformationen) p√• \\(\\widehat{\\tilde{y}}\\) f√∂r att f√• \\(\\widehat{y}\\) (\\(\\exp\\left(\\widehat{\\log(y)}\\right)\\) i exemplet ovan) som √§r prediktionen av \\(y\\) (originalskala).\n\nüí™ Extra Uppgift 4\nH√§rled alla de √∂vriga (eller s√• m√•nga du orkar) inversa transformationerna i tabellen ovan.\n\n\n\nVi √§r nu redo att anpassa den nya regressionen \\[\\widehat{\\log(fev)} = b_0 + b_1height,\\] samt prediktera och genomf√∂ra en residualanalys.\n\nlm_logfev_vs_height <- lm(log(fev) ~ height, data = FevChildren)\nsummary(lm_logfev_vs_height)\n\n\nCall:\nlm(formula = log(fev) ~ height, data = FevChildren)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.69706 -0.09037  0.01058  0.08988  0.43795 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.2227934  0.0717623  -30.97   <2e-16 ***\nheight       0.0202071  0.0004561   44.31   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1476 on 604 degrees of freedom\nMultiple R-squared:  0.7647,    Adjusted R-squared:  0.7643 \nF-statistic:  1963 on 1 and 604 DF,  p-value: < 2.2e-16\n\n\nMinsta kvadratskattningarna √§r nu \\(b_0=-2.222\\) och \\(b_1=0.020\\). \\(R^2=0.76145\\) betyder att ca 76% av variationen i log(fev) (observera log i tolkningen!) f√∂rklaras av height.\n\nlogy_hat <- predict(lm_logfev_vs_height) # log scale prediction\ny_hat <- exp(logy_hat) # original scale prediction\nhead(logy_hat)\n\n        1         2         3         4         5         6 \n0.7027882 1.2417111 0.5744732 0.4974842 0.7027882 0.9080922 \n\nhead(y_hat)\n\n       1        2        3        4        5        6 \n2.019375 3.461531 1.776195 1.644579 2.019375 2.479587 \n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\", ylim = c(0, 7)) # Data on original scale\nlines(FevChildren$height, y_hat, type = \"p\", col = \"lightcoral\")\nlegend(x = \"topleft\", pch = c(1, 1), col = c(\"cornflowerblue\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\"))\n\n\n\n\nNotera att till skillnad fr√•n n√§r vi anpassade fev ~ height s√• anv√§nder vi h√§r inte abline() (som ritar en r√§t linje), eftersom regressionen √§r icke-linj√§r. Vi n√∂jer oss med att markera ut de enskilda prediktionsv√§rden, men se rutan nedanf√∂r p√• hur man kan g√∂ra om man vill rita en kurva.\n\n\n\n\n\n\nExtra: Rita den anpassade kurvan i icke-linj√§r regression\n\n\n\nNotera att eftersom observationerna inte ligger i ordning f√∂r \\(x\\) variabeln s√• kan vi inte binda ihop de r√∂da punkterna ovan med en linje. Det ser konstigt ut som f√∂ljande figur visar:\n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\", ylim = c(0, 7), main = \"Strange looking plot\") # Data on original scale\nlines(FevChildren$height, y_hat, type = \"p\", col = \"lightcoral\") # Prediction of data points\nlines(FevChildren$height, y_hat, type = \"l\", col = \"lightcoral\") # line\nlegend(x = \"topleft\", pch = c(1, 1), col = c(\"cornflowerblue\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\"))\n\n\n\n\nMan skulle kunna sortera datasetet i stigande ordning p√• height och sedan binda ihop varje punkt med en linje. Men om punkterna ligger med en bit avst√•nd i \\(x\\)-led s√• √§r inte det h√§r en bra l√∂sning, eftersom det dras en r√§t linje mellan punkterna och kurvan vi plottar √§r inte r√§t. En b√§ttre l√∂sning √§r att skapa ett rutn√§t (grid p√• engelska) med m√•nga punkter i \\(x\\)-led och sedan prediktera f√∂r varje punkt i rutn√§tet. Ett rutn√§t √§r en indelning av ett intervall \\([a,b]\\) i \\(N\\) punkter med lika stort avst√•nd mellan varandra. Anropet seq(a, b, length.out = N) skapar ett rutn√§t.\n\ngrid <- seq(0.1, 1, length.out = 10) # a = 0.1, b = 1 and N = 10.\ngrid\n\n [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nVi kan nu skapa en dataframe som inneh√•ller ett rutn√§t mellan det minsta \\(x\\)-v√§rdet och det st√∂rsta \\(x\\)-v√§rdet med s√§g \\(N=1000\\) punkter och prediktera responsen f√∂r dessa 1000 \\(x\\)-v√§rden. Funktionen ‚Äòlines()‚Äô kommer att binda ihop dessa punkter med r√§ta linjer emellan ‚Äî men punkterna ligger s√• t√§tt att v√•ra √∂gon kommer uppfatta resultatet som en fin och j√§mn kurva. F√∂ljande kod anpassar kurvan p√• s√§ttet som beskrivits ovan och plottar den tillsammans med data och de enskilda prediktionerna vi skapade ovan.\n\nplot(fev ~ height, data = FevChildren, col = \"cornflowerblue\", ylim = c(0, 7)) # Data on original scale\nx_min <- min(FevChildren$height) # Min height\nx_max <- max(FevChildren$height) # Max height\nN <- 1000 # Number of grid points to predict\nnew_x <- data.frame(height = seq(x_min, x_max, length.out = N)) # The grid in a dataframe\nlogy_hat_grid <- predict(lm_logfev_vs_height, newdata = new_x)\nyhat_grid <- exp(logy_hat_grid) # Inverse transform\nlines(FevChildren$height, y_hat, type = \"p\", col = \"lightcoral\") # Prediction of data points\nlines(new_x$height, yhat_grid, type = \"l\", col = \"lightcoral\") # Prediction on grid\nlegend(x = \"topleft\", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c(\"cornflowerblue\", \"lightcoral\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\", \"Fitted curve\"))\n\n\n\n\n\n\n\nüí™ Uppgift 3.1\nPrediktera responsen f√∂r \\(x=180\\) och \\(x=190\\) med den icke-linj√§ra regressionen. J√§mf√∂r resultaten med den linj√§ra regressionen i Uppgift 2.1.\n\n# Write your code here\n\nSlutligen g√∂r vi en residualanalys.\n\nresid_logfev <- residuals(lm_logfev_vs_height)\nhead(resid_logfev)\n\n          1           2           3           4           5           6 \n-0.16746509 -0.69706393 -0.03214892 -0.05408127 -0.06356935 -0.05965209 \n\nplot(FevChildren$height, resid_logfev, xlab= \"height\", ylab='Residuals', col = \"cornflowerblue\") \n\n\n\nqqnorm(resid_logfev, col = \"cornflowerblue\") # Create normal probability plot for residuals\nqqline(resid_logfev, col = \"red\") # Add a straight line to normal plot \n\n\n\n\n\n\nüí™ Uppgift 3.2\nKommentera residualanalysen f√∂r den nya modellen. J√§mf√∂r resultaten mot residualanalysen f√∂r den otransformerade responsen (dvs fev ~ height). Vilken modell √§r att f√∂redra?\n\n\nüí™ Uppgift 3.3\nAnpassa modellen \\[\\widehat{fev^{1/2}} = b_0 + b_1height.\\] och utf√∂r en liknande analys som f√∂r modellen ovan, dvs \\[\\widehat{\\log(fev)} = b_0 + b_1height.\\] Vilken utav dessa √§r mest l√§mplig f√∂r det h√§r exemplet?\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#multipel-linj√§r-samt-icke-linj√§r-regression",
    "href": "datorlab/lab4/DatorLab4.html#multipel-linj√§r-samt-icke-linj√§r-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "4. Multipel linj√§r samt icke-linj√§r regression",
    "text": "4. Multipel linj√§r samt icke-linj√§r regression\nEn multipel linj√§r regression till√•ter fler f√∂rklarande variabler. Att implementera multipel linj√§r regression i R kr√§ver inte mycket mer kunskap √§n det vi har g√•tt igenom ovan.\nVi analyserar √•terigen FevChildren.RData och inkluderar nu ocks√• smoking (som √§r en dummy-variabel) f√∂r att f√∂rklara fev, dvs \\[\\widehat{fev}=b_0 + b_1height + b_2smoking\\]\n\nlm_fev_vs_height_smoking <- lm(fev ~ height + smoking, data = FevChildren)\nsummary(lm_fev_vs_height_smoking)\n\n\nCall:\nlm(formula = fev ~ height + smoking, data = FevChildren)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.76487 -0.25513  0.00027  0.23445  2.09853 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -5.763158   0.216872 -26.574   <2e-16 ***\nheight       0.053963   0.001388  38.865   <2e-16 ***\nsmoking1    -0.025260   0.060666  -0.416    0.677    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.433 on 603 degrees of freedom\nMultiple R-squared:  0.7285,    Adjusted R-squared:  0.7276 \nF-statistic: 808.9 on 2 and 603 DF,  p-value: < 2.2e-16\n\n\nFr√•n utskriften kan vi utl√§sa att \\(b_0 = -5.763\\), \\(b_1 = 0.054\\) och \\(b_2=-0.025\\). Vidare kan vi utl√§sa att ca 73 av variationen i fev f√∂rklaras av height och smoking Notera att R har kallat variabeln smoking1 ist√§llet f√∂r smoking f√∂r att betona att \\(b_2\\) √§r effekten av gruppen som r√∂ker (vi kodade r√∂kning som 1). I en multipel regression s√• tolkar vi alltid de skattade effektena av en variabel givet att alla andra variablerna h√•lls konstanta. Till exempel, givet barn och ungdomar av samma l√§ngd s√• √§r \\(b_2\\) f√∂r√§ndringen (h√§r negativt d√• \\(b_2 < 0\\)) i fev mellan r√∂kare och inte r√∂kare. Dvs, givet att l√§ngden √§r densamma, s√• tenderar r√∂kare att ha mindre forcerad utandningsvolym j√§mf√∂rt med icke-r√∂kare. Koefficienten \\(b_1\\) tolkas givet att smoking h√•lls konstant, dvs barn och ungdomar som √§r 1 cm l√§ngre tenderar att i genomsnitt ha \\(b_1=0.054\\) fler enheter forcerad utandningsvolym (√§n de som √§r 1 cm kortare) givet att de tillh√∂r samma grupp (antingen r√∂kare eller icke-r√∂kare).\nI multipel regression √§r det vanligt att plotta residualerna mot de predikterade v√§rdena, snarare √§n mot varje f√∂rklarande variabel. Detta beror p√• att man potentiellt kan ha m√•nga f√∂rklarande variabler och d√• √§r det mer praktiskt att ist√§llet g√∂ra residualanalysen utifr√•n en enda figur.\n\nresid_fev_multiplereg <- residuals(lm_fev_vs_height_smoking)\nhead(resid_fev_multiplereg)\n\n          1           2           3           4           5           6 \n-0.34166549 -1.76486977  0.01300219  0.05660280 -0.15466549 -0.26193379 \n\nplot(lm_fev_vs_height_smoking$fitted.values, resid_fev_multiplereg, xlab= \"y_hat\", ylab='Residuals', col = \"cornflowerblue\") \n\n\n\nqqnorm(resid_fev_multiplereg, col = \"cornflowerblue\") # Create normal probability plot for residuals\nqqline(resid_fev_multiplereg, col = \"red\") # Add a straight line to normal \n\n\n\n\nVi ser liknande problem med residualplottarna som i Avsnitt 2.\nAntag att vi vill prediktera den genomsnittliga forcerade utandningsvolymen f√∂r barn och ungdomar som √§r 164.5 cm l√•nga och r√∂ker. Eftersom smoking √§r en s√•kallad factor variabel (Rs s√§tt att koda kategoriska variabler) beh√∂ver vi anv√§nda as.factor() funktionen n√§r vi skapar new_x.\n\nnew_x <- data.frame(height = 164.5, smoking = as.factor(1))\npredict(lm_fev_vs_height_smoking, newdata = new_x)\n\n       1 \n3.088564 \n\n\nV√•r prediktion √§r att den genomsnittliga forcerade utandningsvolymen √§r 3.088 f√∂r r√∂kande barn och ungdomar som √§r \\(164.5\\) cm l√•nga.\n\nüí™ Uppgift 4.1\nAnpassa modellen \\[\\widehat{\\log(fev)}=b_0 + b_1height + b_2smoking.\\] Tolka koefficienterna och utf√∂r en residualanalys samt g√∂r en prediktion enligt ovan. Ser resultaten b√§ttre ut?\n\n# Write your code here\n\n\n\nüí™ Uppgift 4.2\nFilen real_estate.RData inneh√•ller f√∂rs√§ljningspriser SalesPrice samt f√∂rklarande variabler f√∂r 521 s√•lda objekt. En m√§klarfirma anlitar er som statistiker med f√∂ljande uppdrag.\nM√§klarfirman vill att ni utvecklar en prognosmodell f√∂r f√∂rs√§ljningspriset. F√∂r enkelhets skull ska ni anpassa en multipel linj√§r regression (dvs inga transformationer!) med f√∂ljande f√∂rklarande variabler:\n\nSqFeet: Area i kvadratfot (enhet 1000 sqft).\nLot: Tomtarea i kvadratfot (enhet 1000 sqft).\nAir: Dummy-variabel som anger om objektet har luftkonditionering (1 kodat som ja, 0 kodat som nej).\n\nM√§klarfirman undrar f√∂ljande utifr√•n den multipla linj√§ra regressionen:\n\nVad kan man s√§ga om sambandet mellan SqFeet och f√∂rs√§ljningspriset?\nVad kan man s√§ga om sambandet mellan Lot och f√∂rs√§ljningspriset?\nVerkar det finnas n√•got samband f√∂rs√§ljningspriset och Air? Hur ska sambandet tolkas?\nEn visning √§ger rum snart f√∂r en l√§genhet som har en area p√• 2.311 kvadratfot, en tomtarea p√• 17.312 kvadratfot och luftkonditionering. Vad kan den s√§ljas f√∂r? Kommunicera er prediktion med en tydlig tolkning.\n\nHar er modell n√•gra brister?\n\n\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/RealEstate.RData?raw=true\"))\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#modellval-genom-korsvalidering",
    "href": "datorlab/lab4/DatorLab4.html#modellval-genom-korsvalidering",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "5. Modellval genom Korsvalidering",
    "text": "5. Modellval genom Korsvalidering\nI det h√§r avsnittet ska vi g√• igenom hur man v√§ljer en modell med hj√§lp av korsvalidering.\nDatasetet Penguins.RData inneh√•ller dykpuls (DHR) (dive_heart_rate) och tid f√∂r dykning (duration) f√∂r 125 pingviner. Vi vill modellera dykpulsen f√∂r en pingvin som en funktion av tiden f√∂r dykningen. Ett punktdiagram visar att en linj√§r regression inte kommer att anpassa data v√§l.\n\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/Penguins.RData?raw=true\"))\nplot(dive_heart_rate ~ duration, data = penguins, col = \"cornflowerblue\")\n\n\n\n\nVi befinner oss i tredje kvadranten p√• Tukeys cirkel och f√∂resl√•r f√∂ljande tv√• modeller\n\nModell 1: \\(\\widehat{DHR^{1/2}} = b_0 + b_1duration\\).\nModell 2: \\(\\widehat{DHR^{1/2}} = b_0 + b_1duration^{1/2}\\).\n\nVi anpassar Modell 1 och plottar de predikterade v√§rdena tillsammans med data i originalskala som vi gjorde i Avsnitt 3. Skillnaden √§r att n√§r vi predikterar p√• originalskala s√• anv√§nder vi en annan inverstransformation, \\(\\left(\\widehat{y^{1/2}}\\right)^2\\) enligt tabellen ovan.\n\nlm_sqrtDHR_vs_duration <- lm(sqrt(dive_heart_rate) ~ duration, data = penguins)\nsqrty_hat <- predict(lm_sqrtDHR_vs_duration) # sqrt scale prediction\ny_hat <- sqrty_hat^2 # original scale prediction\nplot(dive_heart_rate ~ duration, data = penguins, col = \"cornflowerblue\", ylim = c(0, 140), main = \"Model 1\") # Data on original scale\nlines(penguins$duration, y_hat, type = \"p\", col = \"lightcoral\")\nlegend(x = \"topright\", pch = c(1, 1), col = c(\"cornflowerblue\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\"))\n\n\n\n\n\n\n\n\n\n\nExtra: Rita den anpassade kurvan\n\n\n\nI Avsnitt 3 l√§rde vi oss (extra-rutan) hur man ritar in den anpassade kurvan. Vi kan g√∂ra samma sak f√∂r Modell 1.\n\nplot(dive_heart_rate ~ duration, data = penguins, col = \"cornflowerblue\", ylim = c(0, 140), main = \"Model 1\") # Data on original scale\nx_min <- min(penguins$duration) # Min duration \nx_max <- max(penguins$duration) # Max duration\nN <- 1000 # Number of grid points to predict\nnew_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe\nsqrty_hat_grid <- predict(lm_sqrtDHR_vs_duration, newdata = new_x)\nyhat_grid <- sqrty_hat_grid^2 # Inverse transform\nlines(penguins$duration, y_hat, type = \"p\", col = \"lightcoral\") # Prediction of data points\nlines(new_x$duration, yhat_grid, type = \"l\", col = \"lightcoral\") # Prediction on grid\nlegend(x = \"topright\", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c(\"cornflowerblue\", \"lightcoral\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\", \"Fitted curve\"))\n\n\n\n\n\n\nVi anpassar Modell 2 med f√∂ljande kod. Notera att Modell 2 ocks√• transformerar den f√∂rklarande variabeln. R h√•ller reda p√• det √•t oss om vi anger I(sqrt(duration)) i formula-syntaxen och vi beh√∂ver inte g√∂ra n√•got extra.\n\nlm_sqrtDHR_vs_sqrtduration <- lm(sqrt(dive_heart_rate) ~ I(sqrt(duration)), data = penguins)\nsqrty_hat <- predict(lm_sqrtDHR_vs_sqrtduration) # sqrt scale prediction\ny_hat <- sqrty_hat^2 # original scale prediction\nplot(dive_heart_rate ~ duration, data = penguins, col = \"cornflowerblue\", ylim = c(0, 140), main =\"Model 2\") # Data on original scale\nlines(penguins$duration, y_hat, type = \"p\", col = \"lightcoral\")\nlegend(x = \"topright\", pch = c(1, 1), col = c(\"cornflowerblue\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\"))\n\n\n\n\n\n\n\n\n\n\nExtra: Rita den anpassade kurvan\n\n\n\nKod som ocks√• ritar den anpassade kurvan f√∂r Modell 2.\n\nplot(dive_heart_rate ~ duration, data = penguins, col = \"cornflowerblue\", ylim = c(0, 140), main = \"Model 2\") # Data on original scale\nx_min <- min(penguins$duration) # Min duration \nx_max <- max(penguins$duration) # Max duration\nN <- 1000 # Number of grid points to predict\nnew_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe\nsqrty_hat_grid <- predict(lm_sqrtDHR_vs_sqrtduration, newdata = new_x)\nyhat_grid <- sqrty_hat_grid^2 # Inverse transform\nlines(penguins$duration, y_hat, type = \"p\", col = \"lightcoral\") # Prediction of data points\nlines(new_x$duration, yhat_grid, type = \"l\", col = \"lightcoral\") # Prediction on grid\nlegend(x = \"topright\", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c(\"cornflowerblue\", \"lightcoral\", \"lightcoral\"), legend=c(\"Data\", \"Predicted\", \"Fitted curve\"))\n\n\n\n\n\n\nVi ska nu v√§lja vilken av Modell 1 eller Modell 2 √§r att f√∂redra med hj√§lp av korsvalidering. P√• f√∂rel√§sningen gick vi genom korsvalidering med \\(K = 4\\) folds. H√§r har vi 125 pingviner som √§r j√§mnt delbart med 5, s√• vi anv√§nder \\(K = 5\\) folds ist√§llet. Vi f√•r d√• 80% tr√§ningsdata och 20% testdata f√∂r varje fold enligt figuren nedan.\n\n\n\nKorsvalidering med \\(K=5\\) folds.\n\n\nF√∂r varje modell beh√∂ver vi anropa funktionen lm() \\(K=5\\) g√•nger med olika tr√§ningsdata enligt uppdelningen ovan. Funktionen lm() har ett argument subset som best√§mmer vilka observationer (pingviner) som ska anv√§ndes f√∂r att anpassa modellen, dvs tr√§ningsdata. N√§r lm() har anpassats till fold \\(k\\) anv√§nder vi funktionen predict() f√∂r att prediktera testdatan f√∂r fold \\(k\\) och r√§kna ut dess residualkvadratsumma (SSE, sum of squared errors). Koden nedan demonstrerar proceduren f√∂r f√∂rsta folden, dvs \\(k=1\\), och f√∂rklaras lite mer detaljerad efter kodsnutten.\n\nn <- 125 # Number of observations\n# Fold 1:\nobs_index <- c(1:n) # Keeps track of the indices of  the dataset (1, 2, 3, ...., n = 125)\ntest_fold_index <- obs_index[c(1:25)] # Subsets indices 1:25 (test data fold 1) \ntraining_fold_index <- obs_index[-c(1:25)] # Takes out the complement\nlm_modell1_fold1 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 1\ntest_data <- penguins[test_fold_index, ] # Create test data for fold\nsqrty_hat_fold1 <- predict(lm_modell1_fold1, newdata = test_data) # Predict test data in sqrt scale\ny_hat_fold1 <- (sqrty_hat_fold1)^2 # Predict test data ordinary scale\nSSE_fold1 <- sum((test_data$dive_heart_rate - y_hat_fold1)^2) \n\nNotera att datasetet penguins.RData redan ligger i slumpm√§ssig ordning och d√§rf√∂r kan obs_index inneh√•lla observationerna i stigande ordning. Ett exempel p√• ett dataset som ligger i ordning (dvs inte slumpm√§ssigt ordning) √§r FevChildren.RData d√§r barnen i den l√§gsta √•ldersgruppen kommer f√∂rst, d√§refter mittersta √•ldersgruppen f√∂ljt av √§ldsta √•ldersgruppen (ni kan se det genom att klicka p√• datasetet i Environment-fliken). F√∂r ett dataset som ligger i ordning kan man ist√§llet definiera obs_index <- sample(c(1:n)). D√• inneh√•ller obs_index indexen \\(1, 2, \\dots, n\\) i slumpm√§ssig ordning.\n\nüí™ Uppgift 5.1\nSkriv ut test_fold_index och bekr√§fta att den inneh√•ller indexen f√∂r testdata i fold 1, dvs de f√∂rsta 25 observationerna.\n\n# Write your code here\n\nN√§r vi skapar training_fold_index ovan, notera att -c(1:25) skapar en vektor med v√§rden \\(-1, -2, \\dots, -25\\). N√§r vi skriver obs_index[-c(1:25)] f√∂rs√∂ker vi allts√• plocka ut negativa index ur vektorn obs_index! Negativ indexering i R har en speciell betydelse: Ett negativt index h√§mtar ut alla andra observationer f√∂rutom den som har ett negerat index (negativt index). F√∂r att illustrera detta betrakta f√∂ljande exempel:\n\nmy_vector <- c(3, 2, 1, 20, 3)\nmy_vector[-4]\n\n[1] 3 2 1 3\n\nmy_vector[-2]\n\n[1]  3  1 20  3\n\nmy_vector[c(-1, -3)]\n\n[1]  2 20  3\n\n\nmy_vector[-4] h√§mtar ut alla observationer f√∂rutom den som √§r p√• index 4. my_vector[-2] h√§mtar ut alla observationer f√∂rutom den som √§r p√• index 2. my_vector[c(-1, -3)] h√§mtar ut alla observationer f√∂rutom de som √§r p√• index 1 och 3.\n\n\nüí™ Uppgift 5.2\nVilka observationer h√§mtas ut om man skriver:\n\nmy_vector[-1]?\nmy_vector[-c(3, 1)]?\nmy_vector[-c(1, 2, 4, 5)]?\n\nFundera p√• svaret innan ni bekr√§ftar med hj√§lp av kod.\n\n# Write your code here\n\nF√∂r att tydligt illustrera vad som h√§nder, l√•t oss g√∂ra en figur som inneh√•ller:\n\nTr√§ningsdata.\nTestdata.\nModellens anpassning (baserat p√• tr√§ningsdata) som inkluderar prediktion av testdata.\n\n\nplot(dive_heart_rate ~ duration, subset = training_fold_index,  data = penguins, col = \"cornflower blue\", ylim = c(0, 140), main = \"Crossvalidation Model 1: Fold 1 results\") # Training data\nlines(penguins$duration[test_fold_index], penguins$dive_heart_rate[test_fold_index], type = \"p\", col = \"lightgreen\") # Test data\nx_min <- min(penguins$duration) # Min duration \nx_max <- max(penguins$duration) # Max duration\nN <- 1000 # Number of grid points to predict\nnew_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe\nsqrty_hat_grid_fold1 <- predict(lm_modell1_fold1, newdata = new_x)\nyhat_grid_fold1 <- sqrty_hat_grid_fold1^2 # Inverse transform\nlines(new_x$duration, yhat_grid_fold1, type = \"l\", col = \"lightcoral\") # Prediction on grid\nlegend(x = \"topright\", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c(\"cornflowerblue\", \"lightgreen\", \"lightcoral\"), legend=c(\"Training data\", \"Test data\", \"Fitted curve\"))\n\n\n\n\nVariabeln yhat_grid_fold1 inneh√•ller prediktionerna f√∂r testdata. En s√•dan prediktion ges av kurvans \\(y\\)-v√§rde f√∂r en gr√∂n punkts (testdata) \\(x\\)-v√§rde.\n\n\nüí™ Uppgift 5.3\nIdentifiera testobservationen som har st√∂rst prediktionsfel i plotten ovan.\nOvan har vi grafiskt illustrerat hur korsvalideringsproceduren fungerar inom en given fold i pedagogiskt syfte. Normalt utf√∂r man korsvalidering utan en grafisk illustration. F√∂ljande kod utf√∂r korsvalideringen f√∂r fold 2, 3, 4. Den sista folden (fold 5) l√§mnas som en uppgift (se nedan).\n\n# Fold 2:\ntest_fold_index <- obs_index[c(26:50)] # Subsets indices 26:50 (test data fold 2) \ntraining_fold_index <- obs_index[-c(26:50)] # Takes out the complement\nlm_modell1_fold2 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 2\ntest_data <- penguins[test_fold_index, ] # Create test data for fold\nsqrty_hat_fold2 <- predict(lm_modell1_fold2, newdata = test_data) # Predict test data in sqrt scale\ny_hat_fold2 <- (sqrty_hat_fold2)^2 # Predict test data ordinary scale\nSSE_fold2 <- sum((test_data$dive_heart_rate - y_hat_fold2)^2)\n\n# Fold 3:\ntest_fold_index <- obs_index[c(51:75)] # Subsets indices 51:75 (test data fold 3) \ntraining_fold_index <- obs_index[-c(51:75)] # Takes out the complement\nlm_modell1_fold3 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 3\ntest_data <- penguins[test_fold_index, ] # Create test data for fold\nsqrty_hat_fold3 <- predict(lm_modell1_fold3, newdata = test_data) # Predict test data in sqrt scale\ny_hat_fold3 <- (sqrty_hat_fold3)^2 # Predict test data ordinary scale\nSSE_fold3 <- sum((test_data$dive_heart_rate - y_hat_fold3)^2)\n\n# Fold 4:\ntest_fold_index <- obs_index[c(76:100)] # Subsets indices 76:100 (test data fold 4) \ntraining_fold_index <- obs_index[-c(76:100)] # Takes out the complement\nlm_modell1_fold4 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 4\ntest_data <- penguins[test_fold_index, ] # Create test data for fold\nsqrty_hat_fold4 <- predict(lm_modell1_fold4, newdata = test_data) # Predict test data in sqrt scale\ny_hat_fold4 <- (sqrty_hat_fold4)^2 # Predict test data ordinary scale\nSSE_fold4 <- sum((test_data$dive_heart_rate - y_hat_fold4)^2)\n\n\n\nüí™ Uppgift 5.4\nUtf√∂r de ber√§kningar som kr√§vs att r√§kna ut SSE f√∂r fold 5.\n\n# Write your code here.\n\nDen korsvaliderade root mean squared error (RMSE) ges av \\[\\mathrm{RMSE}_{\\mathrm{cv}} = \\sqrt{\\frac{1}{n} \\sum_{k=1}^K \\mathrm{SSE}_k},\\] d√§r \\(K=5\\), \\(n=125\\) (totala antalet observationer) och \\(\\mathrm{SSE}_k\\) √§r SSE f√∂r fold \\(k\\).\n\n\nüí™ Uppgift 5.5\nBer√§kna \\(\\mathrm{RMSE}_{\\mathrm{cv}}\\) f√∂r Modell 1.\n\n# Write your code here.\n\n\n\nüí™ Uppgift 5.6\nUtf√∂r korsvalidering f√∂r Modell 2 och ber√§kna dess \\(\\mathrm{RMSE}_{\\mathrm{cv}}\\). Vilken modell √§r b√§st?\n\n# Write your code here."
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#sammanfattning",
    "href": "datorlab/lab4/DatorLab4.html#sammanfattning",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "6. Sammanfattning",
    "text": "6. Sammanfattning\n\n\n\n\n\n\nI den h√§r laborationen har du l√§rt dig:\n\n\n\n\nKorrelation f√∂r att beskriva ett linj√§rt samband mellan tv√• numeriska variabler.\nHur man tolkar en enkel och multipel linj√§r regression.\nHur man anv√§nder R f√∂r att anpassa linj√§ra och icke-linj√§ra regressionsmodeller.\nHur man anv√§nder R f√∂r att prediktera linj√§ra och icke-linj√§ra regressionsmodeller.\nHur man validerar en modell via en residualanalys.\nHur man v√§ljer modeller med hj√§lp av korsvalidering."
  },
  {
    "objectID": "datorlab/lab4/DatorLab4.html#a.-appendix",
    "href": "datorlab/lab4/DatorLab4.html#a.-appendix",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "A. Appendix",
    "text": "A. Appendix\nLista √∂ver n√•gra vanliga argument i grafer\n\ncol = f√§rg, kan markeras med siffror eller med namnet p√• f√§rgen, oftast med sm√• bokst√§ver. Gl√∂m ej att texten m√•ste ligga inom citattecken.\nmain = rubrik p√• plotten, detta s√§tts till en textstr√§ng, allts√• en text inom citattecken.\nxlab = rubrik p√• x-axeln, detta s√§tts till en textstr√§ng, allts√• en text inom citattecken.\nylab = rubrik p√• y-axeln, detta s√§tts till en textstr√§ng, allts√• en text inom citattecken.\nxlim = definitionsomr√•de f√∂r x-axeln. Exempelvis betyder xlim = c(0, 14.3) att det l√§gsta v√§rdet som ritas kommer att vara 0 och det h√∂gsta v√§rdet kommer att vara 14.3 (p√• x-axeln).\nylim = definitionsomr√•de f√∂r y-axeln. Exempelvis betyder ylim = c(-2, 20.7) att det l√§gsta v√§rdet som ritas kommer att vara -2 och det h√∂gsta v√§rdet kommer att vara 20.7 (p√• y-axeln).\nlwd = tjocklecken p√• linjer (eller prickar) i ett linjediagram (spridningsdiagram), anges med ett nummer.\nlty = typ av linje (rak, streckad, prickad etc) i ett linjediagram, anges med ett nummer.\npch = typ av prick (rund, fyrkantig + * etc), s√§tts till ett nummer.\nbreaks = antal staplar i ett histogram.\ncex = justering av etiketternas storlek i en figur (exempelvis cex = 0.5 i en legend() funktion minskar storleken som ‚Äúlegend-texten‚Äù tar upp i en figur med h√§lften). Finns √§ven exempelvis cex.axis, cex.main f√∂r att justera storleken av texter p√• axlar respektive rubrik.\nbg = bakgrundsf√§rg i en figur.\ncol.main = rubrikens f√§rg.\ncol.lab = f√§rger f√∂r rubrikerna p√• axlarna.\nfont = specificerar vilken typ av text man vill ha, exempelvis ger font = 3 kursiv text."
  },
  {
    "objectID": "Del1.html",
    "href": "Del1.html",
    "title": "Del I - Dataanalys och Regression, 7.5 hp",
    "section": "",
    "text": "I momentet ing√•r insamling, bearbetning, visualisering och sammanfattning av data i programspr√•ket R. En stor del av momentet behandlar sambands- och regressionsanalys som utmynnar i metoder f√∂r prediktion.\n\nF√∂rkortningen SDM st√•r f√∂r kursboken Stats: Data and Models 5:e upplagan, global edition.\nUnder vissa f√∂rel√§sningar l√§nkar vi till Extramaterial. Det √§r material som inte kr√§vs f√∂r att klara kursen, men som den nyfikne kan l√§sa f√∂r att f√• en djupare f√∂rst√•else.\n\nF√∂rel√§sningar\nF√∂rel√§sning 1 - Introduktion.\nL√§s: SDM Kapitel 1 | Slides\nF√∂rel√§sning 2 - Kort introduktion till R. \nL√§s: Slides\nKod: Kod\nData: SmartPhones | CAPM\nF√∂rel√§sning 3 - Hantera och beskriva data.\nL√§s: SDM Kapitel 2 | Slides\nInteraktivt: widget - histogram\nF√∂rel√§sning 4 - Samband mellan kategoriska variabler.\nL√§s: SDM Kapitel 3 | Slides\nF√∂rel√§sning 5 - J√§mf√∂ra f√∂rdelningar. Tidsserier. Transformationer.\nL√§s: SDM Kapitel 4 | Slides\nF√∂rel√§sning 6 - Standardisering och normalmodellen.\nL√§s: SDM Kapitel 5 | Slides\nF√∂rel√§sning 7 - Samband mellan numeriska variabler.\nL√§s: SDM Kapitel 6 | Slides\nF√∂rel√§sning 8 - Enkel linj√§r och icke-linj√§r regression.\nL√§s: SDM Kapitel 7 | Slides\nwidget - linj√§r regression utan population | widget - linj√§r regression med population\nF√∂rel√§sning 9 - Multipel linj√§r regression och modellval.\nL√§s: SDM Kapitel 8-9 | Slides\nExtramaterial: widget - icke-linj√§r regression\nF√∂rel√§sning 10 - Populationer och stickprov. Unders√∂kningar och experiment.\nL√§s: SDM 10.1-10.3 och 11.1-11.2 | Slides¬†\nF√∂rel√§sning 11 - Sammanfattning\nL√§s: Slides\n\n\nR√§kne√∂vningar\n√ñvningarna i kursboken Stats: Data and Models (SDM) h√§nvisas till med kapitelnummer f√∂ljt av √∂vningsnummer.\n√ñvning 1 - Beskrivande statistik.\nUppgifter: SDM 2.1, 2.2, 2.6, 2.7, 2.9, 2.11, 2.12, 2.14, 2.15, 2.16, 2.17, 2.20, 2.21, 2.24.\n√ñvning 2 - Samband mellan kategoriska variabler. Transformationer.\nUppgifter: SDM 3.1, 3.3, 3.5, 3.6, 3.7, 3.9, 3.25, 3.31, 3.39, 3.41, 3.47, 4.1, 4.3, 4.14, 4.17, 4.45.\n√ñvning 3 - Standarisering och normalmodellen.\nUppgifter: SDM 5.1, 5.2, 5.4, 5.5, 5.8, 5.10, 5.14, 5.16, 5.17, 5.30, 5.42, 5.48.\n√ñvning 4 - Samband mellan numeriska variabler. Korrelation och enkel linj√§r regression.\nUppgifter: SDM 6.2, 6.3, 6.5, 6.6, 6.9, 6.14, 6.20, 7.1, 7.2, 7.3, 7.4, 7.5, 7.7, 7.9, 7.11, 7.13, 7.15, 7.19, 7.23, 7.27, 7.52.\n√ñvning 5 - Multipel linj√§r regression.\nUppgifter: SDM Kapitel 8.18, 8.20, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.9, 9.11, 9.14, 9.16, 9.22, 9.23, 9.28.\n√ñvning 6 - Repetition.\nRepetitionstillf√§lle.\n\n\nDatorlaborationer\nDatorlaboration 1 - Introduktion till R.\nUppgifter: html\nDatorlaboration 2 - Beskrivande statistik och visualisering i R.\nUppgifter: html | quarto\nDatorlaboration 3 - Samband mellan tv√• kategoriska variabler. Samband mellan en kategorisk och en numerisk variabel. Tidsserier.\nUppgifter: html | quarto\nDatorlaboration 4 - Korrelation. Enkel och multipel linj√§r samt icke-linj√§r regression.\nUppgifter: html | quarto\n\n\nInl√§mningsuppgift\nInl√§mningsuppgift 1.\nUppgifter: html | quarto"
  },
  {
    "objectID": "observable/bayestheorem.html",
    "href": "observable/bayestheorem.html",
    "title": "Bayes sats",
    "section": "",
    "text": "Den h√§r widgeten l√•ter dig unders√∂ka hur tillf√∂rlitliga hemtest f√∂r Covid √§r genom att ber√§kna den betingade sannolikheten P(covid | positivt test) med hj√§lp av Bayes sats. Du kan ocks√• anv√§nda widgeten till andra problem, genom att ge h√§ndelserna covid och pos andra namn."
  },
  {
    "objectID": "observable/storatalenslag.html",
    "href": "observable/storatalenslag.html",
    "title": "Stora talens lag - normalf√∂rdelning",
    "section": "",
    "text": "L√•t \\[X_1,X_2,\\ldots,X_n   \\overset{\\mathrm{iid}}{\\sim} \\operatorname{N}(\\mu,\\sigma^2)\\]\nD√• g√§ller att \\[\n\\bar X \\sim \\operatorname{N}(\\mu,\\sigma^2/n)\n\\] Vi ser h√§r stora talens lag in action: eftersom variansen minskar n√§r \\(n\\) √∂kar kommer medelv√§rdet att ligga allt n√§rmare v√§ntev√§rdet \\(\\mu\\) i stora stickprov. Det visas i de interaktiva illustrationerna nedan."
  },
  {
    "objectID": "observable/storatalenslag.html#medelv√§rdet-stabiliseras-kring-mu",
    "href": "observable/storatalenslag.html#medelv√§rdet-stabiliseras-kring-mu",
    "title": "Stora talens lag - normalf√∂rdelning",
    "section": "Medelv√§rdet stabiliseras kring \\(\\mu\\)",
    "text": "Medelv√§rdet stabiliseras kring \\(\\mu\\)"
  },
  {
    "objectID": "observable/storatalenslag.html#samplingf√∂rdelningen-koncentreras-kring-mu",
    "href": "observable/storatalenslag.html#samplingf√∂rdelningen-koncentreras-kring-mu",
    "title": "Stora talens lag - normalf√∂rdelning",
    "section": "Samplingf√∂rdelningen koncentreras kring \\(\\mu\\)",
    "text": "Samplingf√∂rdelningen koncentreras kring \\(\\mu\\)"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#normalf√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#normalf√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Normalf√∂rdelning",
    "text": "Normalf√∂rdelning\nTabellen ger sannolikheten \\(\\Phi(z) = P(Z\\leq z)\\) f√∂r olika \\(z\\) d√§r \\(Z\\) √§r standardnormal, \\(Z\\sim N(0,1)\\).\nSannolikheter i den v√§nstra svansen f√•s genom symmetri: \\(P(Z\\leq \\textminus z) = 1-P(Z\\leq z)\\).\n\n ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† \n\n\nAndra decimalen i \\(z\\)\n\n\n\n\n\n \n  \n      \n    0.00 \n    0.01 \n    0.02 \n    0.03 \n    0.04 \n    0.05 \n    0.06 \n    0.07 \n    0.08 \n    0.09 \n  \n \n\n  \n    0.0 \n    0.5000 \n    0.5040 \n    0.5080 \n    0.5120 \n    0.5160 \n    0.5199 \n    0.5239 \n    0.5279 \n    0.5319 \n    0.5359 \n  \n  \n    0.1 \n    0.5398 \n    0.5438 \n    0.5478 \n    0.5517 \n    0.5557 \n    0.5596 \n    0.5636 \n    0.5675 \n    0.5714 \n    0.5753 \n  \n  \n    0.2 \n    0.5793 \n    0.5832 \n    0.5871 \n    0.5910 \n    0.5948 \n    0.5987 \n    0.6026 \n    0.6064 \n    0.6103 \n    0.6141 \n  \n  \n    0.3 \n    0.6179 \n    0.6217 \n    0.6255 \n    0.6293 \n    0.6331 \n    0.6368 \n    0.6406 \n    0.6443 \n    0.6480 \n    0.6517 \n  \n  \n    0.4 \n    0.6554 \n    0.6591 \n    0.6628 \n    0.6664 \n    0.6700 \n    0.6736 \n    0.6772 \n    0.6808 \n    0.6844 \n    0.6879 \n  \n  \n    0.5 \n    0.6915 \n    0.6950 \n    0.6985 \n    0.7019 \n    0.7054 \n    0.7088 \n    0.7123 \n    0.7157 \n    0.7190 \n    0.7224 \n  \n  \n    0.6 \n    0.7257 \n    0.7291 \n    0.7324 \n    0.7357 \n    0.7389 \n    0.7422 \n    0.7454 \n    0.7486 \n    0.7517 \n    0.7549 \n  \n  \n    0.7 \n    0.7580 \n    0.7611 \n    0.7642 \n    0.7673 \n    0.7704 \n    0.7734 \n    0.7764 \n    0.7794 \n    0.7823 \n    0.7852 \n  \n  \n    0.8 \n    0.7881 \n    0.7910 \n    0.7939 \n    0.7967 \n    0.7995 \n    0.8023 \n    0.8051 \n    0.8078 \n    0.8106 \n    0.8133 \n  \n  \n    0.9 \n    0.8159 \n    0.8186 \n    0.8212 \n    0.8238 \n    0.8264 \n    0.8289 \n    0.8315 \n    0.8340 \n    0.8365 \n    0.8389 \n  \n  \n    1.0 \n    0.8413 \n    0.8438 \n    0.8461 \n    0.8485 \n    0.8508 \n    0.8531 \n    0.8554 \n    0.8577 \n    0.8599 \n    0.8621 \n  \n  \n    1.1 \n    0.8643 \n    0.8665 \n    0.8686 \n    0.8708 \n    0.8729 \n    0.8749 \n    0.8770 \n    0.8790 \n    0.8810 \n    0.8830 \n  \n  \n    1.2 \n    0.8849 \n    0.8869 \n    0.8888 \n    0.8907 \n    0.8925 \n    0.8944 \n    0.8962 \n    0.8980 \n    0.8997 \n    0.9015 \n  \n  \n    1.3 \n    0.9032 \n    0.9049 \n    0.9066 \n    0.9082 \n    0.9099 \n    0.9115 \n    0.9131 \n    0.9147 \n    0.9162 \n    0.9177 \n  \n  \n    1.4 \n    0.9192 \n    0.9207 \n    0.9222 \n    0.9236 \n    0.9251 \n    0.9265 \n    0.9279 \n    0.9292 \n    0.9306 \n    0.9319 \n  \n  \n    1.5 \n    0.9332 \n    0.9345 \n    0.9357 \n    0.9370 \n    0.9382 \n    0.9394 \n    0.9406 \n    0.9418 \n    0.9429 \n    0.9441 \n  \n  \n    1.6 \n    0.9452 \n    0.9463 \n    0.9474 \n    0.9484 \n    0.9495 \n    0.9505 \n    0.9515 \n    0.9525 \n    0.9535 \n    0.9545 \n  \n  \n    1.7 \n    0.9554 \n    0.9564 \n    0.9573 \n    0.9582 \n    0.9591 \n    0.9599 \n    0.9608 \n    0.9616 \n    0.9625 \n    0.9633 \n  \n  \n    1.8 \n    0.9641 \n    0.9649 \n    0.9656 \n    0.9664 \n    0.9671 \n    0.9678 \n    0.9686 \n    0.9693 \n    0.9699 \n    0.9706 \n  \n  \n    1.9 \n    0.9713 \n    0.9719 \n    0.9726 \n    0.9732 \n    0.9738 \n    0.9744 \n    0.9750 \n    0.9756 \n    0.9761 \n    0.9767 \n  \n  \n    2.0 \n    0.9772 \n    0.9778 \n    0.9783 \n    0.9788 \n    0.9793 \n    0.9798 \n    0.9803 \n    0.9808 \n    0.9812 \n    0.9817 \n  \n  \n    2.1 \n    0.9821 \n    0.9826 \n    0.9830 \n    0.9834 \n    0.9838 \n    0.9842 \n    0.9846 \n    0.9850 \n    0.9854 \n    0.9857 \n  \n  \n    2.2 \n    0.9861 \n    0.9864 \n    0.9868 \n    0.9871 \n    0.9875 \n    0.9878 \n    0.9881 \n    0.9884 \n    0.9887 \n    0.9890 \n  \n  \n    2.3 \n    0.9893 \n    0.9896 \n    0.9898 \n    0.9901 \n    0.9904 \n    0.9906 \n    0.9909 \n    0.9911 \n    0.9913 \n    0.9916 \n  \n  \n    2.4 \n    0.9918 \n    0.9920 \n    0.9922 \n    0.9925 \n    0.9927 \n    0.9929 \n    0.9931 \n    0.9932 \n    0.9934 \n    0.9936 \n  \n  \n    2.5 \n    0.9938 \n    0.9940 \n    0.9941 \n    0.9943 \n    0.9945 \n    0.9946 \n    0.9948 \n    0.9949 \n    0.9951 \n    0.9952 \n  \n  \n    2.6 \n    0.9953 \n    0.9955 \n    0.9956 \n    0.9957 \n    0.9959 \n    0.9960 \n    0.9961 \n    0.9962 \n    0.9963 \n    0.9964 \n  \n  \n    2.7 \n    0.9965 \n    0.9966 \n    0.9967 \n    0.9968 \n    0.9969 \n    0.9970 \n    0.9971 \n    0.9972 \n    0.9973 \n    0.9974 \n  \n  \n    2.8 \n    0.9974 \n    0.9975 \n    0.9976 \n    0.9977 \n    0.9977 \n    0.9978 \n    0.9979 \n    0.9979 \n    0.9980 \n    0.9981 \n  \n  \n    2.9 \n    0.9981 \n    0.9982 \n    0.9982 \n    0.9983 \n    0.9984 \n    0.9984 \n    0.9985 \n    0.9985 \n    0.9986 \n    0.9986"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#student-t-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#student-t-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Student-\\(t\\) f√∂rdelning",
    "text": "Student-\\(t\\) f√∂rdelning\n\n\n¬†  ¬†¬† \n\n\n\n\n\n\n\nKonfidensniv√•: \n 80%\n 90%\n 95%\n 98%\n 99%\n\n\nTv√•sidig sannolikhet: \n0.200\n0.100\n0.050\n0.020\n0.010\n\n\nEnsidig sannolikhet: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    3.078 \n    6.314 \n    12.706 \n    31.821 \n    63.657 \n  \n  \n    2 \n    1.886 \n    2.920 \n    4.303 \n    6.965 \n    9.925 \n  \n  \n    3 \n    1.638 \n    2.353 \n    3.182 \n    4.541 \n    5.841 \n  \n  \n    4 \n    1.533 \n    2.132 \n    2.776 \n    3.747 \n    4.604 \n  \n  \n    5 \n    1.476 \n    2.015 \n    2.571 \n    3.365 \n    4.032 \n  \n  \n    6 \n    1.440 \n    1.943 \n    2.447 \n    3.143 \n    3.707 \n  \n  \n    7 \n    1.415 \n    1.895 \n    2.365 \n    2.998 \n    3.499 \n  \n  \n    8 \n    1.397 \n    1.860 \n    2.306 \n    2.896 \n    3.355 \n  \n  \n    9 \n    1.383 \n    1.833 \n    2.262 \n    2.821 \n    3.250 \n  \n  \n    10 \n    1.372 \n    1.812 \n    2.228 \n    2.764 \n    3.169 \n  \n  \n    11 \n    1.363 \n    1.796 \n    2.201 \n    2.718 \n    3.106 \n  \n  \n    12 \n    1.356 \n    1.782 \n    2.179 \n    2.681 \n    3.055 \n  \n  \n    13 \n    1.350 \n    1.771 \n    2.160 \n    2.650 \n    3.012 \n  \n  \n    14 \n    1.345 \n    1.761 \n    2.145 \n    2.624 \n    2.977 \n  \n  \n    15 \n    1.341 \n    1.753 \n    2.131 \n    2.602 \n    2.947 \n  \n  \n    16 \n    1.337 \n    1.746 \n    2.120 \n    2.583 \n    2.921 \n  \n  \n    17 \n    1.333 \n    1.740 \n    2.110 \n    2.567 \n    2.898 \n  \n  \n    18 \n    1.330 \n    1.734 \n    2.101 \n    2.552 \n    2.878 \n  \n  \n    19 \n    1.328 \n    1.729 \n    2.093 \n    2.539 \n    2.861 \n  \n  \n    20 \n    1.325 \n    1.725 \n    2.086 \n    2.528 \n    2.845 \n  \n  \n    21 \n    1.323 \n    1.721 \n    2.080 \n    2.518 \n    2.831 \n  \n  \n    22 \n    1.321 \n    1.717 \n    2.074 \n    2.508 \n    2.819 \n  \n  \n    23 \n    1.319 \n    1.714 \n    2.069 \n    2.500 \n    2.807 \n  \n  \n    24 \n    1.318 \n    1.711 \n    2.064 \n    2.492 \n    2.797 \n  \n  \n    25 \n    1.316 \n    1.708 \n    2.060 \n    2.485 \n    2.787 \n  \n  \n    26 \n    1.315 \n    1.706 \n    2.056 \n    2.479 \n    2.779 \n  \n  \n    27 \n    1.314 \n    1.703 \n    2.052 \n    2.473 \n    2.771 \n  \n  \n    28 \n    1.313 \n    1.701 \n    2.048 \n    2.467 \n    2.763 \n  \n  \n    29 \n    1.311 \n    1.699 \n    2.045 \n    2.462 \n    2.756 \n  \n  \n    30 \n    1.310 \n    1.697 \n    2.042 \n    2.457 \n    2.750 \n  \n  \n    32 \n    1.309 \n    1.694 \n    2.037 \n    2.449 \n    2.738 \n  \n  \n    35 \n    1.306 \n    1.690 \n    2.030 \n    2.438 \n    2.724 \n  \n  \n    40 \n    1.303 \n    1.684 \n    2.021 \n    2.423 \n    2.704 \n  \n  \n    45 \n    1.301 \n    1.679 \n    2.014 \n    2.412 \n    2.690 \n  \n  \n    50 \n    1.299 \n    1.676 \n    2.009 \n    2.403 \n    2.678 \n  \n  \n    60 \n    1.296 \n    1.671 \n    2.000 \n    2.390 \n    2.660 \n  \n  \n    75 \n    1.293 \n    1.665 \n    1.992 \n    2.377 \n    2.643 \n  \n  \n    100 \n    1.290 \n    1.660 \n    1.984 \n    2.364 \n    2.626 \n  \n  \n    120 \n    1.289 \n    1.658 \n    1.980 \n    2.358 \n    2.617 \n  \n  \n    140 \n    1.288 \n    1.656 \n    1.977 \n    2.353 \n    2.611 \n  \n  \n    180 \n    1.286 \n    1.653 \n    1.973 \n    2.347 \n    2.603 \n  \n  \n    250 \n    1.285 \n    1.651 \n    1.969 \n    2.341 \n    2.596 \n  \n  \n    400 \n    1.284 \n    1.649 \n    1.966 \n    2.336 \n    2.588 \n  \n  \n    1000 \n    1.282 \n    1.646 \n    1.962 \n    2.330 \n    2.581 \n  \n  \n    o√§ndligt \n    1.282 \n    1.645 \n    1.960 \n    2.326 \n    2.576"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#chi2-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#chi2-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(\\chi^2\\)-f√∂rdelning",
    "text": "\\(\\chi^2\\)-f√∂rdelning\n\n\n¬† \n\n\n\n\n\n\n\nSannolikhet i h√∂ger svans: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    2.706 \n    3.841 \n    5.024 \n    6.635 \n    7.879 \n  \n  \n    2 \n    4.605 \n    5.991 \n    7.378 \n    9.210 \n    10.597 \n  \n  \n    3 \n    6.251 \n    7.815 \n    9.348 \n    11.345 \n    12.838 \n  \n  \n    4 \n    7.779 \n    9.488 \n    11.143 \n    13.277 \n    14.860 \n  \n  \n    5 \n    9.236 \n    11.070 \n    12.833 \n    15.086 \n    16.750 \n  \n  \n    6 \n    10.645 \n    12.592 \n    14.449 \n    16.812 \n    18.548 \n  \n  \n    7 \n    12.017 \n    14.067 \n    16.013 \n    18.475 \n    20.278 \n  \n  \n    8 \n    13.362 \n    15.507 \n    17.535 \n    20.090 \n    21.955 \n  \n  \n    9 \n    14.684 \n    16.919 \n    19.023 \n    21.666 \n    23.589 \n  \n  \n    10 \n    15.987 \n    18.307 \n    20.483 \n    23.209 \n    25.188 \n  \n  \n    11 \n    17.275 \n    19.675 \n    21.920 \n    24.725 \n    26.757 \n  \n  \n    12 \n    18.549 \n    21.026 \n    23.337 \n    26.217 \n    28.300 \n  \n  \n    13 \n    19.812 \n    22.362 \n    24.736 \n    27.688 \n    29.819 \n  \n  \n    14 \n    21.064 \n    23.685 \n    26.119 \n    29.141 \n    31.319 \n  \n  \n    15 \n    22.307 \n    24.996 \n    27.488 \n    30.578 \n    32.801 \n  \n  \n    16 \n    23.542 \n    26.296 \n    28.845 \n    32.000 \n    34.267 \n  \n  \n    17 \n    24.769 \n    27.587 \n    30.191 \n    33.409 \n    35.718 \n  \n  \n    18 \n    25.989 \n    28.869 \n    31.526 \n    34.805 \n    37.156 \n  \n  \n    19 \n    27.204 \n    30.144 \n    32.852 \n    36.191 \n    38.582 \n  \n  \n    20 \n    28.412 \n    31.410 \n    34.170 \n    37.566 \n    39.997 \n  \n  \n    21 \n    29.615 \n    32.671 \n    35.479 \n    38.932 \n    41.401 \n  \n  \n    22 \n    30.813 \n    33.924 \n    36.781 \n    40.289 \n    42.796 \n  \n  \n    23 \n    32.007 \n    35.172 \n    38.076 \n    41.638 \n    44.181 \n  \n  \n    24 \n    33.196 \n    36.415 \n    39.364 \n    42.980 \n    45.559 \n  \n  \n    25 \n    34.382 \n    37.652 \n    40.646 \n    44.314 \n    46.928 \n  \n  \n    26 \n    35.563 \n    38.885 \n    41.923 \n    45.642 \n    48.290 \n  \n  \n    27 \n    36.741 \n    40.113 \n    43.195 \n    46.963 \n    49.645 \n  \n  \n    28 \n    37.916 \n    41.337 \n    44.461 \n    48.278 \n    50.993 \n  \n  \n    29 \n    39.087 \n    42.557 \n    45.722 \n    49.588 \n    52.336 \n  \n  \n    30 \n    40.256 \n    43.773 \n    46.979 \n    50.892 \n    53.672 \n  \n  \n    40 \n    51.805 \n    55.758 \n    59.342 \n    63.691 \n    66.766 \n  \n  \n    50 \n    63.167 \n    67.505 \n    71.420 \n    76.154 \n    79.490 \n  \n  \n    60 \n    74.397 \n    79.082 \n    83.298 \n    88.379 \n    91.952 \n  \n  \n    70 \n    85.527 \n    90.531 \n    95.023 \n    100.425 \n    104.215 \n  \n  \n    80 \n    96.578 \n    101.879 \n    106.629 \n    112.329 \n    116.321 \n  \n  \n    90 \n    107.565 \n    113.145 \n    118.136 \n    124.116 \n    128.299 \n  \n  \n    100 \n    118.498 \n    124.342 \n    129.561 \n    135.807 \n    140.169"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#f-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#f-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(F\\)-f√∂rdelning",
    "text": "\\(F\\)-f√∂rdelning\n\n\\(\\alpha = 0.01\\)\\(\\alpha = 0.05\\)\\(\\alpha = 0.10\\)\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    4052.18 \n    4999.50 \n    5403.35 \n    5624.58 \n    5763.65 \n    5858.99 \n    5928.36 \n    5981.07 \n    6022.47 \n    6055.85 \n    6083.32 \n    6106.32 \n    6125.86 \n    6142.67 \n    6157.28 \n    6170.10 \n    6181.43 \n    6191.53 \n    6200.58 \n    6208.73 \n    6216.12 \n    6222.84 \n  \n  \n    2 \n    98.50 \n    99.00 \n    99.17 \n    99.25 \n    99.30 \n    99.33 \n    99.36 \n    99.37 \n    99.39 \n    99.40 \n    99.41 \n    99.42 \n    99.42 \n    99.43 \n    99.43 \n    99.44 \n    99.44 \n    99.44 \n    99.45 \n    99.45 \n    99.45 \n    99.45 \n  \n  \n    3 \n    34.12 \n    30.82 \n    29.46 \n    28.71 \n    28.24 \n    27.91 \n    27.67 \n    27.49 \n    27.35 \n    27.23 \n    27.13 \n    27.05 \n    26.98 \n    26.92 \n    26.87 \n    26.83 \n    26.79 \n    26.75 \n    26.72 \n    26.69 \n    26.66 \n    26.64 \n  \n  \n    4 \n    21.20 \n    18.00 \n    16.69 \n    15.98 \n    15.52 \n    15.21 \n    14.98 \n    14.80 \n    14.66 \n    14.55 \n    14.45 \n    14.37 \n    14.31 \n    14.25 \n    14.20 \n    14.15 \n    14.11 \n    14.08 \n    14.05 \n    14.02 \n    13.99 \n    13.97 \n  \n  \n    5 \n    16.26 \n    13.27 \n    12.06 \n    11.39 \n    10.97 \n    10.67 \n    10.46 \n    10.29 \n    10.16 \n    10.05 \n    9.96 \n    9.89 \n    9.82 \n    9.77 \n    9.72 \n    9.68 \n    9.64 \n    9.61 \n    9.58 \n    9.55 \n    9.53 \n    9.51 \n  \n  \n    6 \n    13.75 \n    10.92 \n    9.78 \n    9.15 \n    8.75 \n    8.47 \n    8.26 \n    8.10 \n    7.98 \n    7.87 \n    7.79 \n    7.72 \n    7.66 \n    7.60 \n    7.56 \n    7.52 \n    7.48 \n    7.45 \n    7.42 \n    7.40 \n    7.37 \n    7.35 \n  \n  \n    7 \n    12.25 \n    9.55 \n    8.45 \n    7.85 \n    7.46 \n    7.19 \n    6.99 \n    6.84 \n    6.72 \n    6.62 \n    6.54 \n    6.47 \n    6.41 \n    6.36 \n    6.31 \n    6.28 \n    6.24 \n    6.21 \n    6.18 \n    6.16 \n    6.13 \n    6.11 \n  \n  \n    8 \n    11.26 \n    8.65 \n    7.59 \n    7.01 \n    6.63 \n    6.37 \n    6.18 \n    6.03 \n    5.91 \n    5.81 \n    5.73 \n    5.67 \n    5.61 \n    5.56 \n    5.52 \n    5.48 \n    5.44 \n    5.41 \n    5.38 \n    5.36 \n    5.34 \n    5.32 \n  \n  \n    9 \n    10.56 \n    8.02 \n    6.99 \n    6.42 \n    6.06 \n    5.80 \n    5.61 \n    5.47 \n    5.35 \n    5.26 \n    5.18 \n    5.11 \n    5.05 \n    5.01 \n    4.96 \n    4.92 \n    4.89 \n    4.86 \n    4.83 \n    4.81 \n    4.79 \n    4.77 \n  \n  \n    10 \n    10.04 \n    7.56 \n    6.55 \n    5.99 \n    5.64 \n    5.39 \n    5.20 \n    5.06 \n    4.94 \n    4.85 \n    4.77 \n    4.71 \n    4.65 \n    4.60 \n    4.56 \n    4.52 \n    4.49 \n    4.46 \n    4.43 \n    4.41 \n    4.38 \n    4.36 \n  \n  \n    11 \n    9.65 \n    7.21 \n    6.22 \n    5.67 \n    5.32 \n    5.07 \n    4.89 \n    4.74 \n    4.63 \n    4.54 \n    4.46 \n    4.40 \n    4.34 \n    4.29 \n    4.25 \n    4.21 \n    4.18 \n    4.15 \n    4.12 \n    4.10 \n    4.08 \n    4.06 \n  \n  \n    12 \n    9.33 \n    6.93 \n    5.95 \n    5.41 \n    5.06 \n    4.82 \n    4.64 \n    4.50 \n    4.39 \n    4.30 \n    4.22 \n    4.16 \n    4.10 \n    4.05 \n    4.01 \n    3.97 \n    3.94 \n    3.91 \n    3.88 \n    3.86 \n    3.84 \n    3.82 \n  \n  \n    13 \n    9.07 \n    6.70 \n    5.74 \n    5.21 \n    4.86 \n    4.62 \n    4.44 \n    4.30 \n    4.19 \n    4.10 \n    4.02 \n    3.96 \n    3.91 \n    3.86 \n    3.82 \n    3.78 \n    3.75 \n    3.72 \n    3.69 \n    3.66 \n    3.64 \n    3.62 \n  \n  \n    14 \n    8.86 \n    6.51 \n    5.56 \n    5.04 \n    4.69 \n    4.46 \n    4.28 \n    4.14 \n    4.03 \n    3.94 \n    3.86 \n    3.80 \n    3.75 \n    3.70 \n    3.66 \n    3.62 \n    3.59 \n    3.56 \n    3.53 \n    3.51 \n    3.48 \n    3.46 \n  \n  \n    15 \n    8.68 \n    6.36 \n    5.42 \n    4.89 \n    4.56 \n    4.32 \n    4.14 \n    4.00 \n    3.89 \n    3.80 \n    3.73 \n    3.67 \n    3.61 \n    3.56 \n    3.52 \n    3.49 \n    3.45 \n    3.42 \n    3.40 \n    3.37 \n    3.35 \n    3.33 \n  \n  \n    16 \n    8.53 \n    6.23 \n    5.29 \n    4.77 \n    4.44 \n    4.20 \n    4.03 \n    3.89 \n    3.78 \n    3.69 \n    3.62 \n    3.55 \n    3.50 \n    3.45 \n    3.41 \n    3.37 \n    3.34 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n  \n  \n    17 \n    8.40 \n    6.11 \n    5.18 \n    4.67 \n    4.34 \n    4.10 \n    3.93 \n    3.79 \n    3.68 \n    3.59 \n    3.52 \n    3.46 \n    3.40 \n    3.35 \n    3.31 \n    3.27 \n    3.24 \n    3.21 \n    3.19 \n    3.16 \n    3.14 \n    3.12 \n  \n  \n    18 \n    8.29 \n    6.01 \n    5.09 \n    4.58 \n    4.25 \n    4.01 \n    3.84 \n    3.71 \n    3.60 \n    3.51 \n    3.43 \n    3.37 \n    3.32 \n    3.27 \n    3.23 \n    3.19 \n    3.16 \n    3.13 \n    3.10 \n    3.08 \n    3.05 \n    3.03 \n  \n  \n    19 \n    8.18 \n    5.93 \n    5.01 \n    4.50 \n    4.17 \n    3.94 \n    3.77 \n    3.63 \n    3.52 \n    3.43 \n    3.36 \n    3.30 \n    3.24 \n    3.19 \n    3.15 \n    3.12 \n    3.08 \n    3.05 \n    3.03 \n    3.00 \n    2.98 \n    2.96 \n  \n  \n    20 \n    8.10 \n    5.85 \n    4.94 \n    4.43 \n    4.10 \n    3.87 \n    3.70 \n    3.56 \n    3.46 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.13 \n    3.09 \n    3.05 \n    3.02 \n    2.99 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n  \n  \n    21 \n    8.02 \n    5.78 \n    4.87 \n    4.37 \n    4.04 \n    3.81 \n    3.64 \n    3.51 \n    3.40 \n    3.31 \n    3.24 \n    3.17 \n    3.12 \n    3.07 \n    3.03 \n    2.99 \n    2.96 \n    2.93 \n    2.90 \n    2.88 \n    2.86 \n    2.84 \n  \n  \n    22 \n    7.95 \n    5.72 \n    4.82 \n    4.31 \n    3.99 \n    3.76 \n    3.59 \n    3.45 \n    3.35 \n    3.26 \n    3.18 \n    3.12 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.88 \n    2.85 \n    2.83 \n    2.81 \n    2.78 \n  \n  \n    23 \n    7.88 \n    5.66 \n    4.76 \n    4.26 \n    3.94 \n    3.71 \n    3.54 \n    3.41 \n    3.30 \n    3.21 \n    3.14 \n    3.07 \n    3.02 \n    2.97 \n    2.93 \n    2.89 \n    2.86 \n    2.83 \n    2.80 \n    2.78 \n    2.76 \n    2.74 \n  \n  \n    24 \n    7.82 \n    5.61 \n    4.72 \n    4.22 \n    3.90 \n    3.67 \n    3.50 \n    3.36 \n    3.26 \n    3.17 \n    3.09 \n    3.03 \n    2.98 \n    2.93 \n    2.89 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n  \n  \n    25 \n    7.77 \n    5.57 \n    4.68 \n    4.18 \n    3.85 \n    3.63 \n    3.46 \n    3.32 \n    3.22 \n    3.13 \n    3.06 \n    2.99 \n    2.94 \n    2.89 \n    2.85 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.66 \n  \n  \n    26 \n    7.72 \n    5.53 \n    4.64 \n    4.14 \n    3.82 \n    3.59 \n    3.42 \n    3.29 \n    3.18 \n    3.09 \n    3.02 \n    2.96 \n    2.90 \n    2.86 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n  \n  \n    27 \n    7.68 \n    5.49 \n    4.60 \n    4.11 \n    3.78 \n    3.56 \n    3.39 \n    3.26 \n    3.15 \n    3.06 \n    2.99 \n    2.93 \n    2.87 \n    2.82 \n    2.78 \n    2.75 \n    2.71 \n    2.68 \n    2.66 \n    2.63 \n    2.61 \n    2.59 \n  \n  \n    28 \n    7.64 \n    5.45 \n    4.57 \n    4.07 \n    3.75 \n    3.53 \n    3.36 \n    3.23 \n    3.12 \n    3.03 \n    2.96 \n    2.90 \n    2.84 \n    2.79 \n    2.75 \n    2.72 \n    2.68 \n    2.65 \n    2.63 \n    2.60 \n    2.58 \n    2.56 \n  \n  \n    29 \n    7.60 \n    5.42 \n    4.54 \n    4.04 \n    3.73 \n    3.50 \n    3.33 \n    3.20 \n    3.09 \n    3.00 \n    2.93 \n    2.87 \n    2.81 \n    2.77 \n    2.73 \n    2.69 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n  \n  \n    30 \n    7.56 \n    5.39 \n    4.51 \n    4.02 \n    3.70 \n    3.47 \n    3.30 \n    3.17 \n    3.07 \n    2.98 \n    2.91 \n    2.84 \n    2.79 \n    2.74 \n    2.70 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n    2.51 \n  \n  \n    35 \n    7.42 \n    5.27 \n    4.40 \n    3.91 \n    3.59 \n    3.37 \n    3.20 \n    3.07 \n    2.96 \n    2.88 \n    2.80 \n    2.74 \n    2.69 \n    2.64 \n    2.60 \n    2.56 \n    2.53 \n    2.50 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n  \n  \n    40 \n    7.31 \n    5.18 \n    4.31 \n    3.83 \n    3.51 \n    3.29 \n    3.12 \n    2.99 \n    2.89 \n    2.80 \n    2.73 \n    2.66 \n    2.61 \n    2.56 \n    2.52 \n    2.48 \n    2.45 \n    2.42 \n    2.39 \n    2.37 \n    2.35 \n    2.33 \n  \n  \n    45 \n    7.23 \n    5.11 \n    4.25 \n    3.77 \n    3.45 \n    3.23 \n    3.07 \n    2.94 \n    2.83 \n    2.74 \n    2.67 \n    2.61 \n    2.55 \n    2.51 \n    2.46 \n    2.43 \n    2.39 \n    2.36 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n  \n  \n    50 \n    7.17 \n    5.06 \n    4.20 \n    3.72 \n    3.41 \n    3.19 \n    3.02 \n    2.89 \n    2.78 \n    2.70 \n    2.63 \n    2.56 \n    2.51 \n    2.46 \n    2.42 \n    2.38 \n    2.35 \n    2.32 \n    2.29 \n    2.27 \n    2.24 \n    2.22 \n  \n  \n    60 \n    7.08 \n    4.98 \n    4.13 \n    3.65 \n    3.34 \n    3.12 \n    2.95 \n    2.82 \n    2.72 \n    2.63 \n    2.56 \n    2.50 \n    2.44 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.17 \n    2.15 \n  \n  \n    75 \n    6.99 \n    4.90 \n    4.05 \n    3.58 \n    3.27 \n    3.05 \n    2.89 \n    2.76 \n    2.65 \n    2.57 \n    2.49 \n    2.43 \n    2.38 \n    2.33 \n    2.29 \n    2.25 \n    2.22 \n    2.18 \n    2.16 \n    2.13 \n    2.11 \n    2.09 \n  \n  \n    100 \n    6.90 \n    4.82 \n    3.98 \n    3.51 \n    3.21 \n    2.99 \n    2.82 \n    2.69 \n    2.59 \n    2.50 \n    2.43 \n    2.37 \n    2.31 \n    2.27 \n    2.22 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.04 \n    2.02 \n  \n  \n    120 \n    6.85 \n    4.79 \n    3.95 \n    3.48 \n    3.17 \n    2.96 \n    2.79 \n    2.66 \n    2.56 \n    2.47 \n    2.40 \n    2.34 \n    2.28 \n    2.23 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n  \n  \n    140 \n    6.82 \n    4.76 \n    3.92 \n    3.46 \n    3.15 \n    2.93 \n    2.77 \n    2.64 \n    2.54 \n    2.45 \n    2.38 \n    2.31 \n    2.26 \n    2.21 \n    2.17 \n    2.13 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.97 \n  \n  \n    180 \n    6.78 \n    4.73 \n    3.89 \n    3.43 \n    3.12 \n    2.90 \n    2.74 \n    2.61 \n    2.51 \n    2.42 \n    2.35 \n    2.28 \n    2.23 \n    2.18 \n    2.14 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.96 \n    1.94 \n  \n  \n    250 \n    6.74 \n    4.69 \n    3.86 \n    3.40 \n    3.09 \n    2.87 \n    2.71 \n    2.58 \n    2.48 \n    2.39 \n    2.32 \n    2.26 \n    2.20 \n    2.15 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.95 \n    1.93 \n    1.91 \n  \n  \n    400 \n    6.70 \n    4.66 \n    3.83 \n    3.37 \n    3.06 \n    2.85 \n    2.68 \n    2.56 \n    2.45 \n    2.37 \n    2.29 \n    2.23 \n    2.17 \n    2.13 \n    2.08 \n    2.05 \n    2.01 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.88 \n  \n  \n    1000 \n    6.66 \n    4.63 \n    3.80 \n    3.34 \n    3.04 \n    2.82 \n    2.66 \n    2.53 \n    2.43 \n    2.34 \n    2.27 \n    2.20 \n    2.15 \n    2.10 \n    2.06 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.85 \n  \n\n\n\n\n\n\n\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    161.45 \n    199.50 \n    215.71 \n    224.58 \n    230.16 \n    233.99 \n    236.77 \n    238.88 \n    240.54 \n    241.88 \n    242.98 \n    243.91 \n    244.69 \n    245.36 \n    245.95 \n    246.46 \n    246.92 \n    247.32 \n    247.69 \n    248.01 \n    248.31 \n    248.58 \n  \n  \n    2 \n    18.51 \n    19.00 \n    19.16 \n    19.25 \n    19.30 \n    19.33 \n    19.35 \n    19.37 \n    19.38 \n    19.40 \n    19.40 \n    19.41 \n    19.42 \n    19.42 \n    19.43 \n    19.43 \n    19.44 \n    19.44 \n    19.44 \n    19.45 \n    19.45 \n    19.45 \n  \n  \n    3 \n    10.13 \n    9.55 \n    9.28 \n    9.12 \n    9.01 \n    8.94 \n    8.89 \n    8.85 \n    8.81 \n    8.79 \n    8.76 \n    8.74 \n    8.73 \n    8.71 \n    8.70 \n    8.69 \n    8.68 \n    8.67 \n    8.67 \n    8.66 \n    8.65 \n    8.65 \n  \n  \n    4 \n    7.71 \n    6.94 \n    6.59 \n    6.39 \n    6.26 \n    6.16 \n    6.09 \n    6.04 \n    6.00 \n    5.96 \n    5.94 \n    5.91 \n    5.89 \n    5.87 \n    5.86 \n    5.84 \n    5.83 \n    5.82 \n    5.81 \n    5.80 \n    5.79 \n    5.79 \n  \n  \n    5 \n    6.61 \n    5.79 \n    5.41 \n    5.19 \n    5.05 \n    4.95 \n    4.88 \n    4.82 \n    4.77 \n    4.74 \n    4.70 \n    4.68 \n    4.66 \n    4.64 \n    4.62 \n    4.60 \n    4.59 \n    4.58 \n    4.57 \n    4.56 \n    4.55 \n    4.54 \n  \n  \n    6 \n    5.99 \n    5.14 \n    4.76 \n    4.53 \n    4.39 \n    4.28 \n    4.21 \n    4.15 \n    4.10 \n    4.06 \n    4.03 \n    4.00 \n    3.98 \n    3.96 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n  \n  \n    7 \n    5.59 \n    4.74 \n    4.35 \n    4.12 \n    3.97 \n    3.87 \n    3.79 \n    3.73 \n    3.68 \n    3.64 \n    3.60 \n    3.57 \n    3.55 \n    3.53 \n    3.51 \n    3.49 \n    3.48 \n    3.47 \n    3.46 \n    3.44 \n    3.43 \n    3.43 \n  \n  \n    8 \n    5.32 \n    4.46 \n    4.07 \n    3.84 \n    3.69 \n    3.58 \n    3.50 \n    3.44 \n    3.39 \n    3.35 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n    3.20 \n    3.19 \n    3.17 \n    3.16 \n    3.15 \n    3.14 \n    3.13 \n  \n  \n    9 \n    5.12 \n    4.26 \n    3.86 \n    3.63 \n    3.48 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.14 \n    3.10 \n    3.07 \n    3.05 \n    3.03 \n    3.01 \n    2.99 \n    2.97 \n    2.96 \n    2.95 \n    2.94 \n    2.93 \n    2.92 \n  \n  \n    10 \n    4.96 \n    4.10 \n    3.71 \n    3.48 \n    3.33 \n    3.22 \n    3.14 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.89 \n    2.86 \n    2.85 \n    2.83 \n    2.81 \n    2.80 \n    2.79 \n    2.77 \n    2.76 \n    2.75 \n  \n  \n    11 \n    4.84 \n    3.98 \n    3.59 \n    3.36 \n    3.20 \n    3.09 \n    3.01 \n    2.95 \n    2.90 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n    2.69 \n    2.67 \n    2.66 \n    2.65 \n    2.64 \n    2.63 \n  \n  \n    12 \n    4.75 \n    3.89 \n    3.49 \n    3.26 \n    3.11 \n    3.00 \n    2.91 \n    2.85 \n    2.80 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n    2.60 \n    2.58 \n    2.57 \n    2.56 \n    2.54 \n    2.53 \n    2.52 \n  \n  \n    13 \n    4.67 \n    3.81 \n    3.41 \n    3.18 \n    3.03 \n    2.92 \n    2.83 \n    2.77 \n    2.71 \n    2.67 \n    2.63 \n    2.60 \n    2.58 \n    2.55 \n    2.53 \n    2.51 \n    2.50 \n    2.48 \n    2.47 \n    2.46 \n    2.45 \n    2.44 \n  \n  \n    14 \n    4.60 \n    3.74 \n    3.34 \n    3.11 \n    2.96 \n    2.85 \n    2.76 \n    2.70 \n    2.65 \n    2.60 \n    2.57 \n    2.53 \n    2.51 \n    2.48 \n    2.46 \n    2.44 \n    2.43 \n    2.41 \n    2.40 \n    2.39 \n    2.38 \n    2.37 \n  \n  \n    15 \n    4.54 \n    3.68 \n    3.29 \n    3.06 \n    2.90 \n    2.79 \n    2.71 \n    2.64 \n    2.59 \n    2.54 \n    2.51 \n    2.48 \n    2.45 \n    2.42 \n    2.40 \n    2.38 \n    2.37 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n  \n  \n    16 \n    4.49 \n    3.63 \n    3.24 \n    3.01 \n    2.85 \n    2.74 \n    2.66 \n    2.59 \n    2.54 \n    2.49 \n    2.46 \n    2.42 \n    2.40 \n    2.37 \n    2.35 \n    2.33 \n    2.32 \n    2.30 \n    2.29 \n    2.28 \n    2.26 \n    2.25 \n  \n  \n    17 \n    4.45 \n    3.59 \n    3.20 \n    2.96 \n    2.81 \n    2.70 \n    2.61 \n    2.55 \n    2.49 \n    2.45 \n    2.41 \n    2.38 \n    2.35 \n    2.33 \n    2.31 \n    2.29 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.21 \n  \n  \n    18 \n    4.41 \n    3.55 \n    3.16 \n    2.93 \n    2.77 \n    2.66 \n    2.58 \n    2.51 \n    2.46 \n    2.41 \n    2.37 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n    2.25 \n    2.23 \n    2.22 \n    2.20 \n    2.19 \n    2.18 \n    2.17 \n  \n  \n    19 \n    4.38 \n    3.52 \n    3.13 \n    2.90 \n    2.74 \n    2.63 \n    2.54 \n    2.48 \n    2.42 \n    2.38 \n    2.34 \n    2.31 \n    2.28 \n    2.26 \n    2.23 \n    2.21 \n    2.20 \n    2.18 \n    2.17 \n    2.16 \n    2.14 \n    2.13 \n  \n  \n    20 \n    4.35 \n    3.49 \n    3.10 \n    2.87 \n    2.71 \n    2.60 \n    2.51 \n    2.45 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.17 \n    2.15 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n  \n  \n    21 \n    4.32 \n    3.47 \n    3.07 \n    2.84 \n    2.68 \n    2.57 \n    2.49 \n    2.42 \n    2.37 \n    2.32 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.16 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n  \n  \n    22 \n    4.30 \n    3.44 \n    3.05 \n    2.82 \n    2.66 \n    2.55 \n    2.46 \n    2.40 \n    2.34 \n    2.30 \n    2.26 \n    2.23 \n    2.20 \n    2.17 \n    2.15 \n    2.13 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n  \n  \n    23 \n    4.28 \n    3.42 \n    3.03 \n    2.80 \n    2.64 \n    2.53 \n    2.44 \n    2.37 \n    2.32 \n    2.27 \n    2.24 \n    2.20 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.08 \n    2.06 \n    2.05 \n    2.04 \n    2.02 \n  \n  \n    24 \n    4.26 \n    3.40 \n    3.01 \n    2.78 \n    2.62 \n    2.51 \n    2.42 \n    2.36 \n    2.30 \n    2.25 \n    2.22 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.01 \n    2.00 \n  \n  \n    25 \n    4.24 \n    3.39 \n    2.99 \n    2.76 \n    2.60 \n    2.49 \n    2.40 \n    2.34 \n    2.28 \n    2.24 \n    2.20 \n    2.16 \n    2.14 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.98 \n  \n  \n    26 \n    4.23 \n    3.37 \n    2.98 \n    2.74 \n    2.59 \n    2.47 \n    2.39 \n    2.32 \n    2.27 \n    2.22 \n    2.18 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.05 \n    2.03 \n    2.02 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n  \n  \n    27 \n    4.21 \n    3.35 \n    2.96 \n    2.73 \n    2.57 \n    2.46 \n    2.37 \n    2.31 \n    2.25 \n    2.20 \n    2.17 \n    2.13 \n    2.10 \n    2.08 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n  \n  \n    28 \n    4.20 \n    3.34 \n    2.95 \n    2.71 \n    2.56 \n    2.45 \n    2.36 \n    2.29 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.93 \n  \n  \n    29 \n    4.18 \n    3.33 \n    2.93 \n    2.70 \n    2.55 \n    2.43 \n    2.35 \n    2.28 \n    2.22 \n    2.18 \n    2.14 \n    2.10 \n    2.08 \n    2.05 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.96 \n    1.94 \n    1.93 \n    1.92 \n  \n  \n    30 \n    4.17 \n    3.32 \n    2.92 \n    2.69 \n    2.53 \n    2.42 \n    2.33 \n    2.27 \n    2.21 \n    2.16 \n    2.13 \n    2.09 \n    2.06 \n    2.04 \n    2.01 \n    1.99 \n    1.98 \n    1.96 \n    1.95 \n    1.93 \n    1.92 \n    1.91 \n  \n  \n    35 \n    4.12 \n    3.27 \n    2.87 \n    2.64 \n    2.49 \n    2.37 \n    2.29 \n    2.22 \n    2.16 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.96 \n    1.94 \n    1.92 \n    1.91 \n    1.89 \n    1.88 \n    1.87 \n    1.85 \n  \n  \n    40 \n    4.08 \n    3.23 \n    2.84 \n    2.61 \n    2.45 \n    2.34 \n    2.25 \n    2.18 \n    2.12 \n    2.08 \n    2.04 \n    2.00 \n    1.97 \n    1.95 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.85 \n    1.84 \n    1.83 \n    1.81 \n  \n  \n    45 \n    4.06 \n    3.20 \n    2.81 \n    2.58 \n    2.42 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.05 \n    2.01 \n    1.97 \n    1.94 \n    1.92 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.82 \n    1.81 \n    1.80 \n    1.78 \n  \n  \n    50 \n    4.03 \n    3.18 \n    2.79 \n    2.56 \n    2.40 \n    2.29 \n    2.20 \n    2.13 \n    2.07 \n    2.03 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    60 \n    4.00 \n    3.15 \n    2.76 \n    2.53 \n    2.37 \n    2.25 \n    2.17 \n    2.10 \n    2.04 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.86 \n    1.84 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n  \n  \n    75 \n    3.97 \n    3.12 \n    2.73 \n    2.49 \n    2.34 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.85 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    100 \n    3.94 \n    3.09 \n    2.70 \n    2.46 \n    2.31 \n    2.19 \n    2.10 \n    2.03 \n    1.97 \n    1.93 \n    1.89 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.68 \n    1.66 \n    1.65 \n  \n  \n    120 \n    3.92 \n    3.07 \n    2.68 \n    2.45 \n    2.29 \n    2.18 \n    2.09 \n    2.02 \n    1.96 \n    1.91 \n    1.87 \n    1.83 \n    1.80 \n    1.78 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.67 \n    1.66 \n    1.64 \n    1.63 \n  \n  \n    140 \n    3.91 \n    3.06 \n    2.67 \n    2.44 \n    2.28 \n    2.16 \n    2.08 \n    2.01 \n    1.95 \n    1.90 \n    1.86 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.62 \n  \n  \n    180 \n    3.89 \n    3.05 \n    2.65 \n    2.42 \n    2.26 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.88 \n    1.84 \n    1.81 \n    1.77 \n    1.75 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n  \n  \n    250 \n    3.88 \n    3.03 \n    2.64 \n    2.41 \n    2.25 \n    2.13 \n    2.05 \n    1.98 \n    1.92 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.73 \n    1.71 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n  \n  \n    400 \n    3.86 \n    3.02 \n    2.63 \n    2.39 \n    2.24 \n    2.12 \n    2.03 \n    1.96 \n    1.90 \n    1.85 \n    1.81 \n    1.78 \n    1.74 \n    1.72 \n    1.69 \n    1.67 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n  \n  \n    1000 \n    3.85 \n    3.00 \n    2.61 \n    2.38 \n    2.22 \n    2.11 \n    2.02 \n    1.95 \n    1.89 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n  \n\n\n\n\n\n\n\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    39.86 \n    49.50 \n    53.59 \n    55.83 \n    57.24 \n    58.20 \n    58.91 \n    59.44 \n    59.86 \n    60.19 \n    60.47 \n    60.71 \n    60.90 \n    61.07 \n    61.22 \n    61.35 \n    61.46 \n    61.57 \n    61.66 \n    61.74 \n    61.81 \n    61.88 \n  \n  \n    2 \n    8.53 \n    9.00 \n    9.16 \n    9.24 \n    9.29 \n    9.33 \n    9.35 \n    9.37 \n    9.38 \n    9.39 \n    9.40 \n    9.41 \n    9.41 \n    9.42 \n    9.42 \n    9.43 \n    9.43 \n    9.44 \n    9.44 \n    9.44 \n    9.44 \n    9.45 \n  \n  \n    3 \n    5.54 \n    5.46 \n    5.39 \n    5.34 \n    5.31 \n    5.28 \n    5.27 \n    5.25 \n    5.24 \n    5.23 \n    5.22 \n    5.22 \n    5.21 \n    5.20 \n    5.20 \n    5.20 \n    5.19 \n    5.19 \n    5.19 \n    5.18 \n    5.18 \n    5.18 \n  \n  \n    4 \n    4.54 \n    4.32 \n    4.19 \n    4.11 \n    4.05 \n    4.01 \n    3.98 \n    3.95 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.89 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n    3.85 \n    3.85 \n    3.84 \n    3.84 \n    3.84 \n  \n  \n    5 \n    4.06 \n    3.78 \n    3.62 \n    3.52 \n    3.45 \n    3.40 \n    3.37 \n    3.34 \n    3.32 \n    3.30 \n    3.28 \n    3.27 \n    3.26 \n    3.25 \n    3.24 \n    3.23 \n    3.22 \n    3.22 \n    3.21 \n    3.21 \n    3.20 \n    3.20 \n  \n  \n    6 \n    3.78 \n    3.46 \n    3.29 \n    3.18 \n    3.11 \n    3.05 \n    3.01 \n    2.98 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n    2.89 \n    2.88 \n    2.87 \n    2.86 \n    2.85 \n    2.85 \n    2.84 \n    2.84 \n    2.83 \n    2.83 \n  \n  \n    7 \n    3.59 \n    3.26 \n    3.07 \n    2.96 \n    2.88 \n    2.83 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.67 \n    2.65 \n    2.64 \n    2.63 \n    2.62 \n    2.61 \n    2.61 \n    2.60 \n    2.59 \n    2.59 \n    2.58 \n  \n  \n    8 \n    3.46 \n    3.11 \n    2.92 \n    2.81 \n    2.73 \n    2.67 \n    2.62 \n    2.59 \n    2.56 \n    2.54 \n    2.52 \n    2.50 \n    2.49 \n    2.48 \n    2.46 \n    2.45 \n    2.45 \n    2.44 \n    2.43 \n    2.42 \n    2.42 \n    2.41 \n  \n  \n    9 \n    3.36 \n    3.01 \n    2.81 \n    2.69 \n    2.61 \n    2.55 \n    2.51 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n    2.38 \n    2.36 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n    2.30 \n    2.30 \n    2.29 \n    2.29 \n  \n  \n    10 \n    3.29 \n    2.92 \n    2.73 \n    2.61 \n    2.52 \n    2.46 \n    2.41 \n    2.38 \n    2.35 \n    2.32 \n    2.30 \n    2.28 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.22 \n    2.21 \n    2.20 \n    2.19 \n    2.19 \n  \n  \n    11 \n    3.23 \n    2.86 \n    2.66 \n    2.54 \n    2.45 \n    2.39 \n    2.34 \n    2.30 \n    2.27 \n    2.25 \n    2.23 \n    2.21 \n    2.19 \n    2.18 \n    2.17 \n    2.16 \n    2.15 \n    2.14 \n    2.13 \n    2.12 \n    2.12 \n    2.11 \n  \n  \n    12 \n    3.18 \n    2.81 \n    2.61 \n    2.48 \n    2.39 \n    2.33 \n    2.28 \n    2.24 \n    2.21 \n    2.19 \n    2.17 \n    2.15 \n    2.13 \n    2.12 \n    2.10 \n    2.09 \n    2.08 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n    2.05 \n  \n  \n    13 \n    3.14 \n    2.76 \n    2.56 \n    2.43 \n    2.35 \n    2.28 \n    2.23 \n    2.20 \n    2.16 \n    2.14 \n    2.12 \n    2.10 \n    2.08 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.02 \n    2.01 \n    2.01 \n    2.00 \n    1.99 \n  \n  \n    14 \n    3.10 \n    2.73 \n    2.52 \n    2.39 \n    2.31 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.10 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n    1.96 \n    1.96 \n    1.95 \n  \n  \n    15 \n    3.07 \n    2.70 \n    2.49 \n    2.36 \n    2.27 \n    2.21 \n    2.16 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.92 \n    1.91 \n  \n  \n    16 \n    3.05 \n    2.67 \n    2.46 \n    2.33 \n    2.24 \n    2.18 \n    2.13 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.88 \n  \n  \n    17 \n    3.03 \n    2.64 \n    2.44 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.06 \n    2.03 \n    2.00 \n    1.98 \n    1.96 \n    1.94 \n    1.93 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.87 \n    1.86 \n    1.86 \n    1.85 \n  \n  \n    18 \n    3.01 \n    2.62 \n    2.42 \n    2.29 \n    2.20 \n    2.13 \n    2.08 \n    2.04 \n    2.00 \n    1.98 \n    1.95 \n    1.93 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.86 \n    1.85 \n    1.84 \n    1.84 \n    1.83 \n    1.82 \n  \n  \n    19 \n    2.99 \n    2.61 \n    2.40 \n    2.27 \n    2.18 \n    2.11 \n    2.06 \n    2.02 \n    1.98 \n    1.96 \n    1.93 \n    1.91 \n    1.89 \n    1.88 \n    1.86 \n    1.85 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.81 \n    1.80 \n  \n  \n    20 \n    2.97 \n    2.59 \n    2.38 \n    2.25 \n    2.16 \n    2.09 \n    2.04 \n    2.00 \n    1.96 \n    1.94 \n    1.91 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.80 \n    1.79 \n    1.79 \n    1.78 \n  \n  \n    21 \n    2.96 \n    2.57 \n    2.36 \n    2.23 \n    2.14 \n    2.08 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    22 \n    2.95 \n    2.56 \n    2.35 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.97 \n    1.93 \n    1.90 \n    1.88 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n  \n  \n    23 \n    2.94 \n    2.55 \n    2.34 \n    2.21 \n    2.11 \n    2.05 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.74 \n    1.73 \n  \n  \n    24 \n    2.93 \n    2.54 \n    2.33 \n    2.19 \n    2.10 \n    2.04 \n    1.98 \n    1.94 \n    1.91 \n    1.88 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n  \n  \n    25 \n    2.92 \n    2.53 \n    2.32 \n    2.18 \n    2.09 \n    2.02 \n    1.97 \n    1.93 \n    1.89 \n    1.87 \n    1.84 \n    1.82 \n    1.80 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n    1.70 \n  \n  \n    26 \n    2.91 \n    2.52 \n    2.31 \n    2.17 \n    2.08 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.86 \n    1.83 \n    1.81 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    27 \n    2.90 \n    2.51 \n    2.30 \n    2.17 \n    2.07 \n    2.00 \n    1.95 \n    1.91 \n    1.87 \n    1.85 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.70 \n    1.69 \n    1.68 \n  \n  \n    28 \n    2.89 \n    2.50 \n    2.29 \n    2.16 \n    2.06 \n    2.00 \n    1.94 \n    1.90 \n    1.87 \n    1.84 \n    1.81 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n    1.69 \n    1.68 \n    1.67 \n  \n  \n    29 \n    2.89 \n    2.50 \n    2.28 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.89 \n    1.86 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.69 \n    1.68 \n    1.68 \n    1.67 \n    1.66 \n  \n  \n    30 \n    2.88 \n    2.49 \n    2.28 \n    2.14 \n    2.05 \n    1.98 \n    1.93 \n    1.88 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.69 \n    1.68 \n    1.67 \n    1.66 \n    1.65 \n  \n  \n    35 \n    2.85 \n    2.46 \n    2.25 \n    2.11 \n    2.02 \n    1.95 \n    1.90 \n    1.85 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.69 \n    1.67 \n    1.66 \n    1.65 \n    1.64 \n    1.63 \n    1.62 \n    1.62 \n  \n  \n    40 \n    2.84 \n    2.44 \n    2.23 \n    2.09 \n    2.00 \n    1.93 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.74 \n    1.71 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.64 \n    1.62 \n    1.61 \n    1.61 \n    1.60 \n    1.59 \n  \n  \n    45 \n    2.82 \n    2.42 \n    2.21 \n    2.07 \n    1.98 \n    1.91 \n    1.85 \n    1.81 \n    1.77 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.58 \n    1.57 \n  \n  \n    50 \n    2.81 \n    2.41 \n    2.20 \n    2.06 \n    1.97 \n    1.90 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n    1.59 \n    1.58 \n    1.57 \n    1.56 \n    1.55 \n  \n  \n    60 \n    2.79 \n    2.39 \n    2.18 \n    2.04 \n    1.95 \n    1.87 \n    1.82 \n    1.77 \n    1.74 \n    1.71 \n    1.68 \n    1.66 \n    1.64 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.56 \n    1.55 \n    1.54 \n    1.53 \n    1.53 \n  \n  \n    75 \n    2.77 \n    2.37 \n    2.16 \n    2.02 \n    1.93 \n    1.85 \n    1.80 \n    1.75 \n    1.72 \n    1.69 \n    1.66 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n    1.54 \n    1.53 \n    1.52 \n    1.51 \n    1.50 \n  \n  \n    100 \n    2.76 \n    2.36 \n    2.14 \n    2.00 \n    1.91 \n    1.83 \n    1.78 \n    1.73 \n    1.69 \n    1.66 \n    1.64 \n    1.61 \n    1.59 \n    1.57 \n    1.56 \n    1.54 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.48 \n  \n  \n    120 \n    2.75 \n    2.35 \n    2.13 \n    1.99 \n    1.90 \n    1.82 \n    1.77 \n    1.72 \n    1.68 \n    1.65 \n    1.63 \n    1.60 \n    1.58 \n    1.56 \n    1.55 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.47 \n    1.46 \n  \n  \n    140 \n    2.74 \n    2.34 \n    2.12 \n    1.99 \n    1.89 \n    1.82 \n    1.76 \n    1.71 \n    1.68 \n    1.64 \n    1.62 \n    1.59 \n    1.57 \n    1.55 \n    1.54 \n    1.52 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n  \n  \n    180 \n    2.73 \n    2.33 \n    2.11 \n    1.98 \n    1.88 \n    1.81 \n    1.75 \n    1.70 \n    1.67 \n    1.63 \n    1.61 \n    1.58 \n    1.56 \n    1.54 \n    1.53 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n  \n  \n    250 \n    2.73 \n    2.32 \n    2.11 \n    1.97 \n    1.87 \n    1.80 \n    1.74 \n    1.69 \n    1.66 \n    1.62 \n    1.60 \n    1.57 \n    1.55 \n    1.53 \n    1.51 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n  \n  \n    400 \n    2.72 \n    2.32 \n    2.10 \n    1.96 \n    1.86 \n    1.79 \n    1.73 \n    1.69 \n    1.65 \n    1.61 \n    1.59 \n    1.56 \n    1.54 \n    1.52 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n  \n  \n    1000 \n    2.71 \n    2.31 \n    2.09 \n    1.95 \n    1.85 \n    1.78 \n    1.72 \n    1.68 \n    1.64 \n    1.61 \n    1.58 \n    1.55 \n    1.53 \n    1.51 \n    1.49 \n    1.48 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n    1.41"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#normalf√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#normalf√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Normalf√∂rdelning",
    "text": "Normalf√∂rdelning\nTabellen ger sannolikheten \\(\\Phi(z) = P(Z\\leq z)\\) f√∂r olika \\(z\\) d√§r \\(Z\\) √§r standardnormal, \\(Z\\sim N(0,1)\\).\nSannolikheter i den v√§nstra svansen f√•s genom symmetri: \\(P(Z\\leq \\textminus z) = 1-P(Z\\leq z)\\).\n\n\n¬†  ¬† \n\n\nAndra decimalen i \\(z\\)\n\n\n\n\n\n \n  \n      \n    0.00 \n    0.01 \n    0.02 \n    0.03 \n    0.04 \n    0.05 \n    0.06 \n    0.07 \n    0.08 \n    0.09 \n  \n \n\n  \n    0.0 \n    0.5000 \n    0.5040 \n    0.5080 \n    0.5120 \n    0.5160 \n    0.5199 \n    0.5239 \n    0.5279 \n    0.5319 \n    0.5359 \n  \n  \n    0.1 \n    0.5398 \n    0.5438 \n    0.5478 \n    0.5517 \n    0.5557 \n    0.5596 \n    0.5636 \n    0.5675 \n    0.5714 \n    0.5753 \n  \n  \n    0.2 \n    0.5793 \n    0.5832 \n    0.5871 \n    0.5910 \n    0.5948 \n    0.5987 \n    0.6026 \n    0.6064 \n    0.6103 \n    0.6141 \n  \n  \n    0.3 \n    0.6179 \n    0.6217 \n    0.6255 \n    0.6293 \n    0.6331 \n    0.6368 \n    0.6406 \n    0.6443 \n    0.6480 \n    0.6517 \n  \n  \n    0.4 \n    0.6554 \n    0.6591 \n    0.6628 \n    0.6664 \n    0.6700 \n    0.6736 \n    0.6772 \n    0.6808 \n    0.6844 \n    0.6879 \n  \n  \n    0.5 \n    0.6915 \n    0.6950 \n    0.6985 \n    0.7019 \n    0.7054 \n    0.7088 \n    0.7123 \n    0.7157 \n    0.7190 \n    0.7224 \n  \n  \n    0.6 \n    0.7257 \n    0.7291 \n    0.7324 \n    0.7357 \n    0.7389 \n    0.7422 \n    0.7454 \n    0.7486 \n    0.7517 \n    0.7549 \n  \n  \n    0.7 \n    0.7580 \n    0.7611 \n    0.7642 \n    0.7673 \n    0.7704 \n    0.7734 \n    0.7764 \n    0.7794 \n    0.7823 \n    0.7852 \n  \n  \n    0.8 \n    0.7881 \n    0.7910 \n    0.7939 \n    0.7967 \n    0.7995 \n    0.8023 \n    0.8051 \n    0.8078 \n    0.8106 \n    0.8133 \n  \n  \n    0.9 \n    0.8159 \n    0.8186 \n    0.8212 \n    0.8238 \n    0.8264 \n    0.8289 \n    0.8315 \n    0.8340 \n    0.8365 \n    0.8389 \n  \n  \n    1.0 \n    0.8413 \n    0.8438 \n    0.8461 \n    0.8485 \n    0.8508 \n    0.8531 \n    0.8554 \n    0.8577 \n    0.8599 \n    0.8621 \n  \n  \n    1.1 \n    0.8643 \n    0.8665 \n    0.8686 \n    0.8708 \n    0.8729 \n    0.8749 \n    0.8770 \n    0.8790 \n    0.8810 \n    0.8830 \n  \n  \n    1.2 \n    0.8849 \n    0.8869 \n    0.8888 \n    0.8907 \n    0.8925 \n    0.8944 \n    0.8962 \n    0.8980 \n    0.8997 \n    0.9015 \n  \n  \n    1.3 \n    0.9032 \n    0.9049 \n    0.9066 \n    0.9082 \n    0.9099 \n    0.9115 \n    0.9131 \n    0.9147 \n    0.9162 \n    0.9177 \n  \n  \n    1.4 \n    0.9192 \n    0.9207 \n    0.9222 \n    0.9236 \n    0.9251 \n    0.9265 \n    0.9279 \n    0.9292 \n    0.9306 \n    0.9319 \n  \n  \n    1.5 \n    0.9332 \n    0.9345 \n    0.9357 \n    0.9370 \n    0.9382 \n    0.9394 \n    0.9406 \n    0.9418 \n    0.9429 \n    0.9441 \n  \n  \n    1.6 \n    0.9452 \n    0.9463 \n    0.9474 \n    0.9484 \n    0.9495 \n    0.9505 \n    0.9515 \n    0.9525 \n    0.9535 \n    0.9545 \n  \n  \n    1.7 \n    0.9554 \n    0.9564 \n    0.9573 \n    0.9582 \n    0.9591 \n    0.9599 \n    0.9608 \n    0.9616 \n    0.9625 \n    0.9633 \n  \n  \n    1.8 \n    0.9641 \n    0.9649 \n    0.9656 \n    0.9664 \n    0.9671 \n    0.9678 \n    0.9686 \n    0.9693 \n    0.9699 \n    0.9706 \n  \n  \n    1.9 \n    0.9713 \n    0.9719 \n    0.9726 \n    0.9732 \n    0.9738 \n    0.9744 \n    0.9750 \n    0.9756 \n    0.9761 \n    0.9767 \n  \n  \n    2.0 \n    0.9772 \n    0.9778 \n    0.9783 \n    0.9788 \n    0.9793 \n    0.9798 \n    0.9803 \n    0.9808 \n    0.9812 \n    0.9817 \n  \n  \n    2.1 \n    0.9821 \n    0.9826 \n    0.9830 \n    0.9834 \n    0.9838 \n    0.9842 \n    0.9846 \n    0.9850 \n    0.9854 \n    0.9857 \n  \n  \n    2.2 \n    0.9861 \n    0.9864 \n    0.9868 \n    0.9871 \n    0.9875 \n    0.9878 \n    0.9881 \n    0.9884 \n    0.9887 \n    0.9890 \n  \n  \n    2.3 \n    0.9893 \n    0.9896 \n    0.9898 \n    0.9901 \n    0.9904 \n    0.9906 \n    0.9909 \n    0.9911 \n    0.9913 \n    0.9916 \n  \n  \n    2.4 \n    0.9918 \n    0.9920 \n    0.9922 \n    0.9925 \n    0.9927 \n    0.9929 \n    0.9931 \n    0.9932 \n    0.9934 \n    0.9936 \n  \n  \n    2.5 \n    0.9938 \n    0.9940 \n    0.9941 \n    0.9943 \n    0.9945 \n    0.9946 \n    0.9948 \n    0.9949 \n    0.9951 \n    0.9952 \n  \n  \n    2.6 \n    0.9953 \n    0.9955 \n    0.9956 \n    0.9957 \n    0.9959 \n    0.9960 \n    0.9961 \n    0.9962 \n    0.9963 \n    0.9964 \n  \n  \n    2.7 \n    0.9965 \n    0.9966 \n    0.9967 \n    0.9968 \n    0.9969 \n    0.9970 \n    0.9971 \n    0.9972 \n    0.9973 \n    0.9974 \n  \n  \n    2.8 \n    0.9974 \n    0.9975 \n    0.9976 \n    0.9977 \n    0.9977 \n    0.9978 \n    0.9979 \n    0.9979 \n    0.9980 \n    0.9981 \n  \n  \n    2.9 \n    0.9981 \n    0.9982 \n    0.9982 \n    0.9983 \n    0.9984 \n    0.9984 \n    0.9985 \n    0.9985 \n    0.9986 \n    0.9986"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#student-t-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#student-t-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Student-\\(t\\) f√∂rdelning",
    "text": "Student-\\(t\\) f√∂rdelning\n\n\n¬†  ¬†¬† \n\n\n\n\n\n\n\nKonfidensniv√•: \n 80%\n 90%\n 95%\n 98%\n 99%\n\n\nTv√•sidig sannolikhet: \n0.200\n0.100\n0.050\n0.020\n0.010\n\n\nEnsidig sannolikhet: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    3.078 \n    6.314 \n    12.706 \n    31.821 \n    63.657 \n  \n  \n    2 \n    1.886 \n    2.920 \n    4.303 \n    6.965 \n    9.925 \n  \n  \n    3 \n    1.638 \n    2.353 \n    3.182 \n    4.541 \n    5.841 \n  \n  \n    4 \n    1.533 \n    2.132 \n    2.776 \n    3.747 \n    4.604 \n  \n  \n    5 \n    1.476 \n    2.015 \n    2.571 \n    3.365 \n    4.032 \n  \n  \n    6 \n    1.440 \n    1.943 \n    2.447 \n    3.143 \n    3.707 \n  \n  \n    7 \n    1.415 \n    1.895 \n    2.365 \n    2.998 \n    3.499 \n  \n  \n    8 \n    1.397 \n    1.860 \n    2.306 \n    2.896 \n    3.355 \n  \n  \n    9 \n    1.383 \n    1.833 \n    2.262 \n    2.821 \n    3.250 \n  \n  \n    10 \n    1.372 \n    1.812 \n    2.228 \n    2.764 \n    3.169 \n  \n  \n    11 \n    1.363 \n    1.796 \n    2.201 \n    2.718 \n    3.106 \n  \n  \n    12 \n    1.356 \n    1.782 \n    2.179 \n    2.681 \n    3.055 \n  \n  \n    13 \n    1.350 \n    1.771 \n    2.160 \n    2.650 \n    3.012 \n  \n  \n    14 \n    1.345 \n    1.761 \n    2.145 \n    2.624 \n    2.977 \n  \n  \n    15 \n    1.341 \n    1.753 \n    2.131 \n    2.602 \n    2.947 \n  \n  \n    16 \n    1.337 \n    1.746 \n    2.120 \n    2.583 \n    2.921 \n  \n  \n    17 \n    1.333 \n    1.740 \n    2.110 \n    2.567 \n    2.898 \n  \n  \n    18 \n    1.330 \n    1.734 \n    2.101 \n    2.552 \n    2.878 \n  \n  \n    19 \n    1.328 \n    1.729 \n    2.093 \n    2.539 \n    2.861 \n  \n  \n    20 \n    1.325 \n    1.725 \n    2.086 \n    2.528 \n    2.845 \n  \n  \n    21 \n    1.323 \n    1.721 \n    2.080 \n    2.518 \n    2.831 \n  \n  \n    22 \n    1.321 \n    1.717 \n    2.074 \n    2.508 \n    2.819 \n  \n  \n    23 \n    1.319 \n    1.714 \n    2.069 \n    2.500 \n    2.807 \n  \n  \n    24 \n    1.318 \n    1.711 \n    2.064 \n    2.492 \n    2.797 \n  \n  \n    25 \n    1.316 \n    1.708 \n    2.060 \n    2.485 \n    2.787 \n  \n  \n    26 \n    1.315 \n    1.706 \n    2.056 \n    2.479 \n    2.779 \n  \n  \n    27 \n    1.314 \n    1.703 \n    2.052 \n    2.473 \n    2.771 \n  \n  \n    28 \n    1.313 \n    1.701 \n    2.048 \n    2.467 \n    2.763 \n  \n  \n    29 \n    1.311 \n    1.699 \n    2.045 \n    2.462 \n    2.756 \n  \n  \n    30 \n    1.310 \n    1.697 \n    2.042 \n    2.457 \n    2.750 \n  \n  \n    32 \n    1.309 \n    1.694 \n    2.037 \n    2.449 \n    2.738 \n  \n  \n    35 \n    1.306 \n    1.690 \n    2.030 \n    2.438 \n    2.724 \n  \n  \n    40 \n    1.303 \n    1.684 \n    2.021 \n    2.423 \n    2.704 \n  \n  \n    45 \n    1.301 \n    1.679 \n    2.014 \n    2.412 \n    2.690 \n  \n  \n    50 \n    1.299 \n    1.676 \n    2.009 \n    2.403 \n    2.678 \n  \n  \n    60 \n    1.296 \n    1.671 \n    2.000 \n    2.390 \n    2.660 \n  \n  \n    75 \n    1.293 \n    1.665 \n    1.992 \n    2.377 \n    2.643 \n  \n  \n    100 \n    1.290 \n    1.660 \n    1.984 \n    2.364 \n    2.626 \n  \n  \n    120 \n    1.289 \n    1.658 \n    1.980 \n    2.358 \n    2.617 \n  \n  \n    140 \n    1.288 \n    1.656 \n    1.977 \n    2.353 \n    2.611 \n  \n  \n    180 \n    1.286 \n    1.653 \n    1.973 \n    2.347 \n    2.603 \n  \n  \n    250 \n    1.285 \n    1.651 \n    1.969 \n    2.341 \n    2.596 \n  \n  \n    400 \n    1.284 \n    1.649 \n    1.966 \n    2.336 \n    2.588 \n  \n  \n    1000 \n    1.282 \n    1.646 \n    1.962 \n    2.330 \n    2.581 \n  \n  \n    o√§ndligt \n    1.282 \n    1.645 \n    1.960 \n    2.326 \n    2.576"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#chi2-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#chi2-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(\\chi^2\\)-f√∂rdelning",
    "text": "\\(\\chi^2\\)-f√∂rdelning\n\n\n¬† \n\n\n\n\n\n\n\nSannolikhet i h√∂ger svans: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    2.706 \n    3.841 \n    5.024 \n    6.635 \n    7.879 \n  \n  \n    2 \n    4.605 \n    5.991 \n    7.378 \n    9.210 \n    10.597 \n  \n  \n    3 \n    6.251 \n    7.815 \n    9.348 \n    11.345 \n    12.838 \n  \n  \n    4 \n    7.779 \n    9.488 \n    11.143 \n    13.277 \n    14.860 \n  \n  \n    5 \n    9.236 \n    11.070 \n    12.833 \n    15.086 \n    16.750 \n  \n  \n    6 \n    10.645 \n    12.592 \n    14.449 \n    16.812 \n    18.548 \n  \n  \n    7 \n    12.017 \n    14.067 \n    16.013 \n    18.475 \n    20.278 \n  \n  \n    8 \n    13.362 \n    15.507 \n    17.535 \n    20.090 \n    21.955 \n  \n  \n    9 \n    14.684 \n    16.919 \n    19.023 \n    21.666 \n    23.589 \n  \n  \n    10 \n    15.987 \n    18.307 \n    20.483 \n    23.209 \n    25.188 \n  \n  \n    11 \n    17.275 \n    19.675 \n    21.920 \n    24.725 \n    26.757 \n  \n  \n    12 \n    18.549 \n    21.026 \n    23.337 \n    26.217 \n    28.300 \n  \n  \n    13 \n    19.812 \n    22.362 \n    24.736 \n    27.688 \n    29.819 \n  \n  \n    14 \n    21.064 \n    23.685 \n    26.119 \n    29.141 \n    31.319 \n  \n  \n    15 \n    22.307 \n    24.996 \n    27.488 \n    30.578 \n    32.801 \n  \n  \n    16 \n    23.542 \n    26.296 \n    28.845 \n    32.000 \n    34.267 \n  \n  \n    17 \n    24.769 \n    27.587 \n    30.191 \n    33.409 \n    35.718 \n  \n  \n    18 \n    25.989 \n    28.869 \n    31.526 \n    34.805 \n    37.156 \n  \n  \n    19 \n    27.204 \n    30.144 \n    32.852 \n    36.191 \n    38.582 \n  \n  \n    20 \n    28.412 \n    31.410 \n    34.170 \n    37.566 \n    39.997 \n  \n  \n    21 \n    29.615 \n    32.671 \n    35.479 \n    38.932 \n    41.401 \n  \n  \n    22 \n    30.813 \n    33.924 \n    36.781 \n    40.289 \n    42.796 \n  \n  \n    23 \n    32.007 \n    35.172 \n    38.076 \n    41.638 \n    44.181 \n  \n  \n    24 \n    33.196 \n    36.415 \n    39.364 \n    42.980 \n    45.559 \n  \n  \n    25 \n    34.382 \n    37.652 \n    40.646 \n    44.314 \n    46.928 \n  \n  \n    26 \n    35.563 \n    38.885 \n    41.923 \n    45.642 \n    48.290 \n  \n  \n    27 \n    36.741 \n    40.113 \n    43.195 \n    46.963 \n    49.645 \n  \n  \n    28 \n    37.916 \n    41.337 \n    44.461 \n    48.278 \n    50.993 \n  \n  \n    29 \n    39.087 \n    42.557 \n    45.722 \n    49.588 \n    52.336 \n  \n  \n    30 \n    40.256 \n    43.773 \n    46.979 \n    50.892 \n    53.672 \n  \n  \n    40 \n    51.805 \n    55.758 \n    59.342 \n    63.691 \n    66.766 \n  \n  \n    50 \n    63.167 \n    67.505 \n    71.420 \n    76.154 \n    79.490 \n  \n  \n    60 \n    74.397 \n    79.082 \n    83.298 \n    88.379 \n    91.952 \n  \n  \n    70 \n    85.527 \n    90.531 \n    95.023 \n    100.425 \n    104.215 \n  \n  \n    80 \n    96.578 \n    101.879 \n    106.629 \n    112.329 \n    116.321 \n  \n  \n    90 \n    107.565 \n    113.145 \n    118.136 \n    124.116 \n    128.299 \n  \n  \n    100 \n    118.498 \n    124.342 \n    129.561 \n    135.807 \n    140.169"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#f-f√∂rdelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#f-f√∂rdelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(F\\)-f√∂rdelning",
    "text": "\\(F\\)-f√∂rdelning\n\n\\(\\alpha = 0.01\\)\\(\\alpha = 0.05\\)\\(\\alpha = 0.10\\)\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    4052.18 \n    4999.50 \n    5403.35 \n    5624.58 \n    5763.65 \n    5858.99 \n    5928.36 \n    5981.07 \n    6022.47 \n    6055.85 \n    6083.32 \n    6106.32 \n    6125.86 \n    6142.67 \n    6157.28 \n    6170.10 \n    6181.43 \n    6191.53 \n    6200.58 \n    6208.73 \n    6216.12 \n    6222.84 \n  \n  \n    2 \n    98.50 \n    99.00 \n    99.17 \n    99.25 \n    99.30 \n    99.33 \n    99.36 \n    99.37 \n    99.39 \n    99.40 \n    99.41 \n    99.42 \n    99.42 \n    99.43 \n    99.43 \n    99.44 \n    99.44 \n    99.44 \n    99.45 \n    99.45 \n    99.45 \n    99.45 \n  \n  \n    3 \n    34.12 \n    30.82 \n    29.46 \n    28.71 \n    28.24 \n    27.91 \n    27.67 \n    27.49 \n    27.35 \n    27.23 \n    27.13 \n    27.05 \n    26.98 \n    26.92 \n    26.87 \n    26.83 \n    26.79 \n    26.75 \n    26.72 \n    26.69 \n    26.66 \n    26.64 \n  \n  \n    4 \n    21.20 \n    18.00 \n    16.69 \n    15.98 \n    15.52 \n    15.21 \n    14.98 \n    14.80 \n    14.66 \n    14.55 \n    14.45 \n    14.37 \n    14.31 \n    14.25 \n    14.20 \n    14.15 \n    14.11 \n    14.08 \n    14.05 \n    14.02 \n    13.99 \n    13.97 \n  \n  \n    5 \n    16.26 \n    13.27 \n    12.06 \n    11.39 \n    10.97 \n    10.67 \n    10.46 \n    10.29 \n    10.16 \n    10.05 \n    9.96 \n    9.89 \n    9.82 \n    9.77 \n    9.72 \n    9.68 \n    9.64 \n    9.61 \n    9.58 \n    9.55 \n    9.53 \n    9.51 \n  \n  \n    6 \n    13.75 \n    10.92 \n    9.78 \n    9.15 \n    8.75 \n    8.47 \n    8.26 \n    8.10 \n    7.98 \n    7.87 \n    7.79 \n    7.72 \n    7.66 \n    7.60 \n    7.56 \n    7.52 \n    7.48 \n    7.45 \n    7.42 \n    7.40 \n    7.37 \n    7.35 \n  \n  \n    7 \n    12.25 \n    9.55 \n    8.45 \n    7.85 \n    7.46 \n    7.19 \n    6.99 \n    6.84 \n    6.72 \n    6.62 \n    6.54 \n    6.47 \n    6.41 \n    6.36 \n    6.31 \n    6.28 \n    6.24 \n    6.21 \n    6.18 \n    6.16 \n    6.13 \n    6.11 \n  \n  \n    8 \n    11.26 \n    8.65 \n    7.59 \n    7.01 \n    6.63 \n    6.37 \n    6.18 \n    6.03 \n    5.91 \n    5.81 \n    5.73 \n    5.67 \n    5.61 \n    5.56 \n    5.52 \n    5.48 \n    5.44 \n    5.41 \n    5.38 \n    5.36 \n    5.34 \n    5.32 \n  \n  \n    9 \n    10.56 \n    8.02 \n    6.99 \n    6.42 \n    6.06 \n    5.80 \n    5.61 \n    5.47 \n    5.35 \n    5.26 \n    5.18 \n    5.11 \n    5.05 \n    5.01 \n    4.96 \n    4.92 \n    4.89 \n    4.86 \n    4.83 \n    4.81 \n    4.79 \n    4.77 \n  \n  \n    10 \n    10.04 \n    7.56 \n    6.55 \n    5.99 \n    5.64 \n    5.39 \n    5.20 \n    5.06 \n    4.94 \n    4.85 \n    4.77 \n    4.71 \n    4.65 \n    4.60 \n    4.56 \n    4.52 \n    4.49 \n    4.46 \n    4.43 \n    4.41 \n    4.38 \n    4.36 \n  \n  \n    11 \n    9.65 \n    7.21 \n    6.22 \n    5.67 \n    5.32 \n    5.07 \n    4.89 \n    4.74 \n    4.63 \n    4.54 \n    4.46 \n    4.40 \n    4.34 \n    4.29 \n    4.25 \n    4.21 \n    4.18 \n    4.15 \n    4.12 \n    4.10 \n    4.08 \n    4.06 \n  \n  \n    12 \n    9.33 \n    6.93 \n    5.95 \n    5.41 \n    5.06 \n    4.82 \n    4.64 \n    4.50 \n    4.39 \n    4.30 \n    4.22 \n    4.16 \n    4.10 \n    4.05 \n    4.01 \n    3.97 \n    3.94 \n    3.91 \n    3.88 \n    3.86 \n    3.84 \n    3.82 \n  \n  \n    13 \n    9.07 \n    6.70 \n    5.74 \n    5.21 \n    4.86 \n    4.62 \n    4.44 \n    4.30 \n    4.19 \n    4.10 \n    4.02 \n    3.96 \n    3.91 \n    3.86 \n    3.82 \n    3.78 \n    3.75 \n    3.72 \n    3.69 \n    3.66 \n    3.64 \n    3.62 \n  \n  \n    14 \n    8.86 \n    6.51 \n    5.56 \n    5.04 \n    4.69 \n    4.46 \n    4.28 \n    4.14 \n    4.03 \n    3.94 \n    3.86 \n    3.80 \n    3.75 \n    3.70 \n    3.66 \n    3.62 \n    3.59 \n    3.56 \n    3.53 \n    3.51 \n    3.48 \n    3.46 \n  \n  \n    15 \n    8.68 \n    6.36 \n    5.42 \n    4.89 \n    4.56 \n    4.32 \n    4.14 \n    4.00 \n    3.89 \n    3.80 \n    3.73 \n    3.67 \n    3.61 \n    3.56 \n    3.52 \n    3.49 \n    3.45 \n    3.42 \n    3.40 \n    3.37 \n    3.35 \n    3.33 \n  \n  \n    16 \n    8.53 \n    6.23 \n    5.29 \n    4.77 \n    4.44 \n    4.20 \n    4.03 \n    3.89 \n    3.78 \n    3.69 \n    3.62 \n    3.55 \n    3.50 \n    3.45 \n    3.41 \n    3.37 \n    3.34 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n  \n  \n    17 \n    8.40 \n    6.11 \n    5.18 \n    4.67 \n    4.34 \n    4.10 \n    3.93 \n    3.79 \n    3.68 \n    3.59 \n    3.52 \n    3.46 \n    3.40 \n    3.35 \n    3.31 \n    3.27 \n    3.24 \n    3.21 \n    3.19 \n    3.16 \n    3.14 \n    3.12 \n  \n  \n    18 \n    8.29 \n    6.01 \n    5.09 \n    4.58 \n    4.25 \n    4.01 \n    3.84 \n    3.71 \n    3.60 \n    3.51 \n    3.43 \n    3.37 \n    3.32 \n    3.27 \n    3.23 \n    3.19 \n    3.16 \n    3.13 \n    3.10 \n    3.08 \n    3.05 \n    3.03 \n  \n  \n    19 \n    8.18 \n    5.93 \n    5.01 \n    4.50 \n    4.17 \n    3.94 \n    3.77 \n    3.63 \n    3.52 \n    3.43 \n    3.36 \n    3.30 \n    3.24 \n    3.19 \n    3.15 \n    3.12 \n    3.08 \n    3.05 \n    3.03 \n    3.00 \n    2.98 \n    2.96 \n  \n  \n    20 \n    8.10 \n    5.85 \n    4.94 \n    4.43 \n    4.10 \n    3.87 \n    3.70 \n    3.56 \n    3.46 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.13 \n    3.09 \n    3.05 \n    3.02 \n    2.99 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n  \n  \n    21 \n    8.02 \n    5.78 \n    4.87 \n    4.37 \n    4.04 \n    3.81 \n    3.64 \n    3.51 \n    3.40 \n    3.31 \n    3.24 \n    3.17 \n    3.12 \n    3.07 \n    3.03 \n    2.99 \n    2.96 \n    2.93 \n    2.90 \n    2.88 \n    2.86 \n    2.84 \n  \n  \n    22 \n    7.95 \n    5.72 \n    4.82 \n    4.31 \n    3.99 \n    3.76 \n    3.59 \n    3.45 \n    3.35 \n    3.26 \n    3.18 \n    3.12 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.88 \n    2.85 \n    2.83 \n    2.81 \n    2.78 \n  \n  \n    23 \n    7.88 \n    5.66 \n    4.76 \n    4.26 \n    3.94 \n    3.71 \n    3.54 \n    3.41 \n    3.30 \n    3.21 \n    3.14 \n    3.07 \n    3.02 \n    2.97 \n    2.93 \n    2.89 \n    2.86 \n    2.83 \n    2.80 \n    2.78 \n    2.76 \n    2.74 \n  \n  \n    24 \n    7.82 \n    5.61 \n    4.72 \n    4.22 \n    3.90 \n    3.67 \n    3.50 \n    3.36 \n    3.26 \n    3.17 \n    3.09 \n    3.03 \n    2.98 \n    2.93 \n    2.89 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n  \n  \n    25 \n    7.77 \n    5.57 \n    4.68 \n    4.18 \n    3.85 \n    3.63 \n    3.46 \n    3.32 \n    3.22 \n    3.13 \n    3.06 \n    2.99 \n    2.94 \n    2.89 \n    2.85 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.66 \n  \n  \n    26 \n    7.72 \n    5.53 \n    4.64 \n    4.14 \n    3.82 \n    3.59 \n    3.42 \n    3.29 \n    3.18 \n    3.09 \n    3.02 \n    2.96 \n    2.90 \n    2.86 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n  \n  \n    27 \n    7.68 \n    5.49 \n    4.60 \n    4.11 \n    3.78 \n    3.56 \n    3.39 \n    3.26 \n    3.15 \n    3.06 \n    2.99 \n    2.93 \n    2.87 \n    2.82 \n    2.78 \n    2.75 \n    2.71 \n    2.68 \n    2.66 \n    2.63 \n    2.61 \n    2.59 \n  \n  \n    28 \n    7.64 \n    5.45 \n    4.57 \n    4.07 \n    3.75 \n    3.53 \n    3.36 \n    3.23 \n    3.12 \n    3.03 \n    2.96 \n    2.90 \n    2.84 \n    2.79 \n    2.75 \n    2.72 \n    2.68 \n    2.65 \n    2.63 \n    2.60 \n    2.58 \n    2.56 \n  \n  \n    29 \n    7.60 \n    5.42 \n    4.54 \n    4.04 \n    3.73 \n    3.50 \n    3.33 \n    3.20 \n    3.09 \n    3.00 \n    2.93 \n    2.87 \n    2.81 \n    2.77 \n    2.73 \n    2.69 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n  \n  \n    30 \n    7.56 \n    5.39 \n    4.51 \n    4.02 \n    3.70 \n    3.47 \n    3.30 \n    3.17 \n    3.07 \n    2.98 \n    2.91 \n    2.84 \n    2.79 \n    2.74 \n    2.70 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n    2.51 \n  \n  \n    35 \n    7.42 \n    5.27 \n    4.40 \n    3.91 \n    3.59 \n    3.37 \n    3.20 \n    3.07 \n    2.96 \n    2.88 \n    2.80 \n    2.74 \n    2.69 \n    2.64 \n    2.60 \n    2.56 \n    2.53 \n    2.50 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n  \n  \n    40 \n    7.31 \n    5.18 \n    4.31 \n    3.83 \n    3.51 \n    3.29 \n    3.12 \n    2.99 \n    2.89 \n    2.80 \n    2.73 \n    2.66 \n    2.61 \n    2.56 \n    2.52 \n    2.48 \n    2.45 \n    2.42 \n    2.39 \n    2.37 \n    2.35 \n    2.33 \n  \n  \n    45 \n    7.23 \n    5.11 \n    4.25 \n    3.77 \n    3.45 \n    3.23 \n    3.07 \n    2.94 \n    2.83 \n    2.74 \n    2.67 \n    2.61 \n    2.55 \n    2.51 \n    2.46 \n    2.43 \n    2.39 \n    2.36 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n  \n  \n    50 \n    7.17 \n    5.06 \n    4.20 \n    3.72 \n    3.41 \n    3.19 \n    3.02 \n    2.89 \n    2.78 \n    2.70 \n    2.63 \n    2.56 \n    2.51 \n    2.46 \n    2.42 \n    2.38 \n    2.35 \n    2.32 \n    2.29 \n    2.27 \n    2.24 \n    2.22 \n  \n  \n    60 \n    7.08 \n    4.98 \n    4.13 \n    3.65 \n    3.34 \n    3.12 \n    2.95 \n    2.82 \n    2.72 \n    2.63 \n    2.56 \n    2.50 \n    2.44 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.17 \n    2.15 \n  \n  \n    75 \n    6.99 \n    4.90 \n    4.05 \n    3.58 \n    3.27 \n    3.05 \n    2.89 \n    2.76 \n    2.65 \n    2.57 \n    2.49 \n    2.43 \n    2.38 \n    2.33 \n    2.29 \n    2.25 \n    2.22 \n    2.18 \n    2.16 \n    2.13 \n    2.11 \n    2.09 \n  \n  \n    100 \n    6.90 \n    4.82 \n    3.98 \n    3.51 \n    3.21 \n    2.99 \n    2.82 \n    2.69 \n    2.59 \n    2.50 \n    2.43 \n    2.37 \n    2.31 \n    2.27 \n    2.22 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.04 \n    2.02 \n  \n  \n    120 \n    6.85 \n    4.79 \n    3.95 \n    3.48 \n    3.17 \n    2.96 \n    2.79 \n    2.66 \n    2.56 \n    2.47 \n    2.40 \n    2.34 \n    2.28 \n    2.23 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n  \n  \n    140 \n    6.82 \n    4.76 \n    3.92 \n    3.46 \n    3.15 \n    2.93 \n    2.77 \n    2.64 \n    2.54 \n    2.45 \n    2.38 \n    2.31 \n    2.26 \n    2.21 \n    2.17 \n    2.13 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.97 \n  \n  \n    180 \n    6.78 \n    4.73 \n    3.89 \n    3.43 \n    3.12 \n    2.90 \n    2.74 \n    2.61 \n    2.51 \n    2.42 \n    2.35 \n    2.28 \n    2.23 \n    2.18 \n    2.14 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.96 \n    1.94 \n  \n  \n    250 \n    6.74 \n    4.69 \n    3.86 \n    3.40 \n    3.09 \n    2.87 \n    2.71 \n    2.58 \n    2.48 \n    2.39 \n    2.32 \n    2.26 \n    2.20 \n    2.15 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.95 \n    1.93 \n    1.91 \n  \n  \n    400 \n    6.70 \n    4.66 \n    3.83 \n    3.37 \n    3.06 \n    2.85 \n    2.68 \n    2.56 \n    2.45 \n    2.37 \n    2.29 \n    2.23 \n    2.17 \n    2.13 \n    2.08 \n    2.05 \n    2.01 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.88 \n  \n  \n    1000 \n    6.66 \n    4.63 \n    3.80 \n    3.34 \n    3.04 \n    2.82 \n    2.66 \n    2.53 \n    2.43 \n    2.34 \n    2.27 \n    2.20 \n    2.15 \n    2.10 \n    2.06 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.85 \n  \n\n\n\n\n\n\n\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    161.45 \n    199.50 \n    215.71 \n    224.58 \n    230.16 \n    233.99 \n    236.77 \n    238.88 \n    240.54 \n    241.88 \n    242.98 \n    243.91 \n    244.69 \n    245.36 \n    245.95 \n    246.46 \n    246.92 \n    247.32 \n    247.69 \n    248.01 \n    248.31 \n    248.58 \n  \n  \n    2 \n    18.51 \n    19.00 \n    19.16 \n    19.25 \n    19.30 \n    19.33 \n    19.35 \n    19.37 \n    19.38 \n    19.40 \n    19.40 \n    19.41 \n    19.42 \n    19.42 \n    19.43 \n    19.43 \n    19.44 \n    19.44 \n    19.44 \n    19.45 \n    19.45 \n    19.45 \n  \n  \n    3 \n    10.13 \n    9.55 \n    9.28 \n    9.12 \n    9.01 \n    8.94 \n    8.89 \n    8.85 \n    8.81 \n    8.79 \n    8.76 \n    8.74 \n    8.73 \n    8.71 \n    8.70 \n    8.69 \n    8.68 \n    8.67 \n    8.67 \n    8.66 \n    8.65 \n    8.65 \n  \n  \n    4 \n    7.71 \n    6.94 \n    6.59 \n    6.39 \n    6.26 \n    6.16 \n    6.09 \n    6.04 \n    6.00 \n    5.96 \n    5.94 \n    5.91 \n    5.89 \n    5.87 \n    5.86 \n    5.84 \n    5.83 \n    5.82 \n    5.81 \n    5.80 \n    5.79 \n    5.79 \n  \n  \n    5 \n    6.61 \n    5.79 \n    5.41 \n    5.19 \n    5.05 \n    4.95 \n    4.88 \n    4.82 \n    4.77 \n    4.74 \n    4.70 \n    4.68 \n    4.66 \n    4.64 \n    4.62 \n    4.60 \n    4.59 \n    4.58 \n    4.57 \n    4.56 \n    4.55 \n    4.54 \n  \n  \n    6 \n    5.99 \n    5.14 \n    4.76 \n    4.53 \n    4.39 \n    4.28 \n    4.21 \n    4.15 \n    4.10 \n    4.06 \n    4.03 \n    4.00 \n    3.98 \n    3.96 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n  \n  \n    7 \n    5.59 \n    4.74 \n    4.35 \n    4.12 \n    3.97 \n    3.87 \n    3.79 \n    3.73 \n    3.68 \n    3.64 \n    3.60 \n    3.57 \n    3.55 \n    3.53 \n    3.51 \n    3.49 \n    3.48 \n    3.47 \n    3.46 \n    3.44 \n    3.43 \n    3.43 \n  \n  \n    8 \n    5.32 \n    4.46 \n    4.07 \n    3.84 \n    3.69 \n    3.58 \n    3.50 \n    3.44 \n    3.39 \n    3.35 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n    3.20 \n    3.19 \n    3.17 \n    3.16 \n    3.15 \n    3.14 \n    3.13 \n  \n  \n    9 \n    5.12 \n    4.26 \n    3.86 \n    3.63 \n    3.48 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.14 \n    3.10 \n    3.07 \n    3.05 \n    3.03 \n    3.01 \n    2.99 \n    2.97 \n    2.96 \n    2.95 \n    2.94 \n    2.93 \n    2.92 \n  \n  \n    10 \n    4.96 \n    4.10 \n    3.71 \n    3.48 \n    3.33 \n    3.22 \n    3.14 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.89 \n    2.86 \n    2.85 \n    2.83 \n    2.81 \n    2.80 \n    2.79 \n    2.77 \n    2.76 \n    2.75 \n  \n  \n    11 \n    4.84 \n    3.98 \n    3.59 \n    3.36 \n    3.20 \n    3.09 \n    3.01 \n    2.95 \n    2.90 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n    2.69 \n    2.67 \n    2.66 \n    2.65 \n    2.64 \n    2.63 \n  \n  \n    12 \n    4.75 \n    3.89 \n    3.49 \n    3.26 \n    3.11 \n    3.00 \n    2.91 \n    2.85 \n    2.80 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n    2.60 \n    2.58 \n    2.57 \n    2.56 \n    2.54 \n    2.53 \n    2.52 \n  \n  \n    13 \n    4.67 \n    3.81 \n    3.41 \n    3.18 \n    3.03 \n    2.92 \n    2.83 \n    2.77 \n    2.71 \n    2.67 \n    2.63 \n    2.60 \n    2.58 \n    2.55 \n    2.53 \n    2.51 \n    2.50 \n    2.48 \n    2.47 \n    2.46 \n    2.45 \n    2.44 \n  \n  \n    14 \n    4.60 \n    3.74 \n    3.34 \n    3.11 \n    2.96 \n    2.85 \n    2.76 \n    2.70 \n    2.65 \n    2.60 \n    2.57 \n    2.53 \n    2.51 \n    2.48 \n    2.46 \n    2.44 \n    2.43 \n    2.41 \n    2.40 \n    2.39 \n    2.38 \n    2.37 \n  \n  \n    15 \n    4.54 \n    3.68 \n    3.29 \n    3.06 \n    2.90 \n    2.79 \n    2.71 \n    2.64 \n    2.59 \n    2.54 \n    2.51 \n    2.48 \n    2.45 \n    2.42 \n    2.40 \n    2.38 \n    2.37 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n  \n  \n    16 \n    4.49 \n    3.63 \n    3.24 \n    3.01 \n    2.85 \n    2.74 \n    2.66 \n    2.59 \n    2.54 \n    2.49 \n    2.46 \n    2.42 \n    2.40 \n    2.37 \n    2.35 \n    2.33 \n    2.32 \n    2.30 \n    2.29 \n    2.28 \n    2.26 \n    2.25 \n  \n  \n    17 \n    4.45 \n    3.59 \n    3.20 \n    2.96 \n    2.81 \n    2.70 \n    2.61 \n    2.55 \n    2.49 \n    2.45 \n    2.41 \n    2.38 \n    2.35 \n    2.33 \n    2.31 \n    2.29 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.21 \n  \n  \n    18 \n    4.41 \n    3.55 \n    3.16 \n    2.93 \n    2.77 \n    2.66 \n    2.58 \n    2.51 \n    2.46 \n    2.41 \n    2.37 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n    2.25 \n    2.23 \n    2.22 \n    2.20 \n    2.19 \n    2.18 \n    2.17 \n  \n  \n    19 \n    4.38 \n    3.52 \n    3.13 \n    2.90 \n    2.74 \n    2.63 \n    2.54 \n    2.48 \n    2.42 \n    2.38 \n    2.34 \n    2.31 \n    2.28 \n    2.26 \n    2.23 \n    2.21 \n    2.20 \n    2.18 \n    2.17 \n    2.16 \n    2.14 \n    2.13 \n  \n  \n    20 \n    4.35 \n    3.49 \n    3.10 \n    2.87 \n    2.71 \n    2.60 \n    2.51 \n    2.45 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.17 \n    2.15 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n  \n  \n    21 \n    4.32 \n    3.47 \n    3.07 \n    2.84 \n    2.68 \n    2.57 \n    2.49 \n    2.42 \n    2.37 \n    2.32 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.16 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n  \n  \n    22 \n    4.30 \n    3.44 \n    3.05 \n    2.82 \n    2.66 \n    2.55 \n    2.46 \n    2.40 \n    2.34 \n    2.30 \n    2.26 \n    2.23 \n    2.20 \n    2.17 \n    2.15 \n    2.13 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n  \n  \n    23 \n    4.28 \n    3.42 \n    3.03 \n    2.80 \n    2.64 \n    2.53 \n    2.44 \n    2.37 \n    2.32 \n    2.27 \n    2.24 \n    2.20 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.08 \n    2.06 \n    2.05 \n    2.04 \n    2.02 \n  \n  \n    24 \n    4.26 \n    3.40 \n    3.01 \n    2.78 \n    2.62 \n    2.51 \n    2.42 \n    2.36 \n    2.30 \n    2.25 \n    2.22 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.01 \n    2.00 \n  \n  \n    25 \n    4.24 \n    3.39 \n    2.99 \n    2.76 \n    2.60 \n    2.49 \n    2.40 \n    2.34 \n    2.28 \n    2.24 \n    2.20 \n    2.16 \n    2.14 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.98 \n  \n  \n    26 \n    4.23 \n    3.37 \n    2.98 \n    2.74 \n    2.59 \n    2.47 \n    2.39 \n    2.32 \n    2.27 \n    2.22 \n    2.18 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.05 \n    2.03 \n    2.02 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n  \n  \n    27 \n    4.21 \n    3.35 \n    2.96 \n    2.73 \n    2.57 \n    2.46 \n    2.37 \n    2.31 \n    2.25 \n    2.20 \n    2.17 \n    2.13 \n    2.10 \n    2.08 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n  \n  \n    28 \n    4.20 \n    3.34 \n    2.95 \n    2.71 \n    2.56 \n    2.45 \n    2.36 \n    2.29 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.93 \n  \n  \n    29 \n    4.18 \n    3.33 \n    2.93 \n    2.70 \n    2.55 \n    2.43 \n    2.35 \n    2.28 \n    2.22 \n    2.18 \n    2.14 \n    2.10 \n    2.08 \n    2.05 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.96 \n    1.94 \n    1.93 \n    1.92 \n  \n  \n    30 \n    4.17 \n    3.32 \n    2.92 \n    2.69 \n    2.53 \n    2.42 \n    2.33 \n    2.27 \n    2.21 \n    2.16 \n    2.13 \n    2.09 \n    2.06 \n    2.04 \n    2.01 \n    1.99 \n    1.98 \n    1.96 \n    1.95 \n    1.93 \n    1.92 \n    1.91 \n  \n  \n    35 \n    4.12 \n    3.27 \n    2.87 \n    2.64 \n    2.49 \n    2.37 \n    2.29 \n    2.22 \n    2.16 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.96 \n    1.94 \n    1.92 \n    1.91 \n    1.89 \n    1.88 \n    1.87 \n    1.85 \n  \n  \n    40 \n    4.08 \n    3.23 \n    2.84 \n    2.61 \n    2.45 \n    2.34 \n    2.25 \n    2.18 \n    2.12 \n    2.08 \n    2.04 \n    2.00 \n    1.97 \n    1.95 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.85 \n    1.84 \n    1.83 \n    1.81 \n  \n  \n    45 \n    4.06 \n    3.20 \n    2.81 \n    2.58 \n    2.42 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.05 \n    2.01 \n    1.97 \n    1.94 \n    1.92 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.82 \n    1.81 \n    1.80 \n    1.78 \n  \n  \n    50 \n    4.03 \n    3.18 \n    2.79 \n    2.56 \n    2.40 \n    2.29 \n    2.20 \n    2.13 \n    2.07 \n    2.03 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    60 \n    4.00 \n    3.15 \n    2.76 \n    2.53 \n    2.37 \n    2.25 \n    2.17 \n    2.10 \n    2.04 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.86 \n    1.84 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n  \n  \n    75 \n    3.97 \n    3.12 \n    2.73 \n    2.49 \n    2.34 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.85 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    100 \n    3.94 \n    3.09 \n    2.70 \n    2.46 \n    2.31 \n    2.19 \n    2.10 \n    2.03 \n    1.97 \n    1.93 \n    1.89 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.68 \n    1.66 \n    1.65 \n  \n  \n    120 \n    3.92 \n    3.07 \n    2.68 \n    2.45 \n    2.29 \n    2.18 \n    2.09 \n    2.02 \n    1.96 \n    1.91 \n    1.87 \n    1.83 \n    1.80 \n    1.78 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.67 \n    1.66 \n    1.64 \n    1.63 \n  \n  \n    140 \n    3.91 \n    3.06 \n    2.67 \n    2.44 \n    2.28 \n    2.16 \n    2.08 \n    2.01 \n    1.95 \n    1.90 \n    1.86 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.62 \n  \n  \n    180 \n    3.89 \n    3.05 \n    2.65 \n    2.42 \n    2.26 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.88 \n    1.84 \n    1.81 \n    1.77 \n    1.75 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n  \n  \n    250 \n    3.88 \n    3.03 \n    2.64 \n    2.41 \n    2.25 \n    2.13 \n    2.05 \n    1.98 \n    1.92 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.73 \n    1.71 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n  \n  \n    400 \n    3.86 \n    3.02 \n    2.63 \n    2.39 \n    2.24 \n    2.12 \n    2.03 \n    1.96 \n    1.90 \n    1.85 \n    1.81 \n    1.78 \n    1.74 \n    1.72 \n    1.69 \n    1.67 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n  \n  \n    1000 \n    3.85 \n    3.00 \n    2.61 \n    2.38 \n    2.22 \n    2.11 \n    2.02 \n    1.95 \n    1.89 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n  \n\n\n\n\n\n\n\n\n\n\n\n¬† \n\nKolumnerna √§r frihetsgraderna i t√§ljaren.\nRaderna √§r frihetsgraderna i n√§mnaren.\n\n\n\n\n \n\n\nFrihetsgrader i t√§ljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    39.86 \n    49.50 \n    53.59 \n    55.83 \n    57.24 \n    58.20 \n    58.91 \n    59.44 \n    59.86 \n    60.19 \n    60.47 \n    60.71 \n    60.90 \n    61.07 \n    61.22 \n    61.35 \n    61.46 \n    61.57 \n    61.66 \n    61.74 \n    61.81 \n    61.88 \n  \n  \n    2 \n    8.53 \n    9.00 \n    9.16 \n    9.24 \n    9.29 \n    9.33 \n    9.35 \n    9.37 \n    9.38 \n    9.39 \n    9.40 \n    9.41 \n    9.41 \n    9.42 \n    9.42 \n    9.43 \n    9.43 \n    9.44 \n    9.44 \n    9.44 \n    9.44 \n    9.45 \n  \n  \n    3 \n    5.54 \n    5.46 \n    5.39 \n    5.34 \n    5.31 \n    5.28 \n    5.27 \n    5.25 \n    5.24 \n    5.23 \n    5.22 \n    5.22 \n    5.21 \n    5.20 \n    5.20 \n    5.20 \n    5.19 \n    5.19 \n    5.19 \n    5.18 \n    5.18 \n    5.18 \n  \n  \n    4 \n    4.54 \n    4.32 \n    4.19 \n    4.11 \n    4.05 \n    4.01 \n    3.98 \n    3.95 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.89 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n    3.85 \n    3.85 \n    3.84 \n    3.84 \n    3.84 \n  \n  \n    5 \n    4.06 \n    3.78 \n    3.62 \n    3.52 \n    3.45 \n    3.40 \n    3.37 \n    3.34 \n    3.32 \n    3.30 \n    3.28 \n    3.27 \n    3.26 \n    3.25 \n    3.24 \n    3.23 \n    3.22 \n    3.22 \n    3.21 \n    3.21 \n    3.20 \n    3.20 \n  \n  \n    6 \n    3.78 \n    3.46 \n    3.29 \n    3.18 \n    3.11 \n    3.05 \n    3.01 \n    2.98 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n    2.89 \n    2.88 \n    2.87 \n    2.86 \n    2.85 \n    2.85 \n    2.84 \n    2.84 \n    2.83 \n    2.83 \n  \n  \n    7 \n    3.59 \n    3.26 \n    3.07 \n    2.96 \n    2.88 \n    2.83 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.67 \n    2.65 \n    2.64 \n    2.63 \n    2.62 \n    2.61 \n    2.61 \n    2.60 \n    2.59 \n    2.59 \n    2.58 \n  \n  \n    8 \n    3.46 \n    3.11 \n    2.92 \n    2.81 \n    2.73 \n    2.67 \n    2.62 \n    2.59 \n    2.56 \n    2.54 \n    2.52 \n    2.50 \n    2.49 \n    2.48 \n    2.46 \n    2.45 \n    2.45 \n    2.44 \n    2.43 \n    2.42 \n    2.42 \n    2.41 \n  \n  \n    9 \n    3.36 \n    3.01 \n    2.81 \n    2.69 \n    2.61 \n    2.55 \n    2.51 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n    2.38 \n    2.36 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n    2.30 \n    2.30 \n    2.29 \n    2.29 \n  \n  \n    10 \n    3.29 \n    2.92 \n    2.73 \n    2.61 \n    2.52 \n    2.46 \n    2.41 \n    2.38 \n    2.35 \n    2.32 \n    2.30 \n    2.28 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.22 \n    2.21 \n    2.20 \n    2.19 \n    2.19 \n  \n  \n    11 \n    3.23 \n    2.86 \n    2.66 \n    2.54 \n    2.45 \n    2.39 \n    2.34 \n    2.30 \n    2.27 \n    2.25 \n    2.23 \n    2.21 \n    2.19 \n    2.18 \n    2.17 \n    2.16 \n    2.15 \n    2.14 \n    2.13 \n    2.12 \n    2.12 \n    2.11 \n  \n  \n    12 \n    3.18 \n    2.81 \n    2.61 \n    2.48 \n    2.39 \n    2.33 \n    2.28 \n    2.24 \n    2.21 \n    2.19 \n    2.17 \n    2.15 \n    2.13 \n    2.12 \n    2.10 \n    2.09 \n    2.08 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n    2.05 \n  \n  \n    13 \n    3.14 \n    2.76 \n    2.56 \n    2.43 \n    2.35 \n    2.28 \n    2.23 \n    2.20 \n    2.16 \n    2.14 \n    2.12 \n    2.10 \n    2.08 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.02 \n    2.01 \n    2.01 \n    2.00 \n    1.99 \n  \n  \n    14 \n    3.10 \n    2.73 \n    2.52 \n    2.39 \n    2.31 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.10 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n    1.96 \n    1.96 \n    1.95 \n  \n  \n    15 \n    3.07 \n    2.70 \n    2.49 \n    2.36 \n    2.27 \n    2.21 \n    2.16 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.92 \n    1.91 \n  \n  \n    16 \n    3.05 \n    2.67 \n    2.46 \n    2.33 \n    2.24 \n    2.18 \n    2.13 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.88 \n  \n  \n    17 \n    3.03 \n    2.64 \n    2.44 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.06 \n    2.03 \n    2.00 \n    1.98 \n    1.96 \n    1.94 \n    1.93 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.87 \n    1.86 \n    1.86 \n    1.85 \n  \n  \n    18 \n    3.01 \n    2.62 \n    2.42 \n    2.29 \n    2.20 \n    2.13 \n    2.08 \n    2.04 \n    2.00 \n    1.98 \n    1.95 \n    1.93 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.86 \n    1.85 \n    1.84 \n    1.84 \n    1.83 \n    1.82 \n  \n  \n    19 \n    2.99 \n    2.61 \n    2.40 \n    2.27 \n    2.18 \n    2.11 \n    2.06 \n    2.02 \n    1.98 \n    1.96 \n    1.93 \n    1.91 \n    1.89 \n    1.88 \n    1.86 \n    1.85 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.81 \n    1.80 \n  \n  \n    20 \n    2.97 \n    2.59 \n    2.38 \n    2.25 \n    2.16 \n    2.09 \n    2.04 \n    2.00 \n    1.96 \n    1.94 \n    1.91 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.80 \n    1.79 \n    1.79 \n    1.78 \n  \n  \n    21 \n    2.96 \n    2.57 \n    2.36 \n    2.23 \n    2.14 \n    2.08 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    22 \n    2.95 \n    2.56 \n    2.35 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.97 \n    1.93 \n    1.90 \n    1.88 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n  \n  \n    23 \n    2.94 \n    2.55 \n    2.34 \n    2.21 \n    2.11 \n    2.05 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.74 \n    1.73 \n  \n  \n    24 \n    2.93 \n    2.54 \n    2.33 \n    2.19 \n    2.10 \n    2.04 \n    1.98 \n    1.94 \n    1.91 \n    1.88 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n  \n  \n    25 \n    2.92 \n    2.53 \n    2.32 \n    2.18 \n    2.09 \n    2.02 \n    1.97 \n    1.93 \n    1.89 \n    1.87 \n    1.84 \n    1.82 \n    1.80 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n    1.70 \n  \n  \n    26 \n    2.91 \n    2.52 \n    2.31 \n    2.17 \n    2.08 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.86 \n    1.83 \n    1.81 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    27 \n    2.90 \n    2.51 \n    2.30 \n    2.17 \n    2.07 \n    2.00 \n    1.95 \n    1.91 \n    1.87 \n    1.85 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.70 \n    1.69 \n    1.68 \n  \n  \n    28 \n    2.89 \n    2.50 \n    2.29 \n    2.16 \n    2.06 \n    2.00 \n    1.94 \n    1.90 \n    1.87 \n    1.84 \n    1.81 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n    1.69 \n    1.68 \n    1.67 \n  \n  \n    29 \n    2.89 \n    2.50 \n    2.28 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.89 \n    1.86 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.69 \n    1.68 \n    1.68 \n    1.67 \n    1.66 \n  \n  \n    30 \n    2.88 \n    2.49 \n    2.28 \n    2.14 \n    2.05 \n    1.98 \n    1.93 \n    1.88 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.69 \n    1.68 \n    1.67 \n    1.66 \n    1.65 \n  \n  \n    35 \n    2.85 \n    2.46 \n    2.25 \n    2.11 \n    2.02 \n    1.95 \n    1.90 \n    1.85 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.69 \n    1.67 \n    1.66 \n    1.65 \n    1.64 \n    1.63 \n    1.62 \n    1.62 \n  \n  \n    40 \n    2.84 \n    2.44 \n    2.23 \n    2.09 \n    2.00 \n    1.93 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.74 \n    1.71 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.64 \n    1.62 \n    1.61 \n    1.61 \n    1.60 \n    1.59 \n  \n  \n    45 \n    2.82 \n    2.42 \n    2.21 \n    2.07 \n    1.98 \n    1.91 \n    1.85 \n    1.81 \n    1.77 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.58 \n    1.57 \n  \n  \n    50 \n    2.81 \n    2.41 \n    2.20 \n    2.06 \n    1.97 \n    1.90 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n    1.59 \n    1.58 \n    1.57 \n    1.56 \n    1.55 \n  \n  \n    60 \n    2.79 \n    2.39 \n    2.18 \n    2.04 \n    1.95 \n    1.87 \n    1.82 \n    1.77 \n    1.74 \n    1.71 \n    1.68 \n    1.66 \n    1.64 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.56 \n    1.55 \n    1.54 \n    1.53 \n    1.53 \n  \n  \n    75 \n    2.77 \n    2.37 \n    2.16 \n    2.02 \n    1.93 \n    1.85 \n    1.80 \n    1.75 \n    1.72 \n    1.69 \n    1.66 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n    1.54 \n    1.53 \n    1.52 \n    1.51 \n    1.50 \n  \n  \n    100 \n    2.76 \n    2.36 \n    2.14 \n    2.00 \n    1.91 \n    1.83 \n    1.78 \n    1.73 \n    1.69 \n    1.66 \n    1.64 \n    1.61 \n    1.59 \n    1.57 \n    1.56 \n    1.54 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.48 \n  \n  \n    120 \n    2.75 \n    2.35 \n    2.13 \n    1.99 \n    1.90 \n    1.82 \n    1.77 \n    1.72 \n    1.68 \n    1.65 \n    1.63 \n    1.60 \n    1.58 \n    1.56 \n    1.55 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.47 \n    1.46 \n  \n  \n    140 \n    2.74 \n    2.34 \n    2.12 \n    1.99 \n    1.89 \n    1.82 \n    1.76 \n    1.71 \n    1.68 \n    1.64 \n    1.62 \n    1.59 \n    1.57 \n    1.55 \n    1.54 \n    1.52 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n  \n  \n    180 \n    2.73 \n    2.33 \n    2.11 \n    1.98 \n    1.88 \n    1.81 \n    1.75 \n    1.70 \n    1.67 \n    1.63 \n    1.61 \n    1.58 \n    1.56 \n    1.54 \n    1.53 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n  \n  \n    250 \n    2.73 \n    2.32 \n    2.11 \n    1.97 \n    1.87 \n    1.80 \n    1.74 \n    1.69 \n    1.66 \n    1.62 \n    1.60 \n    1.57 \n    1.55 \n    1.53 \n    1.51 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n  \n  \n    400 \n    2.72 \n    2.32 \n    2.10 \n    1.96 \n    1.86 \n    1.79 \n    1.73 \n    1.69 \n    1.65 \n    1.61 \n    1.59 \n    1.56 \n    1.54 \n    1.52 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n  \n  \n    1000 \n    2.71 \n    2.31 \n    2.09 \n    1.95 \n    1.85 \n    1.78 \n    1.72 \n    1.68 \n    1.64 \n    1.61 \n    1.58 \n    1.55 \n    1.53 \n    1.51 \n    1.49 \n    1.48 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n    1.41"
  },
  {
    "objectID": "R/TidyverseSyntax.html",
    "href": "R/TidyverseSyntax.html",
    "title": "Tidyverse syntax",
    "section": "",
    "text": "Den h√§r sidan samlar lite kommandon i den s k tidyverse  dialekten av R."
  },
  {
    "objectID": "R/TidyverseSyntax.html#introduktion",
    "href": "R/TidyverseSyntax.html#introduktion",
    "title": "Tidyverse syntax",
    "section": "Introduktion",
    "text": "Introduktion\n\n\n\nTidyverse √§r en samling R-paket som delar p√• samma underliggande filosofi. N√§r man v√§l l√§rt sig Tidyverse-filosofin, √§r paketen v√§ldigt kraftfulla. Men eftersom det tar sin tid att l√§ra sig Tidyverse s√• anv√§nder vi inte dessa paket p√• den h√§r grundkursen. F√∂r att stilla nyfikenheten bland programmeringintresserade studenter kommer vi d√• och d√• l√§nka till motsvarande kod i Tidyverse genom att visa den h√§r ikonen i marginalen:\n\n\n\n\n\nKlickar man p√• den ikonen f√•r man se motsvarande kod fr√•n ett eller flera av de olika Tidyverse-paketen, t ex\n\n\n\n\n\nSpeciellt v√§rt att notera bland dessa paket √§r ggplot2 som, trots sitt knepiga namn, √§r ett mycket anv√§ndbart paket f√∂r diagram och visualisering. Se ggplot2 cheat sheet f√∂r kommandon.\nDen s k pipe-operatorn %>% g√∂r att Tidyverse-kod byggs upp p√• annats s√§tt √§n standard R. Pipe-operatorn skickar vidare en ber√§kning eller resultat till funktionen till h√∂ger i uttrycket. Ett exempel f√∂rklarar det b√§st:\n\nsuppressMessages(library(tidyverse))\ntitanic %>% group_by(Survived)  %>% tally()\n\n# A tibble: 2 √ó 2\n  Survived     n\n  <chr>    <int>\n1 Alive      712\n2 Dead      1496\n\n\nd√§r datamaterialet (dataframe) titanic skickas in i funktionen group_by() som grupperar data efter variablen Survived. Denna gruppering skickas sen vidare till funktioen tally() som g√∂r sammanfattningen till en tabell."
  },
  {
    "objectID": "R/TidyverseSyntax.html#scatter-plot",
    "href": "R/TidyverseSyntax.html#scatter-plot",
    "title": "Tidyverse syntax",
    "section": "Scatter plot",
    "text": "Scatter plot\n\nlibrary(ggplot2)\nggplot(data = mtcars, aes(x = hp, y = mpg)) +\n  geom_point() + \n  ggtitle(\"Cars fuel usage\")"
  },
  {
    "objectID": "R/TidyverseSyntax.html#tabeller",
    "href": "R/TidyverseSyntax.html#tabeller",
    "title": "Tidyverse syntax",
    "section": "Tabeller",
    "text": "Tabeller\n\nsuppressMessages(library(tidyverse))\ntitanic %>% dplyr::group_by(Survived) %>% tally()\n\n# A tibble: 2 √ó 2\n  Survived     n\n  <chr>    <int>\n1 Alive      712\n2 Dead      1496\n\n\neller om man vill ocks√• ha proportioner\n\nsuppressMessages(library(tidyverse))\ntitanic %>% \n  dplyr::group_by(Survived)  %>% \n  tally() %>% \n  mutate(freq = prop.table(n))\n\n# A tibble: 2 √ó 3\n  Survived     n  freq\n  <chr>    <int> <dbl>\n1 Alive      712 0.322\n2 Dead      1496 0.678\n\n\nd√§r vi skrivit v√•ra pipes %>% enligt tidyverse-konventionen med radbryt mellan en l√•ng serie pipes."
  },
  {
    "objectID": "R/TidyverseSyntax.html#stapeldiagram",
    "href": "R/TidyverseSyntax.html#stapeldiagram",
    "title": "Tidyverse syntax",
    "section": "Stapeldiagram",
    "text": "Stapeldiagram\n\nAntal\n\nlibrary(ggplot2)\ntitanic %>% \n  group_by(Survived)  %>% \n  tally() %>% \n  ggplot(aes(x = Survived, y = n)) +\n  geom_bar(stat = \"identity\") +\n  ylab(\"proportion\")"
  },
  {
    "objectID": "R/TidyverseSyntax.html#histogram-per-kategori-i-samma-figur",
    "href": "R/TidyverseSyntax.html#histogram-per-kategori-i-samma-figur",
    "title": "Tidyverse syntax",
    "section": "Histogram per kategori i samma figur",
    "text": "Histogram per kategori i samma figur\n\nsuppressMessages(library(ggplot2))\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true\"))\nggplot(FevChildren, aes(x = fev, fill = age.group)) + \n  geom_histogram(alpha =0.75, bins = 20) + ggtitle(\"FEV given age.group\")"
  },
  {
    "objectID": "R/BaseRSyntax.html",
    "href": "R/BaseRSyntax.html",
    "title": "Base-R",
    "section": "",
    "text": "Den h√§r sidan samlar lite kommandon i den s k base-R  dialekten av R."
  },
  {
    "objectID": "R/BaseRSyntax.html#scatter-plot",
    "href": "R/BaseRSyntax.html#scatter-plot",
    "title": "Base-R",
    "section": "Scatter plot",
    "text": "Scatter plot\n\nplot(mtcars$hp, mtcars$mpg, xlab = \"hp\", ylab = \"mpg\", main = \"Cars fuel usage\")"
  },
  {
    "objectID": "R/BaseRSyntax.html#tabeller",
    "href": "R/BaseRSyntax.html#tabeller",
    "title": "Base-R",
    "section": "Tabeller",
    "text": "Tabeller\n\n\n\n\ntable(titanic$Survived)\n\n\nAlive  Dead \n  712  1496 \n\n\neller om man vill ha en tabell med andelar\n\nprop.table(table(titanic$Survived))\n\n\n    Alive      Dead \n0.3224638 0.6775362"
  },
  {
    "objectID": "R/BaseRSyntax.html#stapeldiagram",
    "href": "R/BaseRSyntax.html#stapeldiagram",
    "title": "Base-R",
    "section": "Stapeldiagram",
    "text": "Stapeldiagram\n\nbarplot(prop.table(table(titanic$Survived)), ylab = \"proportion\")"
  },
  {
    "objectID": "R/BaseRSyntax.html#histogram",
    "href": "R/BaseRSyntax.html#histogram",
    "title": "Base-R",
    "section": "Histogram",
    "text": "Histogram\n\nhist(titanic$Age)"
  },
  {
    "objectID": "R/BaseRSyntax.html#histogram-per-kategori-i-separata-figurer",
    "href": "R/BaseRSyntax.html#histogram-per-kategori-i-separata-figurer",
    "title": "Base-R",
    "section": "Histogram per kategori i separata figurer",
    "text": "Histogram per kategori i separata figurer\n\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true\"))\nfev_list <- split(FevChildren$fev, FevChildren$age.group)\nn <- length(fev_list)\nSorted_age.group <- sort(unique(FevChildren$age.group))\npar(mfrow = c(1,3))\nfor(i in 1:n){\n  hist(fev_list[[i]], main = paste(\"FEV given age.group\", Sorted_age.group[i]),\n       xlab = \"FEV\", col = \"lightblue\", ylim = c(0, 1), probability = TRUE)\n}"
  },
  {
    "objectID": "R/BaseRSyntax.html#histogram-per-kategori-i-samma-figur",
    "href": "R/BaseRSyntax.html#histogram-per-kategori-i-samma-figur",
    "title": "Base-R",
    "section": "Histogram per kategori i samma figur",
    "text": "Histogram per kategori i samma figur\n\npar(mfrow = c(1,1))\nhist(fev_list[[1]], main = paste(\"Histogram of fev given age.group\"), xlab = \"FEV\",\n     col = 2, probability = TRUE, xlim = c(1, 8))\nfor(i in 2:n){\n  hist(fev_list[[i]], add = TRUE, col = i+1, probability =  TRUE)\n}\nlegend(\"topright\", legend = c(\"6-9\", \"10-14\", \"15-17\"), fill = c(2, 3, 4))"
  },
  {
    "objectID": "R/InstallR/installR_mac.html",
    "href": "R/InstallR/installR_mac.html",
    "title": "Installera R och Rstudio p√• egen Apple/Mac dator",
    "section": "",
    "text": "En liten guide till hur man installerar R och RStudio p√• Apple/Mac"
  },
  {
    "objectID": "R/InstallR/installR_mac.html#installera-r",
    "href": "R/InstallR/installR_mac.html#installera-r",
    "title": "Installera R och Rstudio p√• egen Apple/Mac dator",
    "section": "Installera R",
    "text": "Installera R\n\nBes√∂k den h√§r installeringssidan och klicka p√• den bl√• knappen:\n\n\n\n\n\n\n\nKlicka p√• Download R for macOS:\n\n\n\n\n\n\n\nDet h√§r steget √§r lite lurigt eftersom du m√•ste veta om din Mac har en processor med det nyare M1-chippet eller det √§ldre Intel-processorn. Om du inte vet det kan du ta redan p√• det s√• h√§r.\n\n\nOm du har M1 processorn (nyare Mac): klicka p√• l√§nken R-4.2.2-arm64.pkg\nOm du har Intel-processorn (√§ldre Mac): klicka p√• l√§nken R-4.2.2.pkg\n\nObservera att numret 4.2.2 kan vara annorlunda n√§r du laddar ner.\n\n\n\n\n\n\nKlicka p√• Download R-4.2.2 for Windows (obs! kan st√• annat nummer n√§r du bes√∂ker sidan).\n\n\n\n\n\n\n\nEfter Steg 4 kommer filen R-4.2.2-arm.pkg (eller R-4.2.2.pkg om du har en √§ldre Mac) att laddas ner p√• din Mac (igen, det kan vara lite annat nummer f√∂r dig). Dubbelklicka p√• den filen och f√∂lj vanliga instruktioner f√∂r hur man installerar ett program.\n\nNu √§r R installerat och det √§r dags att installera RStudio, som √§r den milj√∂ du kommer anv√§nda n√§r du skriver R kod."
  },
  {
    "objectID": "R/InstallR/installR_mac.html#installera-rstudio.",
    "href": "R/InstallR/installR_mac.html#installera-rstudio.",
    "title": "Installera R och Rstudio p√• egen Apple/Mac dator",
    "section": "Installera RStudio.",
    "text": "Installera RStudio.\n\nBes√∂k installeringssidan igen, men g√• till Step 2 och klicka p√• l√§nken RSTUDIO-2022.12.0-353.DMG (igen, mycket m√∂jligt att du ser annat nummer)\n\n\n\n\n\n\n\nFilen RStudio-2022.12.0-353.dmg laddas ner p√• er dator. Installera RStudio genom att klicka p√• den och f√∂lj installationsinstruktionerna.\n\nDu kan nu starta RStudio genom att leta upp RStudio p√• din dator och klicka p√• ikonen som ser ut n√•got √•t det h√§r h√•llet:\n\n\n\n\n\n\nAvboka planerna f√∂r resten av dagen, st√§ng av notifieringar p√• din mobil, och b√∂rja utforska RStudio och R! ü§ì"
  },
  {
    "objectID": "R/InstallR/installR_windows.html",
    "href": "R/InstallR/installR_windows.html",
    "title": "Installera R och Rstudio p√• Windows dator",
    "section": "",
    "text": "En liten guide till hur man installerar R och RStudio p√• Windows-dator"
  },
  {
    "objectID": "R/InstallR/installR_windows.html#installera-r",
    "href": "R/InstallR/installR_windows.html#installera-r",
    "title": "Installera R och Rstudio p√• Windows dator",
    "section": "Installera R",
    "text": "Installera R\n\nBes√∂k den h√§r installeringssidan och klicka p√• den bl√• knappen:\n\n\n\n\n\n\n\nKlicka p√• Download R for Windows:\n\n\n\n\n\n\n\nKlicka p√• install R for the first time:\n\n\n\n\n\n\n\nKlicka p√• Download R-4.2.2 for Windows (obs! kan st√• annat nummer n√§r du bes√∂ker sidan).\n\n\n\n\n\n\n\nEfter Steg 4 kommer filen R-4.2.2-win.exe att laddas ner p√• din dator (igen, det kan vara lite annat nummer f√∂r dig). Dubbelklicka p√• den filen och f√∂lj vanliga instruktioner f√∂r hur man installerar ett program.\n\nNu √§r R installerat och det √§r dags att installera RStudio, som √§r den milj√∂ du kommer anv√§nda n√§r du skriver R kod."
  },
  {
    "objectID": "R/InstallR/installR_windows.html#installera-rstudio.",
    "href": "R/InstallR/installR_windows.html#installera-rstudio.",
    "title": "Installera R och Rstudio p√• Windows dator",
    "section": "Installera RStudio.",
    "text": "Installera RStudio.\n\nBes√∂k installeringssidan igen, men g√• till Step 2 och klicka p√• l√§nken RSTUDIO-2022.12.0-355.EXE (igen, mycket m√∂jligt att du ser annat nummer)\n\n\n\n\n\n\n\nFilen RStudio-2022.12.0-353.exe laddas ner p√• er dator. Installera RStudio genom att klicka p√• den och f√∂lj installationsinstruktionerna.\n\nDu kan nu starta RStudio genom att leta upp RStudio p√• din dator och klicka p√• ikonen som ser ut n√•got √•t det h√§r h√•llet:\n\n\n\n\n\n\nAvboka planerna f√∂r resten av dagen, st√§ng av notifieringar p√• din mobil, och b√∂rja utforska RStudio och R! ü§ì"
  },
  {
    "objectID": "R/Rcommands.html",
    "href": "R/Rcommands.html",
    "title": "R commands for SDA1",
    "section": "",
    "text": "This document gives some useful R commands for the basic stats course SDA1 using the mosaic and ggformula packages using the R formula syntax."
  },
  {
    "objectID": "R/Rcommands.html#credits",
    "href": "R/Rcommands.html#credits",
    "title": "R commands for SDA1",
    "section": "Credits",
    "text": "Credits\nThis document is adapted from Professor Mcnamara‚Äôs All the R you need for STAT 220 - formula."
  },
  {
    "objectID": "R/Rcommands.html#loading-packages",
    "href": "R/Rcommands.html#loading-packages",
    "title": "R commands for SDA1",
    "section": "Loading packages",
    "text": "Loading packages\nLoading two packages for formula based basic statistics\n\nlibrary(mosaic)\nlibrary(ggformula)"
  },
  {
    "objectID": "R/Rcommands.html#reading-in-data",
    "href": "R/Rcommands.html#reading-in-data",
    "title": "R commands for SDA1",
    "section": "Reading in data",
    "text": "Reading in data\n\nGSS <- read.csv(\"GSS_clean.csv\")"
  },
  {
    "objectID": "R/Rcommands.html#plotting",
    "href": "R/Rcommands.html#plotting",
    "title": "R commands for SDA1",
    "section": "Plotting",
    "text": "Plotting\n\n# one categorical\ngf_bar(~marital_status, data = GSS)\n\n\n\n# two categorical\ngf_bar(~marital_status, fill = ~born_in_us, data = GSS)\n\n\n\ngf_bar(~marital_status, fill = ~born_in_us, data = GSS, position = \"dodge\")\n\n\n\n# one numeric\ngf_histogram(~highest_year_of_school_completed, data = GSS)\n\nWarning: Removed 3 rows containing non-finite values (`stat_bin()`).\n\n\n\n\ngf_boxplot(~highest_year_of_school_completed, data = GSS)\n\nWarning: Removed 3 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n# one numeric, one categorical\ngf_boxplot(highest_year_of_school_completed ~ labor_force_status, data = GSS)\n\nWarning: Removed 3 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n# two numeric\ngf_point(highest_year_of_school_completed ~ highest_year_school_completed_spouse,\n  data = GSS\n)\n\nWarning: Removed 1361 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "R/Rcommands.html#summary-statistics",
    "href": "R/Rcommands.html#summary-statistics",
    "title": "R commands for SDA1",
    "section": "Summary statistics",
    "text": "Summary statistics\n\n# one categorical\ntally(~marital_status, data = GSS, format = \"proportion\")\n\nmarital_status\n     Divorced       Married Never married     Separated       Widowed \n 0.1716354344  0.4250425894  0.2853492334  0.0319420784  0.0851788756 \n         <NA> \n 0.0008517888 \n\n# two categorical\ntally(~ marital_status | general_happiness, data = GSS, format = \"proportion\")\n\n               general_happiness\nmarital_status  Not too happy Pretty happy   Very happy         <NA>\n  Divorced       0.2500000000 0.1851568477 0.1098430813 0.0000000000\n  Married        0.1815476190 0.3856159143 0.6162624822 0.2500000000\n  Never married  0.4017857143 0.3129303749 0.1768901569 0.5000000000\n  Separated      0.0565476190 0.0306044376 0.0213980029 0.2500000000\n  Widowed        0.1101190476 0.0849273145 0.0741797432 0.0000000000\n  <NA>           0.0000000000 0.0007651109 0.0014265335 0.0000000000\n\n# one numeric\nmean(~highest_year_of_school_completed, data = GSS, na.rm = TRUE)\n\n[1] 13.73177\n\noptions(na.rm = TRUE) # options\nmedian(~highest_year_of_school_completed, data = GSS)\n\n[1] 14\n\nsd(~highest_year_of_school_completed, data = GSS)\n\n[1] 2.974313\n\nrange(~highest_year_of_school_completed, data = GSS)\n\n[1]  0 20\n\nIQR(~highest_year_of_school_completed, data = GSS)\n\n[1] 4\n\nfivenum(~highest_year_of_school_completed, data = GSS)\n\n[1]  0 12 14 16 20\n\nfavstats(~highest_year_of_school_completed, data = GSS) # favorite statistics\n\n min Q1 median Q3 max     mean       sd    n missing\n   0 12     14 16  20 13.73177 2.974313 2345       3\n\ncor(highest_year_of_school_completed ~ highest_year_school_completed_spouse,\n  data = GSS, use = \"complete.obs\"\n) # correlation\n\n[1] 0.5955573"
  },
  {
    "objectID": "R/Rcommands.html#working-with-data",
    "href": "R/Rcommands.html#working-with-data",
    "title": "R commands for SDA1",
    "section": "Working with data",
    "text": "Working with data\n\n# filtering out NA values\nGSS_prop <- filter(\n  GSS,\n  !is.na(should_marijuana_be_made_legal),\n  !is.na(self_emp_or_works_for_somebody)\n)"
  },
  {
    "objectID": "R/Rcommands.html#modeling-and-inference",
    "href": "R/Rcommands.html#modeling-and-inference",
    "title": "R commands for SDA1",
    "section": "Modeling and inference",
    "text": "Modeling and inference\n\n# linear model\nm1 <- lm(highest_year_of_school_completed ~ highest_year_school_completed_spouse,\n  data = GSS\n)\nsummary(m1)\n\n\nCall:\nlm(formula = highest_year_of_school_completed ~ highest_year_school_completed_spouse, \n    data = GSS)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.5400  -1.3519   0.0242   1.4600   7.0242 \n\nCoefficients:\n                                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                           5.84740    0.36316   16.10   <2e-16 ***\nhighest_year_school_completed_spouse  0.59403    0.02553   23.27   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.462 on 985 degrees of freedom\n  (1361 observations deleted due to missingness)\nMultiple R-squared:  0.3547,    Adjusted R-squared:  0.354 \nF-statistic: 541.4 on 1 and 985 DF,  p-value: < 2.2e-16\n\nrsquared(m1)\n\n[1] 0.3546884\n\npredict(m1,\n  newdata = data.frame(highest_year_school_completed_spouse = 11),\n  interval = \"confidence\"\n)\n\n       fit      lwr      upr\n1 12.38178 12.17059 12.59297\n\npredict(m1,\n  newdata = data.frame(highest_year_school_completed_spouse = 11),\n  interval = \"prediction\"\n)\n\n       fit      lwr      upr\n1 12.38178 7.546498 17.21706\n\n# bootstrapping\nbootstrap_sample <- do(1) * resample(GSS)\nboot <- do(1000) * mean(~highest_year_of_school_completed, data = resample(GSS))\nconfint(boot)\n\n  name    lower    upper level     method estimate\n1 mean 13.61371 13.85108  0.95 percentile 13.73177\n\n# one proportion\nprop.test(~self_emp_or_works_for_somebody,\n  data = GSS, success = \"Self-employed\", p = 0.1, alternative = \"less\"\n)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  GSS$self_emp_or_works_for_somebody  [with success = Self-employed]\nX-squared = 0.1433, df = 1, p-value = 0.6475\nalternative hypothesis: true p is less than 0.1\n95 percent confidence interval:\n 0.0000000 0.1138167\nsample estimates:\n        p \n0.1026095 \n\n# two proportions\nprop.test(should_marijuana_be_made_legal ~ self_emp_or_works_for_somebody,\n  data = GSS_prop, success = \"Legal\"\n)\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  tally(should_marijuana_be_made_legal ~ self_emp_or_works_for_somebody)\nX-squared = 0.87754, df = 1, p-value = 0.3489\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.04100264  0.12791902\nsample estimates:\n   prop 1    prop 2 \n0.6901408 0.6466827 \n\n# one mean\nt.test(~highest_year_of_school_completed, data = GSS, mu = 12, alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  highest_year_of_school_completed\nt = 28.195, df = 2344, p-value < 2.2e-16\nalternative hypothesis: true mean is greater than 12\n95 percent confidence interval:\n 13.6307     Inf\nsample estimates:\nmean of x \n 13.73177 \n\n# two means\nt.test(highest_year_of_school_completed ~ born_in_us, data = GSS)\n\n\n    Welch Two Sample t-test\n\ndata:  highest_year_of_school_completed by born_in_us\nt = -4.8468, df = 337.79, p-value = 1.916e-06\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n -1.7012965 -0.7190416\nsample estimates:\n mean in group No mean in group Yes \n         12.67774          13.88791 \n\n# Chi-square\nchisq.test(tally(marital_status ~ general_happiness, data = GSS)) # independence\n\nWarning in chisq.test(tally(marital_status ~ general_happiness, data = GSS)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  tally(marital_status ~ general_happiness, data = GSS)\nX-squared = 210.13, df = 15, p-value < 2.2e-16\n\nchisq.test(tally(~general_happiness, data = GSS), p = c(0.14, 0.55, 0.30, 0.01)) # GoF\n\n\n    Chi-squared test for given probabilities\n\ndata:  tally(~general_happiness, data = GSS)\nX-squared = 16.528, df = 3, p-value = 0.0008838"
  },
  {
    "objectID": "R/Rcommands.html#probability",
    "href": "R/Rcommands.html#probability",
    "title": "R commands for SDA1",
    "section": "Probability",
    "text": "Probability\n\npnorm(1.96, lower.tail = FALSE) # normal distribution function\n\n[1] 0.0249979\n\nqnorm(0.25, mean = 100, sd = 5) # normal quantile function\n\n[1] 96.62755"
  },
  {
    "objectID": "R/FormulaSyntax.html",
    "href": "R/FormulaSyntax.html",
    "title": "Formula syntax",
    "section": "",
    "text": "Den h√§r sidan samlar lite kommandon i den s k formula/mosaic  dialekten av R."
  },
  {
    "objectID": "R/FormulaSyntax.html#scatter-plot",
    "href": "R/FormulaSyntax.html#scatter-plot",
    "title": "Formula syntax",
    "section": "Scatter plot",
    "text": "Scatter plot\nEn vanlig scatter plot f√•s genom:\n\nplot(mpg ~ hp, data = mtcars, main = \"Cars fuel usage\")\n\n\n\n\nMed ggformula paketet kan man anv√§nda formel-syntax, men f√• plottar som liknar Tidyverse:\n\nlibrary(ggformula)\n\n\ngf_point(mpg ~ hp, data = mtcars, title = \"Cars fuel usage\")"
  },
  {
    "objectID": "Del2.html",
    "href": "Del2.html",
    "title": "Del II - Sannolikhetsmodeller och Inferens, 7.5 hp",
    "section": "",
    "text": "I kursens andra momentet behandlas inledningsvis sannolikheter, slumpvariabler och sannolikhetsf√∂rdelningar. En central del i momentet √§r inferens, dvs. statistiska metoder f√∂r att dra slutsatser om olika fenomen fr√•n data, bl a samband fr√•n regressionsanalys. Kursen avslutas med en introduktion till beslutsfattade under os√§kerhet.\n\nF√∂rkortningen SDM st√•r f√∂r kursboken Stats: Data and Models 5:e upplagan, global edition.\nUnder vissa f√∂rel√§sningar l√§nkar vi till Extramaterial. Det √§r material som inte kr√§vs f√∂r att klara kursen, men som den nyfikne kan l√§sa f√∂r att f√• en djupare f√∂rst√•else.\n\nF√∂rel√§sningar\nF√∂rel√§sning 12 - Os√§kerhet och Sannolikhet.\nL√§s: SDM Kapitel 12 och 13 | Slides\nInteraktivt: slantsingling\nExtramaterial: TedTalk om sannolikheter\nF√∂rel√§sning 13 - Betingade sannolikheter och Bayes sats.\nL√§s: SDM Kapitel 13 | Slides\nInteraktivt: bayessats\nExtramaterial: Artikel om Bayes sats och snabbtest f√∂r Covid-19\nF√∂rel√§sning 14 - Slumpvariabler och deras egenskaper.\nL√§s: SDM Kapitel 14 | Slides\nInteraktivt: normalf√∂rdelningen\nF√∂rel√§sning 15 - Sannolikhetsmodeller I.\nL√§s: SDM Kapitel 15.1, 15.2, 15.3, 15.6 | Slides\nInteraktivt: geometrisk f√∂rdelning | binomialf√∂rdelningen | likformig | normalf√∂rdelning\nKod: geometric.R\nF√∂rel√§sning 16 - Sannolikhetsmodeller II.\nL√§s: SDM Kapitel 5.3, 14.4, 15.7 | Slides\nInteraktivt: Poissonf√∂rdelningen | maximum likelihood - Poisson | exponential | student-t | allm√§n student-t\nKod: exponential.R\nExtramaterial: Notebook - student-t ¬†notebook - matematisk h√§rledning av maximum likelihood skattningen i Poissonmodellen\nF√∂rel√§sning 17 - Samplingf√∂rdelningar och konfidensintervall f√∂r en andel.\nL√§s: SDM Kapitel 16 | Slides\nInteraktivt: samplingf√∂rdelning - liten √§ndlig population | samplingf√∂rdelning f√∂r andel - √§ndlig population\nF√∂rel√§sning 18 - Konfidensintervall f√∂r ett v√§ntev√§rde. Stora talens lag. Centrala gr√§nsv√§rdessatsen.\nL√§s: SDM Kapitel 17 | Slides\nInteraktivt: stora talens lag | centrala gr√§nsv√§rdessatsen\nExtramaterial: Notebook - stora talens lag | Notebook - centrala gr√§nsv√§rdessatsen\nF√∂rel√§sning 19 - Hypotestest.\nL√§s: SDM Kapitel 18 | Slides\nF√∂rel√§sning 20 - Hypotestest och j√§mf√∂ra grupper.\nL√§s: SDM Kapitel 19, 20.4, 20.5 | Slides\nF√∂rel√§sning 21 - J√§mf√∂ra grupper och \\(\\chi^2\\)-test.\nL√§s: SDM Kapitel 21.1, 21.2 | Slides\nInteraktivt: chi2-f√∂rdelningen\nF√∂rel√§sning 22 - Inferens i multipel regression.\nL√§s: SDM Kapitel 23 | Slides\nVideof√∂rel√§sning - Maximum likelihood och Bayesiansk inferens.\nL√§s: Slides\nInteraktivt: betaf√∂rdelningen\nF√∂rel√§sning 23 - Optimala beslut under os√§kerhet.\nL√§s: Slides\nF√∂rel√§sning 24 - Sammanfattning.\nL√§s: Slides\n\n\nR√§kne√∂vningar\n√ñvningarna i kursboken Stats: Data and Models (SDM) h√§nvisas till med kapitelnummer f√∂ljt av √∂vningsnummer.\n√ñvning 7 - Sannolikheter f√∂r h√§ndelser. Kombinatorik.\nUppgifter: SDM 12.2, 12.5, 12.7, 12.9, 12.12, 12.16, 12.21, 12.27, 12.29, 12.31, 12.34, 12.36, 12.39, 12.41, 12.49, 12.52.\n√ñvning 8 - Oberoende h√§ndelser. Betingning och Bayes sats.\nUppgifter: SDM 13.1, 13.5, 13.7, 13.10, 13.12, 13.14, 13.18, 13.21, 13.24, 13.31, 13.47, 13.49.\n√ñvning 9 - Slumpvariabler, v√§ntev√§rde och standardavvikelse.\nUppgifter: SDM 14.1, 14.3, 14.9a, 14.11, 14.13, 14.21, 14.26, 14.33, 14.36, 14.43, 14.54.\n√ñvning 10 - Sannolikhetsmodeller I.\nUppgifter: SDM 15.1, 15.3, 15.5, 15.18, 15.19, 15.21, 15.28, 15.29, 15.31, 15.41, 15.45.\n√ñvning 11 - Sannolikhetsmodeller II.\nUppgifter: SDM 15.7, 15.11, 15.12, 15.49, 15.59, 15.60, 15.61, 15.62.\n√ñvning 12 - Samplingf√∂rdelningar och konfidensintervall f√∂r en andel.\nUppgifter: SDM 16\n√ñvning 13 - Konfidensintervall f√∂r ett v√§ntev√§rde. Hypotestest.\nUppgifter: SDM 17\n√ñvning 14 - Hypotestest.\nUppgifter: SDM 18. SDM 20-21.\n√ñvning 15 - J√§mf√∂ra grupper och chi2-test.\nUppgifter: SDM 23\n√ñvning 16 - Inferens f√∂r regression.\nUppgifter: SDM 23\n\n\nDatorlaborationer\nDatorlaboration 5 - Simulering f√∂r att utforska slumpvariabler och deras egenskaper.\nUppgifter: Datorlab 5\nDatorlaboration 6 - Samplingf√∂rdelningar, standardfel och konfidensintervall.\nUppgifter: Datorlab 6\nDatorlaboration 7 - Multipel linj√§r regression - inferens.\nUppgifter: Datorlab 7"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html",
    "href": "assignments/assignment1/Assignment1.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Varning\n\n\n\nDen h√§r inl√§mningsuppgiften f√∂ruts√§tter att f√∂ljande paket finns installerade:\n\nmosaic\ndplyr\ngeosphere\nleaflet\n\nPaket kan installeras via kommandot install.packages('packagename'), d√§r 'packagename' √§r namnet p√• paketet, t.ex 'mosaic'."
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#introduktion",
    "href": "assignments/assignment1/Assignment1.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\nI den f√∂rsta inl√§mningsuppgiften ska ni sj√§lvst√§ndigt i grupper om tre analysera ett dataset i programmeringsspr√•ket R. Till skillnad fr√•n datorlaborationerna finns det minimalt med kodexempel. Datorlaborationerna g√•r igenom de flesta momenten som behandlas i inl√§mningsuppgiften, s√• se till att g√∂ra klart dessa innan.\n\n\n\n\n\n\n\nInstruktioner\n\n\n\nI denna inl√§mningsuppgift ska ni analysera ett datamaterial som inneh√•ller en m√§ngd olika variabler fr√•n en totalunders√∂kning1 i Boston 1970 som aggregerats till ca 500 censusdistrikt. Datasetet f√∂rekommer i m√•nga olika varianter. H√§r anv√§nder vi en modifierad version2 av originaldata3 som anv√§nts i en studie4 d√§r f√∂rfattarna predikterar medianhuspriset i ett censusdistrikt givet en upps√§ttning f√∂rklarande variabler.\nF√∂ljande variabler finns i datasetet boston_census_data.Rdata (ladda ner) f√∂r 480 observationer. Notera att en observation motsvarar ett censusdistrikt:\n\ntown: Stadsdel.\nlongitude: Longitud koordinat.\nlatitude: Latitud koordinat.\nmedian_home_value: Medianhuspriset (enhet 1K USD).\ncrime_rate: Brott (per 1000 inv√•nare).\nzoned_25k_p: Andel av stadsdelens bostadsmark √§mnad f√∂r marklotter st√∂rre √§n 25000 kvadratfot.\nindust_p: Andel tunnland √§gd av f√∂retag utanf√∂r detaljhandel.\nborders_charles: Charles River dummy variabel (= 1 om omr√•det gr√§nsar till floden, 0 annars).\nNOx: Koncentration av kv√§veoxider (andelar per 10 miljon).\nn_rooms_avg: Genomsnitt antal rum i √§gda bost√§der.\nbefore_1940_p: Andel √§gda bost√§der byggda f√∂re 1940.\nemploy_dist: Viktat avst√•nd till fem arbetsf√∂rmedlingscentra i Boston.\nradial_access: Index som m√§ter tillg√•ng till stadsmotorv√§gar.\ntax_rate: Fastighetsskatt per 10000 USD.\npupil_teacher_ratio: L√§rart√§thet m√§tt som elev per l√§rare.\nlower_stat_pct: Procentandel underklass definerad som en av tv√•: (i) andel vuxna utan gymnasieutbildning eller (ii) andel m√§n som genomf√∂r okvalificerat arbete.\n\nBland de f√∂rklarande variablerna som anv√§nts i studien (ej med i datasetet) finns en icke-linj√§r interaktion av latitud och longitud koordinaterna f√∂r att modellera medianhuspriset spatiellt (dvs deras modell anv√§nder censusdistriktens geografiska platser f√∂r att f√•nga den spatiella variationen i huspriser, dvs geografisk variation). Det h√§r s√§ttet att modellera spatiellt beroende √§r √∂verkurs5, s√• ni kommer att f√• g√∂ra f√∂ljande f√∂renkling f√∂r att f√•nga det geografiska beroendet i medianhuspriset. Genom att anv√§nda latitud och longitud koordinaterna kan ni ber√§kna avst√•ndet till en central plats i Boston. Ni kan sedan inkludera detta avst√•nd som en f√∂rklarande variabel i en regressionsmodell, f√∂r att se om den f√∂rklarar variation i medianhuspriserna.\nI sista uppgiften ska ni f√∂resl√• en prognosmodell f√∂r medianhuspriset d√§r ni f√•r v√§lja vilka f√∂rklaringsvariabler ni vill ha med (ni v√•r v√§lja bland en delm√§ngd av de som listas ovanf√∂r, se Uppgift 5.4). Ni ska sedan anv√§nda er modell f√∂r att prognostisera medianhuspriset f√∂r tio censusdistrikt i datasetet boston_districts_to_predict.Rdata (ladda ner). Det h√§r datasetet har endast de f√∂rklarande variablerna, dvs alla de variabler ni f√•r anv√§nda f√∂rutom medianhuspriset. N√§r vi r√§ttar era inl√§mningsuppgifter kommer vi att j√§mf√∂ra prognoserna mot de faktiska v√§rden (vi har tillg√•ng till dessa). De tre b√§sta prognosmakarna kommer att publiceras p√• hemsidan.\nInl√§mningsuppgiften ska l√§mnas in i form av ett html dokument genererat av Quarto. Kontrollera noga att du inte har n√•gra felmeddelande och att dokumentet kompileras utan problem. Anv√§nd tydliga figurer och namnge axlarna med tydliga variabelnamn. Gl√∂m inte att skriva era namn ovanf√∂r ist√§llet f√∂r Namn 1, Namn 2 och Namn 3."
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#ladda-in-data",
    "href": "assignments/assignment1/Assignment1.html#ladda-in-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "0. Ladda in data",
    "text": "0. Ladda in data\n\nüí™ Uppgift 0.1\nLadda in dataseten Boston_census_data.Rdata och Boston_districts_to_predict.Rdata (l√§nkar f√∂r att ladda ner data finns i Instruktioner avsnittet ovan).\n\n\n\n\n\n\nUppgift 0.1 - Svar\n\n\n\n\n# Write your code here\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_census_data.RData?raw=true\"))"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#kriminalitet-i-boston",
    "href": "assignments/assignment1/Assignment1.html#kriminalitet-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Kriminalitet i Boston",
    "text": "1. Kriminalitet i Boston\nI detta avsnitt ska ni analysera kriminaliteten i Boston med hj√§lp av variabeln crime_rate.\n\nüí™ Uppgift 1.1\nVad kan man generellt s√§ga om kriminaliteten i censusdistrikten? Anv√§nd l√§mpliga figurer samt f√∂rdelningsm√•tt som underlag.\n\n\n\n\n\n\nUppgift 1.1 - Svar\n\n\n\nSkriv svaret h√§r. Vid behov skrivs matematiska symboler inom dollartecken, till exempel \\(\\overline{y} = \\sum^{n}_{i=1} y_i\\). Koden skrivs i R-rutan nedanf√∂r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 1.2\nVarierar brottsligheten i Boston beroende p√• den kategoriska variabeln town? Det finns 88 olika utfall av town (dvs 88 olika stadsdelar). V√§lj ut Boston East Boston, Boston Downtown,Cambridge, samt tv√• valfria stadsdelar f√∂r att besvara fr√•gan. Fr√•gan besvaras med hj√§lp av l√§mpligt valda figurer och statistiska m√•tt.\n\n\n\n\n\n\nTips\n\n\n\nSkapa en ny data frame som filtrerar Boston_census_data (till exempel genom filter() funktionen) utefter de stadsdelarna ni √§r intresserade utav innan ni p√•b√∂rjar analysen.\n\n\n\n\n\n\n\n\nUppgift 1.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 1.3\nVilka tre variabler i datasetet Boston_census_data korrelerar mest med brottslighet? Beskriv det parvisa sambandet mellan brottslighet och vardera av dessa tre variabler.\n\n\n\n\n\n\nTips\n\n\n\nKom ih√•g att korrelation √§r ett beroendem√•tt f√∂r numeriska variabler.\n\n\n\n\n\n\n\n\nUppgift 1.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#fastighetsskatt-i-boston",
    "href": "assignments/assignment1/Assignment1.html#fastighetsskatt-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Fastighetsskatt i Boston",
    "text": "2. Fastighetsskatt i Boston\nI detta avsnitt ska ni analysera fastighetsskatten i Boston med hj√§lp av variabeln tax_rate.\n\nüí™ Uppgift 2.1\nVad kan man generellt s√§ga om fastighetsskatten i censusdistrikten? Anv√§nd l√§mpliga figurer samt f√∂rdelningsm√•tt som underlag.\n\n\n\n\n\n\nUppgift 2.1 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 2.2\nL√•t oss skapa en ny variabel cat_tax som anger om ett censusdistrikt betalar l√•g (low), medel (medium), eller h√∂g (high) fastighetsskatt. Vi definerar skattekategorierna enligt\n\nlow: tax_rate \\(\\leq\\) 250,\nmedium: 250 \\(<\\) tax_rate \\(\\leq\\) 400,\nhigh: tax_rate \\(>\\) 400.\n\nF√∂ljande kod skapar och l√§gger till variabeln cat_tax i Boston_census_data\n\nBoston_census_data$cat_tax <- cut(Boston_census_data$tax_rate, \n              breaks=c(0, 250, 400, 800),\n              labels=c('Low', 'Medium', 'High'))\n\nFinns det ett samband mellan vilken skattekategori ett censusdistrikt tillh√∂r och dess angr√§nsning till Charles River? F√∂rklara med hj√§lp av l√§mplig tabell samt figur.\n\n\n\n\n\n\nUppgift 2.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 2.3\nHur m√•nga procent av alla censusdistrikt ligger i angr√§nsning till Charles River och tillh√∂r en h√∂g skattekategori? Hur stor andel av censusdistrikten med h√∂g skatt ligger inte i angr√§nsning till Charles River?\n\n\n\n\n\n\nUppgift 2.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 2.4\nVilka tv√• variabler i datasetet Boston_census_data korrelerar mest med tax_rate? Beskriv det parvisa sambandet mellan tax_rate och vardera av dessa tv√• variabler. √Ñr dessa korrelationssamband eller kausala samband?\n\n\n\n\n\n\nTips\n\n\n\nKom ih√•g att korrelation √§r ett beroendem√•tt f√∂r numeriska variabler.\n\n\n\n\n\n\n\n\nUppgift 2.4 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#avst√•nd-till-fenway-park",
    "href": "assignments/assignment1/Assignment1.html#avst√•nd-till-fenway-park",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Avst√•nd till Fenway park",
    "text": "3. Avst√•nd till Fenway park\nI detta avsnitt ska ni skapa en ny variabel som m√§ter avst√•ndet till Fenway park (stadion d√§r basebollslaget Boston Red Sox spelar sina hemmamatcher). Genom variablerna latitude och longitude kan vi ber√§kna det s√• kallade cirkelavst√•ndet6 till Fenway park f√∂r varje distrikt. Formeln f√∂r cirkelavst√•ndet √§r ganska komplicerad, men den finns implementerad i funktionen distHaversine() i R-paketet geosphere. F√∂ljande kod ber√§knar avst√•ndet till Fenway park f√∂r varje censusdistrikt och sparar den som en ny variabel dist_fenway_park i Boston_census_data.\n\nlibrary(geosphere) # Install if not available\nlat_long <- cbind(Boston_census_data$latitude, Boston_census_data$longitude)\nfenway_park_lat_long <- c(42.346462, -71.097250) # latitude and longitude for Fenway_park\nBoston_census_data$dist_fenway_park <- distHaversine(lat_long, fenway_park_lat_long)\n\nVi kan visualisera Fenway park samt censusdistrikten i en interaktiv karta med hj√§lp av R-paketet leaflet. F√∂ljande kod visualiserar Fenway park samt censusdistrikten f√∂r observationerna 30 och 45.\n\nlibrary(leaflet) # Install if not available\nBoston_map <- leaflet() %>% \n  addTiles() %>%\n  addMarkers(lat = fenway_park_lat_long[1], lng = fenway_park_lat_long[2], popup=\"Fenway park\") %>%\n  addMarkers(lat = Boston_census_data$latitude[30], lng = Boston_census_data$longitude[30], popup=\"Observation 30\") %>%\n  addMarkers(lat = Boston_census_data$latitude[45], lng = Boston_census_data$longitude[45], popup=\"Observation 45\") \n\nBoston_map # Show interactive map\n\n\n\n\n\n\nüí™ Uppgift 3.1\nG√∂r ett histogram f√∂r variabeln dist_fenway_park. Vilket av censusdistrikten har l√§ngst respektive kortast avst√•nd till Fenway park? Markera ut dessa distrikt i en interaktiv karta tillsammans med Fenway park.\n\n\n\n\n\n\nTips\n\n\n\nN√§r ni vet vad det l√§ngsta respektive kortaste avst√•ndet √§r s√• kan ni anv√§nda filter() funktionen f√∂r att filtrera Boston_census_data p√• ett l√§mpligt s√§tt.\n\n\n\n\n\n\n\n\nUppgift 3.1 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 3.2\nFinns det ett samband mellan dist_fenway_park och median_home_value?\n\n\n\n\n\n\nUppgift 3.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 3.3\nFinns det ett samband mellan dist_fenway_park och crime_rate?\n\n\n\n\n\n\nUppgift 3.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#enkel-linj√§r-regression",
    "href": "assignments/assignment1/Assignment1.html#enkel-linj√§r-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "4. Enkel linj√§r regression",
    "text": "4. Enkel linj√§r regression\nI detta avsnitt ska ni anpassa och tolka n√•gra enkla linj√§ra regressionsmodeller.\n\nüí™ Uppgift 4.1\nAnpassa en linj√§r regression med responsvariabel NOx och f√∂rklarande variabel employ_dist. Rita den anpassade regressionslinjen tillsammans med data i en l√§mplig figur. Beskriv resultaten och tolka modellen. Utf√∂r en modellvalidering via en residualanalys och kommentera modellens l√§mplighet. Om modellen inte anses l√§mplig, vilka antaganden har inte varit uppfyllda?\n\n\n\n\n\n\nUppgift 4.1 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 4.2\nAnv√§nd modellen i Uppgift 4.1 f√∂r att prediktera genomsnittsutsl√§ppet f√∂r observation 10 med employ_dist=10.5857 och ber√§kna dess residual.\n\n\n\n\n\n\nUppgift 4.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 4.3\nAnv√§nd Tukeys cirkel f√∂r att transformera variablerna i Uppgift 4.1 (avg√∂r sj√§lv vilken eller vilka av de tv√• som beh√∂ver transformeras). Anpassa en ny linj√§r regression p√• de transformerade data. Utf√∂r en modellvalidering (efter transformation) via en residualanalys och kommentera modellens l√§mplighet j√§mf√∂rt med modellen i Uppgift 4.1. Plotta den anpassade regressionen i icke-transformerad skala tillsammans med data (ocks√• i icke-transformerad skala) i en l√§mplig figur.\n\n\n\n\n\n\nTips\n\n\n\nT√§nk p√• att ta h√§nsyn till eventuella transformationer!\n\n\n\n\n\n\n\n\nUppgift 4.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 4.4\nAnv√§nd modellen i Uppgift 4.3 f√∂r att prediktera genomsnittsutsl√§ppet f√∂r observation 10 med employ_dist=10.5857 och ber√§kna dess residual. Kommentera resultaten j√§mf√∂rt med Uppgift 4.2.\n\n\n\n\n\n\nTips\n\n\n\nT√§nk p√• att ta h√§nsyn till eventuella transformationer!\n\n\n\n\n\n\n\n\nUppgift 4.4 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment1/Assignment1.html#multipel-linj√§r-regression",
    "href": "assignments/assignment1/Assignment1.html#multipel-linj√§r-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "5. Multipel linj√§r regression",
    "text": "5. Multipel linj√§r regression\nI detta avsnitt ska ni studera multipel linj√§ra regression.\n\nüí™ Uppgift 5.1\nAnpassa en linj√§r regression med responsvariabel logaritmerad median_home_value samt f√∂rklarande variabler lower_stat_pct och dummy-variabeln borders_charles. Tolka koefficienten f√∂r borders_charles.\n\n\n\n\n\n\nUppgift 5.1 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 5.2\nAnpassa en linj√§r regression med responsvariabel NOx samt f√∂rklarande variabler lower_stat_pct och dummy-variabeln borders_charles. Vad tror ni om den statistiska signifikansen f√∂r respektive f√∂rklarande variabel?\n\n\n\n\n\n\nUppgift 5.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 5.3\nAnv√§nd modellen i Uppgift 5.1 f√∂r att prediktera median_home_value f√∂r observation 30 och ber√§kna dess residual.\n\n\n\n\n\n\nTips\n\n\n\nT√§nk p√• att ta h√§nsyn till log-transformationen i den anpassade modellen!\n\n\n\n\n\n\n\n\nUppgift 5.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 5.4\nNi ska nu utveckla en prognosmodell f√∂r medianhuspriset median_home_value. Ni f√•r endast v√§lja mellan f√∂ljande f√∂rklarande variabler samt godtyckliga transformationer av dom (ni f√•r √§ven transformera responsen):\n\nbefore_1940_p\ncrime_rate\nradial_access\nNOx\ndist_fenway_park (som skapades i Avsnitt 3).\n\nDet finns \\(2^5 = 32\\) olika s√§tt att inkludera de olika f√∂rklarande variabler och d√§rmed 32 olika modeller man kan testa, plus i princip hur m√•nga som helst om vi ocks√• transformerar. Vi f√∂rv√§ntar oss naturligtvis inte att ni g√•r igenom varje m√∂jlig modell, men vi f√∂ruts√§tter att ni testar er fram metodiskt.\nF√∂r att utv√§rdera mellan olika modeller kan ni anv√§nda justerat R-kvadrat samt korsvalidering med 4 folds. Sortera inte `boston_census_data.Rdata slumpm√§ssigt n√§r ni korsvaliderar (data ligger redan i slumpm√§ssig ordning). Dela upp datasetet i fyra delar n√§r ni korsvaliderar (del 1: observationer 1-120, del 2: observationer 121-240, del 3: observationer 241-360, del 4: observationer 361-480).\n\n\n\n\n\n\nTips\n\n\n\nT√§nk p√• att ta h√§nsyn till eventuell transformation av responsvariabeln n√§r ni utf√∂r korsvalideringen. Korsvalideringen anv√§nder prediktionen \\(\\hat{y}\\) som √§r prediktionen av \\(y\\). Exempelvis, om ni har valt transformationen \\(\\log(y)\\) √§r modellens prediktion av responsen \\(\\widehat{\\log(y)}\\). N√§r ni korsvaliderar blir d√• \\(\\hat{y}=\\exp\\left(\\widehat{\\log(y)}\\right)\\) prediktionen av \\(y\\).\nOm ni anv√§nder reg_crossval() funktionen fr√•n kurspaketet sdakurs t√§nk d√• p√• tv√• saker:\n\nAnv√§nd argumentet obs_order = 1:480 f√∂r att inte data ska sorteras slumpm√§ssigt.\nFunktionen kan inte hantera en transformerad respons.\n\nVill man transformera responsen kan man f√∂lja korsvalideringsexemplet (med transformerad respons) i Lab 4.\n\n\n\n\n\n\n\n\nUppgift 5.4 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 5.5\nG√∂r en residualanalys av den valda modellen i Uppgift 5.3.\n\n\n\n\n\n\nUppgift 5.5 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 5.6\nAnv√§nd modellen i Uppgift 5.4 f√∂r att prediktera medianhuspriset f√∂r observationerna i datasetet Boston_districts_to_predict.RData. Skriv ut resultatet s√• att vi enkelt kan j√§mf√∂ra dina prognoser n√§r vi r√§ttar.\n\n\n\n\n\n\nTips\n\n\n\nT√§nk p√• att ta h√§nsyn till eventuella transformationer av de f√∂rklarande variablerna! Om ni har dist_fenway_park med i er prognosmodell beh√∂ver ni r√§kna ut dess v√§rde f√∂r observationerna i datasetet Boston_districts_to_predict.RData (genom att anv√§nda latitud och longitud variablerna s√•som i Avsnitt 3).\n\n\n\n\n\n\n\n\nUppgift 5.6 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html",
    "href": "assignments/assignment2/Assignment2.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installation av n√∂dv√§ndiga paket\n\n\n\nDen h√§r inl√§mningsuppgiften f√∂ruts√§tter att f√∂ljande paket finns installerade:\n\nmosaic\n\nPaket kan installeras via kommandot install.packages('packagename'), d√§r 'packagename' √§r namnet p√• paketet, t.ex 'mosaic'."
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#introduktion",
    "href": "assignments/assignment2/Assignment2.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\nI den f√∂rsta inl√§mningsuppgiften ska ni sj√§lvst√§ndigt i grupper om tre analysera ett dataset i programmeringsspr√•ket R. Till skillnad fr√•n datorlaborationerna finns det minimalt med kodexempel. Datorlaborationerna g√•r igenom de flesta momenten som behandlas i inl√§mningsuppgiften, s√• se till att g√∂ra klart dessa innan.\n\n\n\n\n\n\n\nInstruktioner\n\n\n\nI denna inl√§mningsuppgift ska ni analysera ett datamaterial ‚Ä¶ F√∂ljande variabler finns i datasetet boston_census_data.Rdata (ladda ner) ‚Ä¶\n\ntown: Stadsdel.\nlongitude: Longitud koordinat..\nlower_stat_pct: Procentandel underklass definerad som en av tv√•: (i) andel vuxna utan gymnasieutbildning eller (ii) andel m√§n som genomf√∂r okvalificerat arbete.\n\nROADMAP\nInl√§mningsuppgiften ska l√§mnas in i form av ett html dokument genererat av Quarto. Kontrollera noga att du inte har n√•gra felmeddelande och att dokumentet kompileras utan problem. Anv√§nd tydliga figurer och namnge axlarna med tydliga variabelnamn. Gl√∂m inte att skriva era namn ovanf√∂r ist√§llet f√∂r Namn 1, Namn 2 och Namn 3."
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#l√§sa-in-data",
    "href": "assignments/assignment2/Assignment2.html#l√§sa-in-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "0. L√§sa in data",
    "text": "0. L√§sa in data\n\nüí™ Uppgift 0.1\nLadda in dataseten Boston_census_data.Rdata och Boston_districts_to_predict.Rdata (l√§nkar f√∂r att ladda ner data finns i Instruktioner avsnittet ovan).\n\n\n\n\n\n\nUppgift 0.1 - Svar\n\n\n\n\n# Write your code here\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_census_data.RData?raw=true\"))"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#kriminalitet-i-boston",
    "href": "assignments/assignment2/Assignment2.html#kriminalitet-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Kriminalitet i Boston",
    "text": "1. Kriminalitet i Boston\nI detta avsnitt ska ni analysera kriminaliteten i Boston med hj√§lp av variabeln crime_rate.\n\nüí™ Uppgift 1.1\nVad kan man generellt s√§ga om kriminaliteten i censusdistrikten? Anv√§nd l√§mpliga figurer samt f√∂rdelningsm√•tt som underlag.\n\n\n\n\n\n\nUppgift 1.1 - Svar\n\n\n\nSkriv svaret h√§r. Vid behov skrivs matematiska symboler inom dollartecken, till exempel \\(\\overline{y} = \\sum^{n}_{i=1} y_i\\). Koden skrivs i R-rutan nedanf√∂r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 1.2\nVarierar brottsligheten i Boston beroende p√• den kategoriska variabeln town? Det finns 88 olika utfall av town (dvs 88 olika stadsdelar). V√§lj ut Boston East Boston, Boston Downtown,Cambridge, samt tv√• valfria stadsdelar f√∂r att besvara fr√•gan. Fr√•gan besvaras med hj√§lp av l√§mpligt valda figurer och statistiska m√•tt.\n\n\n\n\n\n\nTips\n\n\n\nSkapa en ny data frame som filtrerar Boston_census_data (till exempel genom filter() funktionen) utefter de stadsdelarna ni √§r intresserade utav innan ni p√•b√∂rjar analysen.\n\n\n\n\n\n\n\n\nUppgift 1.2 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here\n\n\n\n\n\nüí™ Uppgift 1.3\nVilka tre variabler i datasetet Boston_census_data korrelerar mest med brottslighet? Beskriv det parvisa sambandet mellan brottslighet och vardera av dessa tre variabler.\n\n\n\n\n\n\nTips\n\n\n\nKom ih√•g att korrelation √§r ett beroendem√•tt f√∂r numeriska variabler.\n\n\n\n\n\n\n\n\nUppgift 1.3 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#fastighetsskatt-i-boston",
    "href": "assignments/assignment2/Assignment2.html#fastighetsskatt-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Fastighetsskatt i Boston",
    "text": "2. Fastighetsskatt i Boston\nI detta avsnitt ska ni analysera fastighetsskatten i Boston med hj√§lp av variabeln tax_rate.\n\nüí™ Uppgift 2.1\nVad kan man generellt s√§ga om fastighetsskatten i censusdistrikten? Anv√§nd l√§mpliga figurer samt f√∂rdelningsm√•tt som underlag.\n\n\n\n\n\n\nUppgift 2.1 - Svar\n\n\n\nSkriv svaret h√§r.\n\n# Write your code here"
  },
  {
    "objectID": "R.html",
    "href": "R.html",
    "title": "R",
    "section": "",
    "text": "Kursen anv√§nder det popul√§ra statistiska programmeringsspr√•ket R. Programmet √§r helt gratis och kan laddas ner p√• alla datorer."
  },
  {
    "objectID": "R.html#rstudio",
    "href": "R.html#rstudio",
    "title": "R",
    "section": "RStudio",
    "text": "RStudio\nR √§r l√§ttast att jobba i fr√•n programmet RStudio. RStudio √§r en slags arbetsmilj√∂ byggd kring R. √Ñven RStudio √§r gratis."
  },
  {
    "objectID": "R.html#ladda-ner-r-och-rstudio",
    "href": "R.html#ladda-ner-r-och-rstudio",
    "title": "R",
    "section": "Ladda ner R och RStudio",
    "text": "Ladda ner R och RStudio\nDu m√•ste f√∂rst installera R och sen RStudio:\n\nR kan laddas ner h√§r.\nRStudio kan laddas ner h√§r.\n\nDen h√§r YouTube videon g√•r igenom alla steg i installationen.\nH√§r √§r v√•ra egna steg-efter-steg instruktioner:\n\nWindows\nApple/Mac"
  },
  {
    "objectID": "R.html#tre-dialekter-av-r",
    "href": "R.html#tre-dialekter-av-r",
    "title": "R",
    "section": "Tre dialekter av R",
    "text": "Tre dialekter av R\nMan kan dela upp R‚Äôs spr√•k i tre slags dialekter, dvs tre olika kommandon (syntax) f√∂r att g√∂ra ungef√§r samma sak:\n\nBase-R - (den ursprungliga) med dess s k dollar sign $ syntax\nFormula - syntax som via paketet Mosaic har utvecklats f√∂r undervisning i statistik\nTidyverse - en alternativ syntax utvecklat av personerna bakom RStudio.\n\n\n¬† ¬† \n\n\nI SDA1 kommer vi f√∂rs√∂ka anv√§nda Formula syntax som mycket som m√∂jligt, med inslag av Base-R. Tidyverse-kod kan ofta vara extremt effektiv, men tar f√∂r l√•ng tid att l√§ra sig p√• en grundkurs i statistik. Vi kommer ibland visa hur man g√∂r samma sak i de olika dialekterna, men p√• ett s√§tt som inte st√∂r fl√∂det f√∂r den student som helst vill h√•lla sig till ett s√§tt. Vi anv√§nder ikoner i marginalen som man kan klicka p√• f√∂r att se ett kommando i olika dialekter. Se t ex avsnittet om cheatsheets p√• denna sida f√∂r ett exempel (prova att klicka ikonerna i h√∂ger-marginalen)."
  },
  {
    "objectID": "R.html#guidertutorials",
    "href": "R.html#guidertutorials",
    "title": "R",
    "section": "Guider/Tutorials",
    "text": "Guider/Tutorials\n\nTutorial om hur man l√§ser in data fr√•n Excel och text-filer. üá¨üáß\nQuarto f√∂r att skriva kompletta rapporter med kod. üá¨üáß\nhtml | pdf | video p√• Athena\nDet kan bli lite trassel med svenska √•√§√∂ n√§r man skriver R kod eller arbetar med Quarto. H√§r √§r en guide om hur man √§ndrar s k teckenkodning i RStudio s√• R klarar av dessa svenska bokst√§ver."
  },
  {
    "objectID": "R.html#cheat-sheets",
    "href": "R.html#cheat-sheets",
    "title": "R",
    "section": "Cheat sheets",
    "text": "Cheat sheets\n\nMosaic-paketet  i R med dess sk formula syntax anv√§nds mycket under kursen och inneh√•ller grundl√§ggande statistiska metoder och grafik. Detta s k cheat sheet f√∂r mosaic sammanfattar de viktigaste metoderna i mosaic paketet. Klicka p√• ikonerna i marginalen om du √§r nyfiken p√• motsvarande cheatsheets f√∂r de andra tv√• dialekterna av R. Om du vill j√§mf√∂ra de olika dialekterna sida vid sida kan du titta p√• R Syntax Comparison cheat sheet.\n\n\n\n¬† \n\nDenna RStudio cheat sheet √§r r√§tt r√∂rig, men kan kanske vara anv√§ndbar efter att man sj√§lv bekantat sig lite med RStudio.\nKursens egna R-paket sda1 (se nedan) har ocks√• ett cheat sheet."
  },
  {
    "objectID": "R.html#datamaterial",
    "href": "R.html#datamaterial",
    "title": "R",
    "section": "Datamaterial",
    "text": "Datamaterial\n\nKursboken Stats: Data and Models kommer med √∂ver 500 olika datamaterial som hittas h√§r. Datamaterialen √§r i ofta i Excel-format, se denna guide om hur man l√§ser in data fr√•n Excel i R.\nKursens R-paket sda1 (se nedan) inneh√•ller ocks√• n√•gra datamaterial som kommer anv√§ndas under kursen."
  },
  {
    "objectID": "R.html#kursens-r-paket",
    "href": "R.html#kursens-r-paket",
    "title": "R",
    "section": "Kursens R-paket",
    "text": "Kursens R-paket\nKursen har ett eget R-paket sda1 med n√•gra hj√§lpfunktioner och datamaterial som anv√§nds p√• kursen.\ncheat sheet | manual\n\n\n\n\n\n\n\n\nInstallera kurspaketet\n\ninstall.packages(\"remotes\") \nlibrary(remotes)\ninstall_github(\"StatisticsSU/sda1paket\") \nlibrary(sda1)"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#analys-av-antalet-bes√∂k-till-webbsida",
    "href": "datorlab/lab5/DatorLab5.html#analys-av-antalet-bes√∂k-till-webbsida",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "4. Analys av antalet bes√∂k till webbsida",
    "text": "4. Analys av antalet bes√∂k till webbsida\nEn webbsida registrerade n√§r bes√∂kare bes√∂kte deras webbsida under ett dygn. H√§r √§r en grafisk illustration av antalet bes√∂k under dygnet, varje streck √§r ett bes√∂k vid en viss tidpunkt:\n\n\n\n\n\nAntalet bes√∂k f√∂r var och ett av dygnets timmar var\n\nvisits_per_hour = c(0, 1,  6,  0,  1,  0,  1,  0,  3,  0,  0,  0,  0,  2,  2, \n                    0,  1,  9,  1,  1,  0,  1,  0,  0)\n\nAntag att antalet bes√∂k per timme kan modelleras som oberoende Poissonf√∂rdelade variabler med parameter \\(\\lambda\\). Vi vill nu best√§mma det b√§sta v√§rdet p√• \\(\\lambda\\) genom att anv√§nda data. En vanlig skattning av \\(\\lambda\\) i en Poissonf√∂rdelning √§r medelv√§rdet \\(\\bar x\\) av data (det √§r t ex den skattning man f√•r med den s k maximum likelihoodmetoden).\n\nüí™ Uppgift 4.1\nSkatta parametern \\(\\lambda\\) fr√•n variabeln visits_per_hour .\n\n# Write your code here\n\n\n\nüí™ Uppgift 4.2\nF√∂retaget som driver webbsidan vill veta sannolikheten att de f√•r fler √§n 5 bes√∂kare under √•tminstone n√•gon av morgondagens 24 timmar. Anv√§nd din skattade Poissonmodell f√∂r att ber√§kna den sannolikheten. [hint: union och komplement].\n\n# Write your code here\n\n\n\nüí™ Uppgift 4.2\n\nUnders√∂k om Poissonf√∂rdelningen verkar anpassa dessa data bra. Du kan t ex unders√∂ka om det teoretiska v√§ntev√§rdet och variansen i den skattade Poissonmodellen ligger hyfsat n√§ra medelv√§rdet och stickprovsvariansen i data. Du kan ocks√• kolla hur sannolikt det faktiskt √§r att observera 9 st bes√∂k under en timme (som vi ju ser i data mellan kl 17-18) i den skattade Poissonmodellen.\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#r√§kna-med-sannolikhetsf√∂rdelningar",
    "href": "datorlab/lab5/DatorLab5.html#r√§kna-med-sannolikhetsf√∂rdelningar",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. R√§kna med sannolikhetsf√∂rdelningar",
    "text": "1. R√§kna med sannolikhetsf√∂rdelningar\n\nüí™ Uppgift 1.1\nL√•t \\(X\\sim \\mathrm{Pois}(\\lambda)\\) med \\(\\lambda = 2\\). Ber√§kna \\(P(X=2)\\) och \\(P(X\\leq 3)\\). Hint: ?ppois\n\n# Write your code here\n\n\n\nüí™ Uppgift 1.2\nI valet 2022 fick Liberalerna 4.61% av r√∂sterna. I en unders√∂kning bland totalt 1046 personser angav 30 personer att de skulle r√∂sta p√• Liberalerna om det var val idag. Kan det vara s√• att Liberalernas r√∂stningsandel √§r (ungef√§r) of√∂r√§ndrad p√• 4.61%, eller tyder den nya unders√∂kningen p√• n√•got annat? Unders√∂k detta genom att rita upp ett stapeldiagram √∂ver sannolikhetsf√∂rdelningen \\(P(X=x)\\) f√∂r \\(X \\sim \\mathrm{Binom}\\operatorname{}(n= 1046, p = 0.0461)\\) f√∂r x-v√§rdena xvalues = 0:100. √Ñr resultatet fr√•n valunders√∂kningen ett sannolikt utfall? Om inte, vilket slutsats drar du om Liberalernas faktiska v√§ljarandel?\n\n# Write your code here\n\n\n\nüí™ Uppgift 1.3\nBer√§kna \\(P(X \\leq 30)\\) f√∂r \\(X \\sim \\mathrm{Binom}(n= 1046, p = 0.0461)\\) genom att anv√§nda binomialf√∂rdelningen. J√§mf√∂r svaret med samma sannolikhet fr√•n en normalapproximation (se F15):\n\\[\nX\\sim \\mathrm{Binom}(n,p) \\text{ approximeras med } X\\sim \\mathrm{N}\\Big(\\mu=np, \\sigma = \\sqrt{n p (1-p)}\\Big)\n\\]\nObservera att jag skrivit normalf√∂rdelningen med standardavvikelse som andra argument h√§r. Precis som R g√∂r.\n\n# Write your code here"
  }
]