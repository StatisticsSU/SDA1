[
  {
    "objectID": "Del2.html",
    "href": "Del2.html",
    "title": "Del II - Sannolikhetsmodeller och Inferens, 7.5 hp",
    "section": "",
    "text": "I kursens andra momentet behandlas inledningsvis sannolikheter, slumpvariabler och sannolikhetsfördelningar. En central del i momentet är inferens, dvs. statistiska metoder för att dra slutsatser om olika fenomen från data, bl a samband från regressionsanalys. Kursen avslutas med en introduktion till beslutsfattade under osäkerhet.\n\nFörkortningen SDM står för kursboken Stats: Data and Models 5:e upplagan, global edition.\nUnder vissa föreläsningar länkar vi till Extramaterial. Det är material som inte krävs för att klara kursen, men som den nyfikne kan läsa för att få en djupare förståelse.\n\nFöreläsningar\nFöreläsning 12 - Osäkerhet och Sannolikhet.\nLäs: SDM Kapitel 12 och 13 | Slides\nInteraktivt: slantsingling\nExtramaterial: TedTalk om sannolikheter\nFöreläsning 13 - Betingade sannolikheter och Bayes sats.\nLäs: SDM Kapitel 13 | Slides\nInteraktivt: bayessats\nExtramaterial: artikel om Bayes sats och snabbtest för Covid-19\nFöreläsning 14 - Slumpvariabler och deras egenskaper.\nLäs: SDM Kapitel 14 | Slides\nInteraktivt: normalfördelningen\nFöreläsning 15 - Sannolikhetsmodeller I\nLäs: SDM Kapitel 15.1, 15.2, 15.3, 15.6 | Slides\nInteraktivt: bernoullifördelning | geometrisk fördelning | binomialfördelningen | likformig | normalfördelning\nKod: geometric.R\nFöreläsning 16 - Sannolikhetsmodeller II\nLäs: SDM Kapitel 5.3, 14.4, 15.7 | Slides\nInteraktivt: Poissonfördelningen | maximum likelihood - Poisson | exponential | student-t | allmän student-t\nKod: exponential.R\nExtramaterial: Notebook - maximum likelihood för Poisson | Notebook - student-t\nFöreläsning 17 - Samplingfördelningar och konfidensintervall för en andel.\nLäs: SDM Kapitel 16.1-16.5 | Slides\nInteraktivt: samplingfördelning - liten ändlig population | stora talens lag - normalapproximation för en andel | samplingfördelning för andel - ändlig population | konfidensintervall för en andel\nFöreläsning 18 - Konfidensintervall för ett väntevärde. Stora talens lag. Centrala gränsvärdessatsen.\nLäs: SDM Kapitel 17 | Slides\nInteraktivt: stora talens lag | centrala gränsvärdessatsen\nExtramaterial: Notebook - stora talens lag | Notebook - centrala gränsvärdessatsen\nKod: konfidensintervall laxar\nFöreläsning 19 - Hypotestest.\nLäs: SDM Kapitel 18 (ej Random matters på sid 579) | Slides\nInteraktivt: hypotestest - väntevärde\nFöreläsning 20 - Inferens i linjär regression - populationsmodell och samplingfördelning\nLäs: SDM Kapitel 23.1-23.3 | Slides\nKod: regression lifespan data\nInteraktivt: samplingfördelning regression\nExtramaterial: kod för residualanalys på simulerad regressionsdata\nFöreläsning 21 - Inferens i linjär regression - konfidensintervall, hypotestest och prediktionsintervall\nLäs: SDM Kapitel 23.3-23.6 | Slides\n\nFöreläsning 22 - Hypotestest och jämföra grupper.\nLäs: SDM Kapitel 19, 20.4-20.5, 21.1-21.3 | Slides\nKod: oberoende grupper - laxar | parade grupper - online försäkringar\nInteraktivt: hypotestest fel typ I och II\nFöreläsning 23 - \\(\\chi^2\\) goodness-of-fit test. Optimala beslut under osäkerhet.\nLäs: SDM 22.1 | Slides\nInteraktivt: chi2-fördelningen\nFöreläsning 24 - Räkning av övningstenta.\nLäs: Slides\nVideoföreläsning - Maximum likelihood och Bayesiansk inferens.\nLäs: Slides\nInteraktivt: maximum likelihood - Poisson | betafördelningen\nExtramaterial: notebook - matematisk härledning av maximum likelihood skattningen i Poissonmodellen\n\n\nRäkneövningar\nÖvningarna i kursboken Stats: Data and Models (SDM) hänvisas till med kapitelnummer följt av övningsnummer.\nÖvning 7 - Sannolikheter för händelser. Kombinatorik.\nUppgifter: SDM 12.2, 12.5, 12.7, 12.9, 12.12, 12.16, 12.21, 12.27, 12.29, 12.31, 12.34, 12.36, 12.39, 12.41, 12.49, 12.52.\nÖvning 8 - Oberoende händelser. Betingning och Bayes sats.\nUppgifter: SDM 13.1, 13.5, 13.7, 13.10, 13.12, 13.14, 13.18, 13.21, 13.24, 13.31, 13.47, 13.49.\nÖvning 9 - Slumpvariabler, väntevärde och standardavvikelse.\nUppgifter: SDM 14.1, 14.3, 14.9a, 14.11, 14.13, 14.21, 14.26, 14.33, 14.36, 14.43, 14.54.\nÖvning 10 - Sannolikhetsmodeller I.\nUppgifter: SDM 15.1, 15.3, 15.5, 15.18, 15.19, 15.21, 15.28, 15.29, 15.31, 15.41, 15.45.\nÖvning 11 - Sannolikhetsmodeller II.\nUppgifter: SDM 15.7, 15.11, 15.12, 15.49, 15.59, 15.60, 15.61, 15.62.\nÖvning 12 - Konfidensintervall.\nUppgifter: SDM 16.2, 16.3, 16.5, 16.7, 16.14, 16.16, 16.27a-c), 16.31, 17.23, 17.29, 17.31, 17.56.\nÖvning 13 - Hypotestest.\nUppgifter: SDM 18.1, 18.4, 18.5, 18.8, 18.10, 18.14, 18.16, 18.23, 18.27, 18.45, 18.50.\nÖvning 14 - Inferens för regression.\nUppgifter: SDM 23.1, 23.3, 23.5, 23.7, 23.9, 23.13, 23.15, 23.17.\nÖvning 15 - Jämföra grupper och chi2-test.\nUppgifter: SDM 20.11, 20.13, 20.15, 20.62, 21.19, 21.21.\n\n\nDatorlaborationer\nDatorlaboration 5 - Räkna med fördelningar i R. Simulering.\nUppgifter: html | quarto\nDatorlaboration 6 - Konfidensintervall, hypotesttest och centrala gränsvärdessatsen.\nUppgifter: html | quarto\nDatorlaboration 7 - Multipel linjär regression - inferens.\nUppgifter: html | quarto\n\n\nInlämningsuppgift\nInlämningsuppgift 2.\nUppgifter: instruktioner i html | quarto för inlämning"
  },
  {
    "objectID": "interaktiv.html",
    "href": "interaktiv.html",
    "title": "Interaktivt lärande",
    "section": "",
    "text": "Här samlar vi alla interaktiva grafer (widgets) som vi länkar till från slides.\nExtramaterial: till varje interaktiv graf finns en interaktiv/reaktiv notebook med mer information, här finns en lista med alla notebooks. Dessa notebook ingår inte i kursen, men länkas här för den nyfikne studenten som vill läsa lite mer för en djupare förståelse."
  },
  {
    "objectID": "interaktiv.html#del-1---dataanalys-och-regression",
    "href": "interaktiv.html#del-1---dataanalys-och-regression",
    "title": "Interaktivt lärande",
    "section": "Del 1 - Dataanalys och Regression",
    "text": "Del 1 - Dataanalys och Regression\n\nFöreläsning 3\nVal av antal bins i histogram:  widget | notebook\n\n\nFöreläsning 8\nEnkel linjär regression  widget - utan population\nwidget - med population | notebook\n\n\nFöreläsning 9\nIcke-linjär regression:  widget | notebook"
  },
  {
    "objectID": "interaktiv.html#del-2---sannolikhetsmodeller-och-inferens",
    "href": "interaktiv.html#del-2---sannolikhetsmodeller-och-inferens",
    "title": "Interaktivt lärande",
    "section": "Del 2 - Sannolikhetsmodeller och Inferens",
    "text": "Del 2 - Sannolikhetsmodeller och Inferens\n\nFöreläsning 12\nSlantsingling och stora talens lag slantsingling - widget | slantsingling - notebook\n\n\nFöreläsning 13\nBayes sats:  widget | notebook\n\n\nFöreläsning 14\nNormalfördelningen  widget | notebook\n\n\nFöreläsning 15\nBernoullifördelning  widget\ngeometrisk fördelning  widget\nbinomialfördelning:  widget\nPoissonfördelning  widget\nMaximum likelihoodskattning - Poissonfördelning:  widget\n\n\nFöreläsning 16\nlikformig fördelning:  widget | notebook\nexponentialfördelning:  widget | notebook\nStudent-t fördelning:  widget | notebook\nAllmän student-t fördelning:  widget | notebook\n\n\nFöreläsning 17\nSamplingfördelning - ändlig population widget | notebook\nSamplingfördelning för en andel - ändlig population widget | notebook\nStora talens lag - normalapproximation av en andel widget\nKonfidensintervall för en andel - normalapproximation widget\n\n\nFöreläsning 18\nStora talens lag:  normalpopulation - widget | normalpopulation - notebook\nCentrala gränsvärdessatsen:  widget | notebook\nSamplingfördelning för ett medelvärde widget | notebook\n\n\nFöreläsning 19\nHypotesttest väntevärde widget\n\n\nFöreläsning 20\nsamplingfördelning regression  widget | notebook\n\n\nFöreläsning 21\nHypotestest - fel av typ I och II:  widget | notebook\n\n\nFöreläsning 22\nChi2-fördelning:  widget | notebook\n\n\nVideoföreläsning\nBeta-fördelning:  widget"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Kursens innehåll\n\nData finns numera överallt i samhället. Kursen Statistik och dataanalys I ger dig grunderna för att förstå och använda data, både som samhällsmedborgare och som avancerad dataanalytiker.\n\nKursen ger dig en översikt av metoder för statistisk dataanalys och dess många tillämpningar. En introduktion till dataanalys följs av praktisk datahantering i det populära statistiska programspråket R. Samband mellan variabler analyseras, och du tränas i hur statistiska modeller kan användas för att förutsäga nya data. Slutsatser från data är alltid osäkra och en viktig del av kursen är därför sannolikhetsberäkningar. Sannolikhetsteorin används sedan i de inferensmetoder som gör det möjligt att dra korrekta slutsatser från data och fatta optimala beslut under osäkerhet.\nDu lär dig att utföra dataanalyser i praktiken, bl a genom datorlaborationer och två inlämningsuppgifter, men kursen ger dig även en kritisk blick på statistik som gör att du kan ifrågasätta, tolka och söka ny information för att bättre svara på olika frågeställningar.\nKursen består av två delar:\n\nDataanalys och regression, 7.5 hp. I det här momentet ingår insamling, bearbetning, visualisering och sammanfattning av data i programspråket R. En stor del av momentet behandlar sambands- och regressionsanalys som utmynnar i metoder för prediktion.\nSannolikhetsmodeller och inferens, 7.5 hp. I kursens andra momentet behandlas sannolikheter, slumpvariabler och sannolikhetsfördelningar. En central del i momentet är inferens, dvs. statistiska metoder för att dra slutsatser om olika fenomen från data. Kursen avslutas med en introduktion till beslutsfattade under osäkerhet.\n\n\n\nKurslitteratur\n\nDe Veaux, R., Velleman, P. och Bock, D. (2021). Stats: Data and Models, 5:e upplagan, Pearson Global Edition, ISBN 9781292362212. Boken förkortas SDM nedan. Boken finns att köpa som fysisk bok på Akademibokhandeln Frescati eller City, eller online på Adlibris och Bokus. En digital version finns att köpa här.\nYtterligare kompletterande material som delas ut under kursens gång.\n\n\n\nKursstruktur\nKursen består av föreläsningar, räkneövningar och datorlaborationer. Se respektive del av kursen för detaljer: Dataanalys och regression, 7.5 hp. och Sannolikhetsmodeller och inferens, 7.5 hp..\n\n\n\nSchema\nKursens schema finns på TimeEdit. Ett tips är att välja Prenumerera i övre högra hörnet på TimeEdit och sen klistra in länken i ditt kalenderprogram på mobilen.\n\n\nFormel- och tabellsamlingar\n\nFormel- och tabellsamling innehåller de flesta av kursens formler och tabeller och kommer att delas ut under salstentamen.\nTabellsamling är en webb-version av tabellerna i Formel- och tabellsamling.\n\n\n\nInteraktivt material\nPå vissa delar av kursen använder vi interaktivt material för att underlätta lärandet. De interaktiva applikationerna kommer vara länkade från föreläsningsslides och under respektive föreläsning. En sida med alla applikationer finns här.\n\n\nLärare\n\n\n\n\nMattias VillaniKursansvarig och FöreläsareProfessor\n\n\n\nMatias QuirozFöreläsareUniversitetslektor\n\n\n\n\n\nMona SfaxiÖvningar, Datorövningar och JourMasterexamen i Statistik\n\n\n\nJon LachmannDatorövningarMasterexamen i Statistik\n\n\n\n\n\nGamla tentor med lösningar\n\n2023-02-10 [Obs! visas inte för studenter!]"
  },
  {
    "objectID": "Del1.html",
    "href": "Del1.html",
    "title": "Del I - Dataanalys och Regression, 7.5 hp",
    "section": "",
    "text": "I momentet ingår insamling, bearbetning, visualisering och sammanfattning av data i programspråket R. En stor del av momentet behandlar sambands- och regressionsanalys som utmynnar i metoder för prediktion.\n\nFörkortningen SDM står för kursboken Stats: Data and Models 5:e upplagan, global edition.\nUnder vissa föreläsningar länkar vi till Extramaterial. Det är material som inte krävs för att klara kursen, men som den nyfikne kan läsa för att få en djupare förståelse.\n\nFöreläsningar\nFöreläsning 1 - Introduktion.\nLäs: SDM Kapitel 1 | Slides\nFöreläsning 2 - Kort introduktion till R. \nLäs: Slides\nKod: Kod\nData: SmartPhones | CAPM\nFöreläsning 3 - Hantera och beskriva data.\nLäs: SDM Kapitel 2 | Slides\nInteraktivt: widget - histogram\nFöreläsning 4 - Samband mellan kategoriska variabler.\nLäs: SDM Kapitel 3 | Slides\nFöreläsning 5 - Jämföra fördelningar. Tidsserier. Transformationer.\nLäs: SDM Kapitel 4 | Slides\nFöreläsning 6 - Standardisering och normalmodellen.\nLäs: SDM Kapitel 5 | Slides\nFöreläsning 7 - Samband mellan numeriska variabler.\nLäs: SDM Kapitel 6 | Slides\nFöreläsning 8 - Enkel linjär och icke-linjär regression.\nLäs: SDM Kapitel 7 | Slides\nwidget - linjär regression utan population | widget - linjär regression med population\nFöreläsning 9 - Multipel linjär regression och modellval.\nLäs: SDM Kapitel 8-9 | Slides\nExtramaterial: widget - icke-linjär regression\nFöreläsning 10 - Populationer och stickprov. Undersökningar och experiment.\nLäs: SDM 10.1-10.3 och 11.1-11.2 | Slides \nFöreläsning 11 - Sammanfattning\nLäs: Slides\n\n\nRäkneövningar\nÖvningarna i kursboken Stats: Data and Models (SDM) hänvisas till med kapitelnummer följt av övningsnummer.\nÖvning 1 - Beskrivande statistik.\nUppgifter: SDM 2.1, 2.2, 2.6, 2.7, 2.9, 2.11, 2.12, 2.14, 2.15, 2.16, 2.17, 2.20, 2.21, 2.24.\nÖvning 2 - Samband mellan kategoriska variabler. Transformationer.\nUppgifter: SDM 3.1, 3.3, 3.5, 3.6, 3.7, 3.9, 3.25, 3.31, 3.39, 3.41, 3.47, 4.1, 4.3, 4.14, 4.17, 4.45.\nÖvning 3 - Standarisering och normalmodellen.\nUppgifter: SDM 5.1, 5.2, 5.4, 5.5, 5.8, 5.10, 5.14, 5.16, 5.17, 5.30, 5.42, 5.48.\nÖvning 4 - Samband mellan numeriska variabler. Korrelation och enkel linjär regression.\nUppgifter: SDM 6.2, 6.3, 6.5, 6.6, 6.9, 6.14, 6.20, 7.1, 7.2, 7.3, 7.4, 7.5, 7.7, 7.9, 7.11, 7.13, 7.15, 7.19, 7.23, 7.27, 7.52.\nÖvning 5 - Multipel linjär regression.\nUppgifter: SDM Kapitel 8.18, 8.20, 9.1, 9.2, 9.3, 9.4, 9.5, 9.6, 9.9, 9.11, 9.14, 9.16, 9.22, 9.23, 9.28.\nÖvning 6 - Repetition.\nRepetitionstillfälle.\n\n\nDatorlaborationer\nDatorlaboration 1 - Introduktion till R.\nUppgifter: html\nDatorlaboration 2 - Beskrivande statistik och visualisering i R.\nUppgifter: html | quarto\nDatorlaboration 3 - Samband mellan två kategoriska variabler. Samband mellan en kategorisk och en numerisk variabel. Tidsserier.\nUppgifter: html | quarto\nDatorlaboration 4 - Korrelation. Enkel och multipel linjär samt icke-linjär regression.\nUppgifter: html | quarto\n\n\nInlämningsuppgift\nInlämningsuppgift 1.\nUppgifter: html | quarto"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#normalfördelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#normalfördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Normalfördelning",
    "text": "Normalfördelning\nTabellen ger sannolikheten \\(\\Phi(z) = P(Z\\leq z)\\) för olika \\(z\\) där \\(Z\\) är standardnormal, \\(Z\\sim N(0,1)\\).\nSannolikheter i den vänstra svansen fås genom symmetri: \\(P(Z\\leq \\textminus z) = 1-P(Z\\leq z)\\).\n\n\n     \n\n\nAndra decimalen i \\(z\\)\n\n\n\n\n\n \n  \n      \n    0.00 \n    0.01 \n    0.02 \n    0.03 \n    0.04 \n    0.05 \n    0.06 \n    0.07 \n    0.08 \n    0.09 \n  \n \n\n  \n    0.0 \n    0.5000 \n    0.5040 \n    0.5080 \n    0.5120 \n    0.5160 \n    0.5199 \n    0.5239 \n    0.5279 \n    0.5319 \n    0.5359 \n  \n  \n    0.1 \n    0.5398 \n    0.5438 \n    0.5478 \n    0.5517 \n    0.5557 \n    0.5596 \n    0.5636 \n    0.5675 \n    0.5714 \n    0.5753 \n  \n  \n    0.2 \n    0.5793 \n    0.5832 \n    0.5871 \n    0.5910 \n    0.5948 \n    0.5987 \n    0.6026 \n    0.6064 \n    0.6103 \n    0.6141 \n  \n  \n    0.3 \n    0.6179 \n    0.6217 \n    0.6255 \n    0.6293 \n    0.6331 \n    0.6368 \n    0.6406 \n    0.6443 \n    0.6480 \n    0.6517 \n  \n  \n    0.4 \n    0.6554 \n    0.6591 \n    0.6628 \n    0.6664 \n    0.6700 \n    0.6736 \n    0.6772 \n    0.6808 \n    0.6844 \n    0.6879 \n  \n  \n    0.5 \n    0.6915 \n    0.6950 \n    0.6985 \n    0.7019 \n    0.7054 \n    0.7088 \n    0.7123 \n    0.7157 \n    0.7190 \n    0.7224 \n  \n  \n    0.6 \n    0.7257 \n    0.7291 \n    0.7324 \n    0.7357 \n    0.7389 \n    0.7422 \n    0.7454 \n    0.7486 \n    0.7517 \n    0.7549 \n  \n  \n    0.7 \n    0.7580 \n    0.7611 \n    0.7642 \n    0.7673 \n    0.7704 \n    0.7734 \n    0.7764 \n    0.7794 \n    0.7823 \n    0.7852 \n  \n  \n    0.8 \n    0.7881 \n    0.7910 \n    0.7939 \n    0.7967 \n    0.7995 \n    0.8023 \n    0.8051 \n    0.8078 \n    0.8106 \n    0.8133 \n  \n  \n    0.9 \n    0.8159 \n    0.8186 \n    0.8212 \n    0.8238 \n    0.8264 \n    0.8289 \n    0.8315 \n    0.8340 \n    0.8365 \n    0.8389 \n  \n  \n    1.0 \n    0.8413 \n    0.8438 \n    0.8461 \n    0.8485 \n    0.8508 \n    0.8531 \n    0.8554 \n    0.8577 \n    0.8599 \n    0.8621 \n  \n  \n    1.1 \n    0.8643 \n    0.8665 \n    0.8686 \n    0.8708 \n    0.8729 \n    0.8749 \n    0.8770 \n    0.8790 \n    0.8810 \n    0.8830 \n  \n  \n    1.2 \n    0.8849 \n    0.8869 \n    0.8888 \n    0.8907 \n    0.8925 \n    0.8944 \n    0.8962 \n    0.8980 \n    0.8997 \n    0.9015 \n  \n  \n    1.3 \n    0.9032 \n    0.9049 \n    0.9066 \n    0.9082 \n    0.9099 \n    0.9115 \n    0.9131 \n    0.9147 \n    0.9162 \n    0.9177 \n  \n  \n    1.4 \n    0.9192 \n    0.9207 \n    0.9222 \n    0.9236 \n    0.9251 \n    0.9265 \n    0.9279 \n    0.9292 \n    0.9306 \n    0.9319 \n  \n  \n    1.5 \n    0.9332 \n    0.9345 \n    0.9357 \n    0.9370 \n    0.9382 \n    0.9394 \n    0.9406 \n    0.9418 \n    0.9429 \n    0.9441 \n  \n  \n    1.6 \n    0.9452 \n    0.9463 \n    0.9474 \n    0.9484 \n    0.9495 \n    0.9505 \n    0.9515 \n    0.9525 \n    0.9535 \n    0.9545 \n  \n  \n    1.7 \n    0.9554 \n    0.9564 \n    0.9573 \n    0.9582 \n    0.9591 \n    0.9599 \n    0.9608 \n    0.9616 \n    0.9625 \n    0.9633 \n  \n  \n    1.8 \n    0.9641 \n    0.9649 \n    0.9656 \n    0.9664 \n    0.9671 \n    0.9678 \n    0.9686 \n    0.9693 \n    0.9699 \n    0.9706 \n  \n  \n    1.9 \n    0.9713 \n    0.9719 \n    0.9726 \n    0.9732 \n    0.9738 \n    0.9744 \n    0.9750 \n    0.9756 \n    0.9761 \n    0.9767 \n  \n  \n    2.0 \n    0.9772 \n    0.9778 \n    0.9783 \n    0.9788 \n    0.9793 \n    0.9798 \n    0.9803 \n    0.9808 \n    0.9812 \n    0.9817 \n  \n  \n    2.1 \n    0.9821 \n    0.9826 \n    0.9830 \n    0.9834 \n    0.9838 \n    0.9842 \n    0.9846 \n    0.9850 \n    0.9854 \n    0.9857 \n  \n  \n    2.2 \n    0.9861 \n    0.9864 \n    0.9868 \n    0.9871 \n    0.9875 \n    0.9878 \n    0.9881 \n    0.9884 \n    0.9887 \n    0.9890 \n  \n  \n    2.3 \n    0.9893 \n    0.9896 \n    0.9898 \n    0.9901 \n    0.9904 \n    0.9906 \n    0.9909 \n    0.9911 \n    0.9913 \n    0.9916 \n  \n  \n    2.4 \n    0.9918 \n    0.9920 \n    0.9922 \n    0.9925 \n    0.9927 \n    0.9929 \n    0.9931 \n    0.9932 \n    0.9934 \n    0.9936 \n  \n  \n    2.5 \n    0.9938 \n    0.9940 \n    0.9941 \n    0.9943 \n    0.9945 \n    0.9946 \n    0.9948 \n    0.9949 \n    0.9951 \n    0.9952 \n  \n  \n    2.6 \n    0.9953 \n    0.9955 \n    0.9956 \n    0.9957 \n    0.9959 \n    0.9960 \n    0.9961 \n    0.9962 \n    0.9963 \n    0.9964 \n  \n  \n    2.7 \n    0.9965 \n    0.9966 \n    0.9967 \n    0.9968 \n    0.9969 \n    0.9970 \n    0.9971 \n    0.9972 \n    0.9973 \n    0.9974 \n  \n  \n    2.8 \n    0.9974 \n    0.9975 \n    0.9976 \n    0.9977 \n    0.9977 \n    0.9978 \n    0.9979 \n    0.9979 \n    0.9980 \n    0.9981 \n  \n  \n    2.9 \n    0.9981 \n    0.9982 \n    0.9982 \n    0.9983 \n    0.9984 \n    0.9984 \n    0.9985 \n    0.9985 \n    0.9986 \n    0.9986"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#student-t-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#student-t-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Student-\\(t\\) fördelning",
    "text": "Student-\\(t\\) fördelning\n\n\n      \n\n\n\n\n\n\n\nKonfidensnivå: \n 80%\n 90%\n 95%\n 98%\n 99%\n\n\nTvåsidig sannolikhet: \n0.200\n0.100\n0.050\n0.020\n0.010\n\n\nEnsidig sannolikhet: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    3.078 \n    6.314 \n    12.706 \n    31.821 \n    63.657 \n  \n  \n    2 \n    1.886 \n    2.920 \n    4.303 \n    6.965 \n    9.925 \n  \n  \n    3 \n    1.638 \n    2.353 \n    3.182 \n    4.541 \n    5.841 \n  \n  \n    4 \n    1.533 \n    2.132 \n    2.776 \n    3.747 \n    4.604 \n  \n  \n    5 \n    1.476 \n    2.015 \n    2.571 \n    3.365 \n    4.032 \n  \n  \n    6 \n    1.440 \n    1.943 \n    2.447 \n    3.143 \n    3.707 \n  \n  \n    7 \n    1.415 \n    1.895 \n    2.365 \n    2.998 \n    3.499 \n  \n  \n    8 \n    1.397 \n    1.860 \n    2.306 \n    2.896 \n    3.355 \n  \n  \n    9 \n    1.383 \n    1.833 \n    2.262 \n    2.821 \n    3.250 \n  \n  \n    10 \n    1.372 \n    1.812 \n    2.228 \n    2.764 \n    3.169 \n  \n  \n    11 \n    1.363 \n    1.796 \n    2.201 \n    2.718 \n    3.106 \n  \n  \n    12 \n    1.356 \n    1.782 \n    2.179 \n    2.681 \n    3.055 \n  \n  \n    13 \n    1.350 \n    1.771 \n    2.160 \n    2.650 \n    3.012 \n  \n  \n    14 \n    1.345 \n    1.761 \n    2.145 \n    2.624 \n    2.977 \n  \n  \n    15 \n    1.341 \n    1.753 \n    2.131 \n    2.602 \n    2.947 \n  \n  \n    16 \n    1.337 \n    1.746 \n    2.120 \n    2.583 \n    2.921 \n  \n  \n    17 \n    1.333 \n    1.740 \n    2.110 \n    2.567 \n    2.898 \n  \n  \n    18 \n    1.330 \n    1.734 \n    2.101 \n    2.552 \n    2.878 \n  \n  \n    19 \n    1.328 \n    1.729 \n    2.093 \n    2.539 \n    2.861 \n  \n  \n    20 \n    1.325 \n    1.725 \n    2.086 \n    2.528 \n    2.845 \n  \n  \n    21 \n    1.323 \n    1.721 \n    2.080 \n    2.518 \n    2.831 \n  \n  \n    22 \n    1.321 \n    1.717 \n    2.074 \n    2.508 \n    2.819 \n  \n  \n    23 \n    1.319 \n    1.714 \n    2.069 \n    2.500 \n    2.807 \n  \n  \n    24 \n    1.318 \n    1.711 \n    2.064 \n    2.492 \n    2.797 \n  \n  \n    25 \n    1.316 \n    1.708 \n    2.060 \n    2.485 \n    2.787 \n  \n  \n    26 \n    1.315 \n    1.706 \n    2.056 \n    2.479 \n    2.779 \n  \n  \n    27 \n    1.314 \n    1.703 \n    2.052 \n    2.473 \n    2.771 \n  \n  \n    28 \n    1.313 \n    1.701 \n    2.048 \n    2.467 \n    2.763 \n  \n  \n    29 \n    1.311 \n    1.699 \n    2.045 \n    2.462 \n    2.756 \n  \n  \n    30 \n    1.310 \n    1.697 \n    2.042 \n    2.457 \n    2.750 \n  \n  \n    32 \n    1.309 \n    1.694 \n    2.037 \n    2.449 \n    2.738 \n  \n  \n    35 \n    1.306 \n    1.690 \n    2.030 \n    2.438 \n    2.724 \n  \n  \n    40 \n    1.303 \n    1.684 \n    2.021 \n    2.423 \n    2.704 \n  \n  \n    45 \n    1.301 \n    1.679 \n    2.014 \n    2.412 \n    2.690 \n  \n  \n    50 \n    1.299 \n    1.676 \n    2.009 \n    2.403 \n    2.678 \n  \n  \n    60 \n    1.296 \n    1.671 \n    2.000 \n    2.390 \n    2.660 \n  \n  \n    75 \n    1.293 \n    1.665 \n    1.992 \n    2.377 \n    2.643 \n  \n  \n    100 \n    1.290 \n    1.660 \n    1.984 \n    2.364 \n    2.626 \n  \n  \n    120 \n    1.289 \n    1.658 \n    1.980 \n    2.358 \n    2.617 \n  \n  \n    140 \n    1.288 \n    1.656 \n    1.977 \n    2.353 \n    2.611 \n  \n  \n    180 \n    1.286 \n    1.653 \n    1.973 \n    2.347 \n    2.603 \n  \n  \n    250 \n    1.285 \n    1.651 \n    1.969 \n    2.341 \n    2.596 \n  \n  \n    400 \n    1.284 \n    1.649 \n    1.966 \n    2.336 \n    2.588 \n  \n  \n    1000 \n    1.282 \n    1.646 \n    1.962 \n    2.330 \n    2.581 \n  \n  \n    oändligt \n    1.282 \n    1.645 \n    1.960 \n    2.326 \n    2.576"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#chi2-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#chi2-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(\\chi^2\\)-fördelning",
    "text": "\\(\\chi^2\\)-fördelning\n\n\n  \n\n\n\n\n\n\n\nSannolikhet i höger svans: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    2.706 \n    3.841 \n    5.024 \n    6.635 \n    7.879 \n  \n  \n    2 \n    4.605 \n    5.991 \n    7.378 \n    9.210 \n    10.597 \n  \n  \n    3 \n    6.251 \n    7.815 \n    9.348 \n    11.345 \n    12.838 \n  \n  \n    4 \n    7.779 \n    9.488 \n    11.143 \n    13.277 \n    14.860 \n  \n  \n    5 \n    9.236 \n    11.070 \n    12.833 \n    15.086 \n    16.750 \n  \n  \n    6 \n    10.645 \n    12.592 \n    14.449 \n    16.812 \n    18.548 \n  \n  \n    7 \n    12.017 \n    14.067 \n    16.013 \n    18.475 \n    20.278 \n  \n  \n    8 \n    13.362 \n    15.507 \n    17.535 \n    20.090 \n    21.955 \n  \n  \n    9 \n    14.684 \n    16.919 \n    19.023 \n    21.666 \n    23.589 \n  \n  \n    10 \n    15.987 \n    18.307 \n    20.483 \n    23.209 \n    25.188 \n  \n  \n    11 \n    17.275 \n    19.675 \n    21.920 \n    24.725 \n    26.757 \n  \n  \n    12 \n    18.549 \n    21.026 \n    23.337 \n    26.217 \n    28.300 \n  \n  \n    13 \n    19.812 \n    22.362 \n    24.736 \n    27.688 \n    29.819 \n  \n  \n    14 \n    21.064 \n    23.685 \n    26.119 \n    29.141 \n    31.319 \n  \n  \n    15 \n    22.307 \n    24.996 \n    27.488 \n    30.578 \n    32.801 \n  \n  \n    16 \n    23.542 \n    26.296 \n    28.845 \n    32.000 \n    34.267 \n  \n  \n    17 \n    24.769 \n    27.587 \n    30.191 \n    33.409 \n    35.718 \n  \n  \n    18 \n    25.989 \n    28.869 \n    31.526 \n    34.805 \n    37.156 \n  \n  \n    19 \n    27.204 \n    30.144 \n    32.852 \n    36.191 \n    38.582 \n  \n  \n    20 \n    28.412 \n    31.410 \n    34.170 \n    37.566 \n    39.997 \n  \n  \n    21 \n    29.615 \n    32.671 \n    35.479 \n    38.932 \n    41.401 \n  \n  \n    22 \n    30.813 \n    33.924 \n    36.781 \n    40.289 \n    42.796 \n  \n  \n    23 \n    32.007 \n    35.172 \n    38.076 \n    41.638 \n    44.181 \n  \n  \n    24 \n    33.196 \n    36.415 \n    39.364 \n    42.980 \n    45.559 \n  \n  \n    25 \n    34.382 \n    37.652 \n    40.646 \n    44.314 \n    46.928 \n  \n  \n    26 \n    35.563 \n    38.885 \n    41.923 \n    45.642 \n    48.290 \n  \n  \n    27 \n    36.741 \n    40.113 \n    43.195 \n    46.963 \n    49.645 \n  \n  \n    28 \n    37.916 \n    41.337 \n    44.461 \n    48.278 \n    50.993 \n  \n  \n    29 \n    39.087 \n    42.557 \n    45.722 \n    49.588 \n    52.336 \n  \n  \n    30 \n    40.256 \n    43.773 \n    46.979 \n    50.892 \n    53.672 \n  \n  \n    40 \n    51.805 \n    55.758 \n    59.342 \n    63.691 \n    66.766 \n  \n  \n    50 \n    63.167 \n    67.505 \n    71.420 \n    76.154 \n    79.490 \n  \n  \n    60 \n    74.397 \n    79.082 \n    83.298 \n    88.379 \n    91.952 \n  \n  \n    70 \n    85.527 \n    90.531 \n    95.023 \n    100.425 \n    104.215 \n  \n  \n    80 \n    96.578 \n    101.879 \n    106.629 \n    112.329 \n    116.321 \n  \n  \n    90 \n    107.565 \n    113.145 \n    118.136 \n    124.116 \n    128.299 \n  \n  \n    100 \n    118.498 \n    124.342 \n    129.561 \n    135.807 \n    140.169"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling.html#f-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling.html#f-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(F\\)-fördelning",
    "text": "\\(F\\)-fördelning\n\n\\(\\alpha = 0.01\\)\\(\\alpha = 0.05\\)\\(\\alpha = 0.10\\)\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    4052.18 \n    4999.50 \n    5403.35 \n    5624.58 \n    5763.65 \n    5858.99 \n    5928.36 \n    5981.07 \n    6022.47 \n    6055.85 \n    6083.32 \n    6106.32 \n    6125.86 \n    6142.67 \n    6157.28 \n    6170.10 \n    6181.43 \n    6191.53 \n    6200.58 \n    6208.73 \n    6216.12 \n    6222.84 \n  \n  \n    2 \n    98.50 \n    99.00 \n    99.17 \n    99.25 \n    99.30 \n    99.33 \n    99.36 \n    99.37 \n    99.39 \n    99.40 \n    99.41 \n    99.42 \n    99.42 \n    99.43 \n    99.43 \n    99.44 \n    99.44 \n    99.44 \n    99.45 \n    99.45 \n    99.45 \n    99.45 \n  \n  \n    3 \n    34.12 \n    30.82 \n    29.46 \n    28.71 \n    28.24 \n    27.91 \n    27.67 \n    27.49 \n    27.35 \n    27.23 \n    27.13 \n    27.05 \n    26.98 \n    26.92 \n    26.87 \n    26.83 \n    26.79 \n    26.75 \n    26.72 \n    26.69 \n    26.66 \n    26.64 \n  \n  \n    4 \n    21.20 \n    18.00 \n    16.69 \n    15.98 \n    15.52 \n    15.21 \n    14.98 \n    14.80 \n    14.66 \n    14.55 \n    14.45 \n    14.37 \n    14.31 \n    14.25 \n    14.20 \n    14.15 \n    14.11 \n    14.08 \n    14.05 \n    14.02 \n    13.99 \n    13.97 \n  \n  \n    5 \n    16.26 \n    13.27 \n    12.06 \n    11.39 \n    10.97 \n    10.67 \n    10.46 \n    10.29 \n    10.16 \n    10.05 \n    9.96 \n    9.89 \n    9.82 \n    9.77 \n    9.72 \n    9.68 \n    9.64 \n    9.61 \n    9.58 \n    9.55 \n    9.53 \n    9.51 \n  \n  \n    6 \n    13.75 \n    10.92 \n    9.78 \n    9.15 \n    8.75 \n    8.47 \n    8.26 \n    8.10 \n    7.98 \n    7.87 \n    7.79 \n    7.72 \n    7.66 \n    7.60 \n    7.56 \n    7.52 \n    7.48 \n    7.45 \n    7.42 \n    7.40 \n    7.37 \n    7.35 \n  \n  \n    7 \n    12.25 \n    9.55 \n    8.45 \n    7.85 \n    7.46 \n    7.19 \n    6.99 \n    6.84 \n    6.72 \n    6.62 \n    6.54 \n    6.47 \n    6.41 \n    6.36 \n    6.31 \n    6.28 \n    6.24 \n    6.21 \n    6.18 \n    6.16 \n    6.13 \n    6.11 \n  \n  \n    8 \n    11.26 \n    8.65 \n    7.59 \n    7.01 \n    6.63 \n    6.37 \n    6.18 \n    6.03 \n    5.91 \n    5.81 \n    5.73 \n    5.67 \n    5.61 \n    5.56 \n    5.52 \n    5.48 \n    5.44 \n    5.41 \n    5.38 \n    5.36 \n    5.34 \n    5.32 \n  \n  \n    9 \n    10.56 \n    8.02 \n    6.99 \n    6.42 \n    6.06 \n    5.80 \n    5.61 \n    5.47 \n    5.35 \n    5.26 \n    5.18 \n    5.11 \n    5.05 \n    5.01 \n    4.96 \n    4.92 \n    4.89 \n    4.86 \n    4.83 \n    4.81 \n    4.79 \n    4.77 \n  \n  \n    10 \n    10.04 \n    7.56 \n    6.55 \n    5.99 \n    5.64 \n    5.39 \n    5.20 \n    5.06 \n    4.94 \n    4.85 \n    4.77 \n    4.71 \n    4.65 \n    4.60 \n    4.56 \n    4.52 \n    4.49 \n    4.46 \n    4.43 \n    4.41 \n    4.38 \n    4.36 \n  \n  \n    11 \n    9.65 \n    7.21 \n    6.22 \n    5.67 \n    5.32 \n    5.07 \n    4.89 \n    4.74 \n    4.63 \n    4.54 \n    4.46 \n    4.40 \n    4.34 \n    4.29 \n    4.25 \n    4.21 \n    4.18 \n    4.15 \n    4.12 \n    4.10 \n    4.08 \n    4.06 \n  \n  \n    12 \n    9.33 \n    6.93 \n    5.95 \n    5.41 \n    5.06 \n    4.82 \n    4.64 \n    4.50 \n    4.39 \n    4.30 \n    4.22 \n    4.16 \n    4.10 \n    4.05 \n    4.01 \n    3.97 \n    3.94 \n    3.91 \n    3.88 \n    3.86 \n    3.84 \n    3.82 \n  \n  \n    13 \n    9.07 \n    6.70 \n    5.74 \n    5.21 \n    4.86 \n    4.62 \n    4.44 \n    4.30 \n    4.19 \n    4.10 \n    4.02 \n    3.96 \n    3.91 \n    3.86 \n    3.82 \n    3.78 \n    3.75 \n    3.72 \n    3.69 \n    3.66 \n    3.64 \n    3.62 \n  \n  \n    14 \n    8.86 \n    6.51 \n    5.56 \n    5.04 \n    4.69 \n    4.46 \n    4.28 \n    4.14 \n    4.03 \n    3.94 \n    3.86 \n    3.80 \n    3.75 \n    3.70 \n    3.66 \n    3.62 \n    3.59 \n    3.56 \n    3.53 \n    3.51 \n    3.48 \n    3.46 \n  \n  \n    15 \n    8.68 \n    6.36 \n    5.42 \n    4.89 \n    4.56 \n    4.32 \n    4.14 \n    4.00 \n    3.89 \n    3.80 \n    3.73 \n    3.67 \n    3.61 \n    3.56 \n    3.52 \n    3.49 \n    3.45 \n    3.42 \n    3.40 \n    3.37 \n    3.35 \n    3.33 \n  \n  \n    16 \n    8.53 \n    6.23 \n    5.29 \n    4.77 \n    4.44 \n    4.20 \n    4.03 \n    3.89 \n    3.78 \n    3.69 \n    3.62 \n    3.55 \n    3.50 \n    3.45 \n    3.41 \n    3.37 \n    3.34 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n  \n  \n    17 \n    8.40 \n    6.11 \n    5.18 \n    4.67 \n    4.34 \n    4.10 \n    3.93 \n    3.79 \n    3.68 \n    3.59 \n    3.52 \n    3.46 \n    3.40 \n    3.35 \n    3.31 \n    3.27 \n    3.24 \n    3.21 \n    3.19 \n    3.16 \n    3.14 \n    3.12 \n  \n  \n    18 \n    8.29 \n    6.01 \n    5.09 \n    4.58 \n    4.25 \n    4.01 \n    3.84 \n    3.71 \n    3.60 \n    3.51 \n    3.43 \n    3.37 \n    3.32 \n    3.27 \n    3.23 \n    3.19 \n    3.16 \n    3.13 \n    3.10 \n    3.08 \n    3.05 \n    3.03 \n  \n  \n    19 \n    8.18 \n    5.93 \n    5.01 \n    4.50 \n    4.17 \n    3.94 \n    3.77 \n    3.63 \n    3.52 \n    3.43 \n    3.36 \n    3.30 \n    3.24 \n    3.19 \n    3.15 \n    3.12 \n    3.08 \n    3.05 \n    3.03 \n    3.00 \n    2.98 \n    2.96 \n  \n  \n    20 \n    8.10 \n    5.85 \n    4.94 \n    4.43 \n    4.10 \n    3.87 \n    3.70 \n    3.56 \n    3.46 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.13 \n    3.09 \n    3.05 \n    3.02 \n    2.99 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n  \n  \n    21 \n    8.02 \n    5.78 \n    4.87 \n    4.37 \n    4.04 \n    3.81 \n    3.64 \n    3.51 \n    3.40 \n    3.31 \n    3.24 \n    3.17 \n    3.12 \n    3.07 \n    3.03 \n    2.99 \n    2.96 \n    2.93 \n    2.90 \n    2.88 \n    2.86 \n    2.84 \n  \n  \n    22 \n    7.95 \n    5.72 \n    4.82 \n    4.31 \n    3.99 \n    3.76 \n    3.59 \n    3.45 \n    3.35 \n    3.26 \n    3.18 \n    3.12 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.88 \n    2.85 \n    2.83 \n    2.81 \n    2.78 \n  \n  \n    23 \n    7.88 \n    5.66 \n    4.76 \n    4.26 \n    3.94 \n    3.71 \n    3.54 \n    3.41 \n    3.30 \n    3.21 \n    3.14 \n    3.07 \n    3.02 \n    2.97 \n    2.93 \n    2.89 \n    2.86 \n    2.83 \n    2.80 \n    2.78 \n    2.76 \n    2.74 \n  \n  \n    24 \n    7.82 \n    5.61 \n    4.72 \n    4.22 \n    3.90 \n    3.67 \n    3.50 \n    3.36 \n    3.26 \n    3.17 \n    3.09 \n    3.03 \n    2.98 \n    2.93 \n    2.89 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n  \n  \n    25 \n    7.77 \n    5.57 \n    4.68 \n    4.18 \n    3.85 \n    3.63 \n    3.46 \n    3.32 \n    3.22 \n    3.13 \n    3.06 \n    2.99 \n    2.94 \n    2.89 \n    2.85 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.66 \n  \n  \n    26 \n    7.72 \n    5.53 \n    4.64 \n    4.14 \n    3.82 \n    3.59 \n    3.42 \n    3.29 \n    3.18 \n    3.09 \n    3.02 \n    2.96 \n    2.90 \n    2.86 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n  \n  \n    27 \n    7.68 \n    5.49 \n    4.60 \n    4.11 \n    3.78 \n    3.56 \n    3.39 \n    3.26 \n    3.15 \n    3.06 \n    2.99 \n    2.93 \n    2.87 \n    2.82 \n    2.78 \n    2.75 \n    2.71 \n    2.68 \n    2.66 \n    2.63 \n    2.61 \n    2.59 \n  \n  \n    28 \n    7.64 \n    5.45 \n    4.57 \n    4.07 \n    3.75 \n    3.53 \n    3.36 \n    3.23 \n    3.12 \n    3.03 \n    2.96 \n    2.90 \n    2.84 \n    2.79 \n    2.75 \n    2.72 \n    2.68 \n    2.65 \n    2.63 \n    2.60 \n    2.58 \n    2.56 \n  \n  \n    29 \n    7.60 \n    5.42 \n    4.54 \n    4.04 \n    3.73 \n    3.50 \n    3.33 \n    3.20 \n    3.09 \n    3.00 \n    2.93 \n    2.87 \n    2.81 \n    2.77 \n    2.73 \n    2.69 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n  \n  \n    30 \n    7.56 \n    5.39 \n    4.51 \n    4.02 \n    3.70 \n    3.47 \n    3.30 \n    3.17 \n    3.07 \n    2.98 \n    2.91 \n    2.84 \n    2.79 \n    2.74 \n    2.70 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n    2.51 \n  \n  \n    35 \n    7.42 \n    5.27 \n    4.40 \n    3.91 \n    3.59 \n    3.37 \n    3.20 \n    3.07 \n    2.96 \n    2.88 \n    2.80 \n    2.74 \n    2.69 \n    2.64 \n    2.60 \n    2.56 \n    2.53 \n    2.50 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n  \n  \n    40 \n    7.31 \n    5.18 \n    4.31 \n    3.83 \n    3.51 \n    3.29 \n    3.12 \n    2.99 \n    2.89 \n    2.80 \n    2.73 \n    2.66 \n    2.61 \n    2.56 \n    2.52 \n    2.48 \n    2.45 \n    2.42 \n    2.39 \n    2.37 \n    2.35 \n    2.33 \n  \n  \n    45 \n    7.23 \n    5.11 \n    4.25 \n    3.77 \n    3.45 \n    3.23 \n    3.07 \n    2.94 \n    2.83 \n    2.74 \n    2.67 \n    2.61 \n    2.55 \n    2.51 \n    2.46 \n    2.43 \n    2.39 \n    2.36 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n  \n  \n    50 \n    7.17 \n    5.06 \n    4.20 \n    3.72 \n    3.41 \n    3.19 \n    3.02 \n    2.89 \n    2.78 \n    2.70 \n    2.63 \n    2.56 \n    2.51 \n    2.46 \n    2.42 \n    2.38 \n    2.35 \n    2.32 \n    2.29 \n    2.27 \n    2.24 \n    2.22 \n  \n  \n    60 \n    7.08 \n    4.98 \n    4.13 \n    3.65 \n    3.34 \n    3.12 \n    2.95 \n    2.82 \n    2.72 \n    2.63 \n    2.56 \n    2.50 \n    2.44 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.17 \n    2.15 \n  \n  \n    75 \n    6.99 \n    4.90 \n    4.05 \n    3.58 \n    3.27 \n    3.05 \n    2.89 \n    2.76 \n    2.65 \n    2.57 \n    2.49 \n    2.43 \n    2.38 \n    2.33 \n    2.29 \n    2.25 \n    2.22 \n    2.18 \n    2.16 \n    2.13 \n    2.11 \n    2.09 \n  \n  \n    100 \n    6.90 \n    4.82 \n    3.98 \n    3.51 \n    3.21 \n    2.99 \n    2.82 \n    2.69 \n    2.59 \n    2.50 \n    2.43 \n    2.37 \n    2.31 \n    2.27 \n    2.22 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.04 \n    2.02 \n  \n  \n    120 \n    6.85 \n    4.79 \n    3.95 \n    3.48 \n    3.17 \n    2.96 \n    2.79 \n    2.66 \n    2.56 \n    2.47 \n    2.40 \n    2.34 \n    2.28 \n    2.23 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n  \n  \n    140 \n    6.82 \n    4.76 \n    3.92 \n    3.46 \n    3.15 \n    2.93 \n    2.77 \n    2.64 \n    2.54 \n    2.45 \n    2.38 \n    2.31 \n    2.26 \n    2.21 \n    2.17 \n    2.13 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.97 \n  \n  \n    180 \n    6.78 \n    4.73 \n    3.89 \n    3.43 \n    3.12 \n    2.90 \n    2.74 \n    2.61 \n    2.51 \n    2.42 \n    2.35 \n    2.28 \n    2.23 \n    2.18 \n    2.14 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.96 \n    1.94 \n  \n  \n    250 \n    6.74 \n    4.69 \n    3.86 \n    3.40 \n    3.09 \n    2.87 \n    2.71 \n    2.58 \n    2.48 \n    2.39 \n    2.32 \n    2.26 \n    2.20 \n    2.15 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.95 \n    1.93 \n    1.91 \n  \n  \n    400 \n    6.70 \n    4.66 \n    3.83 \n    3.37 \n    3.06 \n    2.85 \n    2.68 \n    2.56 \n    2.45 \n    2.37 \n    2.29 \n    2.23 \n    2.17 \n    2.13 \n    2.08 \n    2.05 \n    2.01 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.88 \n  \n  \n    1000 \n    6.66 \n    4.63 \n    3.80 \n    3.34 \n    3.04 \n    2.82 \n    2.66 \n    2.53 \n    2.43 \n    2.34 \n    2.27 \n    2.20 \n    2.15 \n    2.10 \n    2.06 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.85 \n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    161.45 \n    199.50 \n    215.71 \n    224.58 \n    230.16 \n    233.99 \n    236.77 \n    238.88 \n    240.54 \n    241.88 \n    242.98 \n    243.91 \n    244.69 \n    245.36 \n    245.95 \n    246.46 \n    246.92 \n    247.32 \n    247.69 \n    248.01 \n    248.31 \n    248.58 \n  \n  \n    2 \n    18.51 \n    19.00 \n    19.16 \n    19.25 \n    19.30 \n    19.33 \n    19.35 \n    19.37 \n    19.38 \n    19.40 \n    19.40 \n    19.41 \n    19.42 \n    19.42 \n    19.43 \n    19.43 \n    19.44 \n    19.44 \n    19.44 \n    19.45 \n    19.45 \n    19.45 \n  \n  \n    3 \n    10.13 \n    9.55 \n    9.28 \n    9.12 \n    9.01 \n    8.94 \n    8.89 \n    8.85 \n    8.81 \n    8.79 \n    8.76 \n    8.74 \n    8.73 \n    8.71 \n    8.70 \n    8.69 \n    8.68 \n    8.67 \n    8.67 \n    8.66 \n    8.65 \n    8.65 \n  \n  \n    4 \n    7.71 \n    6.94 \n    6.59 \n    6.39 \n    6.26 \n    6.16 \n    6.09 \n    6.04 \n    6.00 \n    5.96 \n    5.94 \n    5.91 \n    5.89 \n    5.87 \n    5.86 \n    5.84 \n    5.83 \n    5.82 \n    5.81 \n    5.80 \n    5.79 \n    5.79 \n  \n  \n    5 \n    6.61 \n    5.79 \n    5.41 \n    5.19 \n    5.05 \n    4.95 \n    4.88 \n    4.82 \n    4.77 \n    4.74 \n    4.70 \n    4.68 \n    4.66 \n    4.64 \n    4.62 \n    4.60 \n    4.59 \n    4.58 \n    4.57 \n    4.56 \n    4.55 \n    4.54 \n  \n  \n    6 \n    5.99 \n    5.14 \n    4.76 \n    4.53 \n    4.39 \n    4.28 \n    4.21 \n    4.15 \n    4.10 \n    4.06 \n    4.03 \n    4.00 \n    3.98 \n    3.96 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n  \n  \n    7 \n    5.59 \n    4.74 \n    4.35 \n    4.12 \n    3.97 \n    3.87 \n    3.79 \n    3.73 \n    3.68 \n    3.64 \n    3.60 \n    3.57 \n    3.55 \n    3.53 \n    3.51 \n    3.49 \n    3.48 \n    3.47 \n    3.46 \n    3.44 \n    3.43 \n    3.43 \n  \n  \n    8 \n    5.32 \n    4.46 \n    4.07 \n    3.84 \n    3.69 \n    3.58 \n    3.50 \n    3.44 \n    3.39 \n    3.35 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n    3.20 \n    3.19 \n    3.17 \n    3.16 \n    3.15 \n    3.14 \n    3.13 \n  \n  \n    9 \n    5.12 \n    4.26 \n    3.86 \n    3.63 \n    3.48 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.14 \n    3.10 \n    3.07 \n    3.05 \n    3.03 \n    3.01 \n    2.99 \n    2.97 \n    2.96 \n    2.95 \n    2.94 \n    2.93 \n    2.92 \n  \n  \n    10 \n    4.96 \n    4.10 \n    3.71 \n    3.48 \n    3.33 \n    3.22 \n    3.14 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.89 \n    2.86 \n    2.85 \n    2.83 \n    2.81 \n    2.80 \n    2.79 \n    2.77 \n    2.76 \n    2.75 \n  \n  \n    11 \n    4.84 \n    3.98 \n    3.59 \n    3.36 \n    3.20 \n    3.09 \n    3.01 \n    2.95 \n    2.90 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n    2.69 \n    2.67 \n    2.66 \n    2.65 \n    2.64 \n    2.63 \n  \n  \n    12 \n    4.75 \n    3.89 \n    3.49 \n    3.26 \n    3.11 \n    3.00 \n    2.91 \n    2.85 \n    2.80 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n    2.60 \n    2.58 \n    2.57 \n    2.56 \n    2.54 \n    2.53 \n    2.52 \n  \n  \n    13 \n    4.67 \n    3.81 \n    3.41 \n    3.18 \n    3.03 \n    2.92 \n    2.83 \n    2.77 \n    2.71 \n    2.67 \n    2.63 \n    2.60 \n    2.58 \n    2.55 \n    2.53 \n    2.51 \n    2.50 \n    2.48 \n    2.47 \n    2.46 \n    2.45 \n    2.44 \n  \n  \n    14 \n    4.60 \n    3.74 \n    3.34 \n    3.11 \n    2.96 \n    2.85 \n    2.76 \n    2.70 \n    2.65 \n    2.60 \n    2.57 \n    2.53 \n    2.51 \n    2.48 \n    2.46 \n    2.44 \n    2.43 \n    2.41 \n    2.40 \n    2.39 \n    2.38 \n    2.37 \n  \n  \n    15 \n    4.54 \n    3.68 \n    3.29 \n    3.06 \n    2.90 \n    2.79 \n    2.71 \n    2.64 \n    2.59 \n    2.54 \n    2.51 \n    2.48 \n    2.45 \n    2.42 \n    2.40 \n    2.38 \n    2.37 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n  \n  \n    16 \n    4.49 \n    3.63 \n    3.24 \n    3.01 \n    2.85 \n    2.74 \n    2.66 \n    2.59 \n    2.54 \n    2.49 \n    2.46 \n    2.42 \n    2.40 \n    2.37 \n    2.35 \n    2.33 \n    2.32 \n    2.30 \n    2.29 \n    2.28 \n    2.26 \n    2.25 \n  \n  \n    17 \n    4.45 \n    3.59 \n    3.20 \n    2.96 \n    2.81 \n    2.70 \n    2.61 \n    2.55 \n    2.49 \n    2.45 \n    2.41 \n    2.38 \n    2.35 \n    2.33 \n    2.31 \n    2.29 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.21 \n  \n  \n    18 \n    4.41 \n    3.55 \n    3.16 \n    2.93 \n    2.77 \n    2.66 \n    2.58 \n    2.51 \n    2.46 \n    2.41 \n    2.37 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n    2.25 \n    2.23 \n    2.22 \n    2.20 \n    2.19 \n    2.18 \n    2.17 \n  \n  \n    19 \n    4.38 \n    3.52 \n    3.13 \n    2.90 \n    2.74 \n    2.63 \n    2.54 \n    2.48 \n    2.42 \n    2.38 \n    2.34 \n    2.31 \n    2.28 \n    2.26 \n    2.23 \n    2.21 \n    2.20 \n    2.18 \n    2.17 \n    2.16 \n    2.14 \n    2.13 \n  \n  \n    20 \n    4.35 \n    3.49 \n    3.10 \n    2.87 \n    2.71 \n    2.60 \n    2.51 \n    2.45 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.17 \n    2.15 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n  \n  \n    21 \n    4.32 \n    3.47 \n    3.07 \n    2.84 \n    2.68 \n    2.57 \n    2.49 \n    2.42 \n    2.37 \n    2.32 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.16 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n  \n  \n    22 \n    4.30 \n    3.44 \n    3.05 \n    2.82 \n    2.66 \n    2.55 \n    2.46 \n    2.40 \n    2.34 \n    2.30 \n    2.26 \n    2.23 \n    2.20 \n    2.17 \n    2.15 \n    2.13 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n  \n  \n    23 \n    4.28 \n    3.42 \n    3.03 \n    2.80 \n    2.64 \n    2.53 \n    2.44 \n    2.37 \n    2.32 \n    2.27 \n    2.24 \n    2.20 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.08 \n    2.06 \n    2.05 \n    2.04 \n    2.02 \n  \n  \n    24 \n    4.26 \n    3.40 \n    3.01 \n    2.78 \n    2.62 \n    2.51 \n    2.42 \n    2.36 \n    2.30 \n    2.25 \n    2.22 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.01 \n    2.00 \n  \n  \n    25 \n    4.24 \n    3.39 \n    2.99 \n    2.76 \n    2.60 \n    2.49 \n    2.40 \n    2.34 \n    2.28 \n    2.24 \n    2.20 \n    2.16 \n    2.14 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.98 \n  \n  \n    26 \n    4.23 \n    3.37 \n    2.98 \n    2.74 \n    2.59 \n    2.47 \n    2.39 \n    2.32 \n    2.27 \n    2.22 \n    2.18 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.05 \n    2.03 \n    2.02 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n  \n  \n    27 \n    4.21 \n    3.35 \n    2.96 \n    2.73 \n    2.57 \n    2.46 \n    2.37 \n    2.31 \n    2.25 \n    2.20 \n    2.17 \n    2.13 \n    2.10 \n    2.08 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n  \n  \n    28 \n    4.20 \n    3.34 \n    2.95 \n    2.71 \n    2.56 \n    2.45 \n    2.36 \n    2.29 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.93 \n  \n  \n    29 \n    4.18 \n    3.33 \n    2.93 \n    2.70 \n    2.55 \n    2.43 \n    2.35 \n    2.28 \n    2.22 \n    2.18 \n    2.14 \n    2.10 \n    2.08 \n    2.05 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.96 \n    1.94 \n    1.93 \n    1.92 \n  \n  \n    30 \n    4.17 \n    3.32 \n    2.92 \n    2.69 \n    2.53 \n    2.42 \n    2.33 \n    2.27 \n    2.21 \n    2.16 \n    2.13 \n    2.09 \n    2.06 \n    2.04 \n    2.01 \n    1.99 \n    1.98 \n    1.96 \n    1.95 \n    1.93 \n    1.92 \n    1.91 \n  \n  \n    35 \n    4.12 \n    3.27 \n    2.87 \n    2.64 \n    2.49 \n    2.37 \n    2.29 \n    2.22 \n    2.16 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.96 \n    1.94 \n    1.92 \n    1.91 \n    1.89 \n    1.88 \n    1.87 \n    1.85 \n  \n  \n    40 \n    4.08 \n    3.23 \n    2.84 \n    2.61 \n    2.45 \n    2.34 \n    2.25 \n    2.18 \n    2.12 \n    2.08 \n    2.04 \n    2.00 \n    1.97 \n    1.95 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.85 \n    1.84 \n    1.83 \n    1.81 \n  \n  \n    45 \n    4.06 \n    3.20 \n    2.81 \n    2.58 \n    2.42 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.05 \n    2.01 \n    1.97 \n    1.94 \n    1.92 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.82 \n    1.81 \n    1.80 \n    1.78 \n  \n  \n    50 \n    4.03 \n    3.18 \n    2.79 \n    2.56 \n    2.40 \n    2.29 \n    2.20 \n    2.13 \n    2.07 \n    2.03 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    60 \n    4.00 \n    3.15 \n    2.76 \n    2.53 \n    2.37 \n    2.25 \n    2.17 \n    2.10 \n    2.04 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.86 \n    1.84 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n  \n  \n    75 \n    3.97 \n    3.12 \n    2.73 \n    2.49 \n    2.34 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.85 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    100 \n    3.94 \n    3.09 \n    2.70 \n    2.46 \n    2.31 \n    2.19 \n    2.10 \n    2.03 \n    1.97 \n    1.93 \n    1.89 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.68 \n    1.66 \n    1.65 \n  \n  \n    120 \n    3.92 \n    3.07 \n    2.68 \n    2.45 \n    2.29 \n    2.18 \n    2.09 \n    2.02 \n    1.96 \n    1.91 \n    1.87 \n    1.83 \n    1.80 \n    1.78 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.67 \n    1.66 \n    1.64 \n    1.63 \n  \n  \n    140 \n    3.91 \n    3.06 \n    2.67 \n    2.44 \n    2.28 \n    2.16 \n    2.08 \n    2.01 \n    1.95 \n    1.90 \n    1.86 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.62 \n  \n  \n    180 \n    3.89 \n    3.05 \n    2.65 \n    2.42 \n    2.26 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.88 \n    1.84 \n    1.81 \n    1.77 \n    1.75 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n  \n  \n    250 \n    3.88 \n    3.03 \n    2.64 \n    2.41 \n    2.25 \n    2.13 \n    2.05 \n    1.98 \n    1.92 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.73 \n    1.71 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n  \n  \n    400 \n    3.86 \n    3.02 \n    2.63 \n    2.39 \n    2.24 \n    2.12 \n    2.03 \n    1.96 \n    1.90 \n    1.85 \n    1.81 \n    1.78 \n    1.74 \n    1.72 \n    1.69 \n    1.67 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n  \n  \n    1000 \n    3.85 \n    3.00 \n    2.61 \n    2.38 \n    2.22 \n    2.11 \n    2.02 \n    1.95 \n    1.89 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    39.86 \n    49.50 \n    53.59 \n    55.83 \n    57.24 \n    58.20 \n    58.91 \n    59.44 \n    59.86 \n    60.19 \n    60.47 \n    60.71 \n    60.90 \n    61.07 \n    61.22 \n    61.35 \n    61.46 \n    61.57 \n    61.66 \n    61.74 \n    61.81 \n    61.88 \n  \n  \n    2 \n    8.53 \n    9.00 \n    9.16 \n    9.24 \n    9.29 \n    9.33 \n    9.35 \n    9.37 \n    9.38 \n    9.39 \n    9.40 \n    9.41 \n    9.41 \n    9.42 \n    9.42 \n    9.43 \n    9.43 \n    9.44 \n    9.44 \n    9.44 \n    9.44 \n    9.45 \n  \n  \n    3 \n    5.54 \n    5.46 \n    5.39 \n    5.34 \n    5.31 \n    5.28 \n    5.27 \n    5.25 \n    5.24 \n    5.23 \n    5.22 \n    5.22 \n    5.21 \n    5.20 \n    5.20 \n    5.20 \n    5.19 \n    5.19 \n    5.19 \n    5.18 \n    5.18 \n    5.18 \n  \n  \n    4 \n    4.54 \n    4.32 \n    4.19 \n    4.11 \n    4.05 \n    4.01 \n    3.98 \n    3.95 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.89 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n    3.85 \n    3.85 \n    3.84 \n    3.84 \n    3.84 \n  \n  \n    5 \n    4.06 \n    3.78 \n    3.62 \n    3.52 \n    3.45 \n    3.40 \n    3.37 \n    3.34 \n    3.32 \n    3.30 \n    3.28 \n    3.27 \n    3.26 \n    3.25 \n    3.24 \n    3.23 \n    3.22 \n    3.22 \n    3.21 \n    3.21 \n    3.20 \n    3.20 \n  \n  \n    6 \n    3.78 \n    3.46 \n    3.29 \n    3.18 \n    3.11 \n    3.05 \n    3.01 \n    2.98 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n    2.89 \n    2.88 \n    2.87 \n    2.86 \n    2.85 \n    2.85 \n    2.84 \n    2.84 \n    2.83 \n    2.83 \n  \n  \n    7 \n    3.59 \n    3.26 \n    3.07 \n    2.96 \n    2.88 \n    2.83 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.67 \n    2.65 \n    2.64 \n    2.63 \n    2.62 \n    2.61 \n    2.61 \n    2.60 \n    2.59 \n    2.59 \n    2.58 \n  \n  \n    8 \n    3.46 \n    3.11 \n    2.92 \n    2.81 \n    2.73 \n    2.67 \n    2.62 \n    2.59 \n    2.56 \n    2.54 \n    2.52 \n    2.50 \n    2.49 \n    2.48 \n    2.46 \n    2.45 \n    2.45 \n    2.44 \n    2.43 \n    2.42 \n    2.42 \n    2.41 \n  \n  \n    9 \n    3.36 \n    3.01 \n    2.81 \n    2.69 \n    2.61 \n    2.55 \n    2.51 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n    2.38 \n    2.36 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n    2.30 \n    2.30 \n    2.29 \n    2.29 \n  \n  \n    10 \n    3.29 \n    2.92 \n    2.73 \n    2.61 \n    2.52 \n    2.46 \n    2.41 \n    2.38 \n    2.35 \n    2.32 \n    2.30 \n    2.28 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.22 \n    2.21 \n    2.20 \n    2.19 \n    2.19 \n  \n  \n    11 \n    3.23 \n    2.86 \n    2.66 \n    2.54 \n    2.45 \n    2.39 \n    2.34 \n    2.30 \n    2.27 \n    2.25 \n    2.23 \n    2.21 \n    2.19 \n    2.18 \n    2.17 \n    2.16 \n    2.15 \n    2.14 \n    2.13 \n    2.12 \n    2.12 \n    2.11 \n  \n  \n    12 \n    3.18 \n    2.81 \n    2.61 \n    2.48 \n    2.39 \n    2.33 \n    2.28 \n    2.24 \n    2.21 \n    2.19 \n    2.17 \n    2.15 \n    2.13 \n    2.12 \n    2.10 \n    2.09 \n    2.08 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n    2.05 \n  \n  \n    13 \n    3.14 \n    2.76 \n    2.56 \n    2.43 \n    2.35 \n    2.28 \n    2.23 \n    2.20 \n    2.16 \n    2.14 \n    2.12 \n    2.10 \n    2.08 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.02 \n    2.01 \n    2.01 \n    2.00 \n    1.99 \n  \n  \n    14 \n    3.10 \n    2.73 \n    2.52 \n    2.39 \n    2.31 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.10 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n    1.96 \n    1.96 \n    1.95 \n  \n  \n    15 \n    3.07 \n    2.70 \n    2.49 \n    2.36 \n    2.27 \n    2.21 \n    2.16 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.92 \n    1.91 \n  \n  \n    16 \n    3.05 \n    2.67 \n    2.46 \n    2.33 \n    2.24 \n    2.18 \n    2.13 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.88 \n  \n  \n    17 \n    3.03 \n    2.64 \n    2.44 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.06 \n    2.03 \n    2.00 \n    1.98 \n    1.96 \n    1.94 \n    1.93 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.87 \n    1.86 \n    1.86 \n    1.85 \n  \n  \n    18 \n    3.01 \n    2.62 \n    2.42 \n    2.29 \n    2.20 \n    2.13 \n    2.08 \n    2.04 \n    2.00 \n    1.98 \n    1.95 \n    1.93 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.86 \n    1.85 \n    1.84 \n    1.84 \n    1.83 \n    1.82 \n  \n  \n    19 \n    2.99 \n    2.61 \n    2.40 \n    2.27 \n    2.18 \n    2.11 \n    2.06 \n    2.02 \n    1.98 \n    1.96 \n    1.93 \n    1.91 \n    1.89 \n    1.88 \n    1.86 \n    1.85 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.81 \n    1.80 \n  \n  \n    20 \n    2.97 \n    2.59 \n    2.38 \n    2.25 \n    2.16 \n    2.09 \n    2.04 \n    2.00 \n    1.96 \n    1.94 \n    1.91 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.80 \n    1.79 \n    1.79 \n    1.78 \n  \n  \n    21 \n    2.96 \n    2.57 \n    2.36 \n    2.23 \n    2.14 \n    2.08 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    22 \n    2.95 \n    2.56 \n    2.35 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.97 \n    1.93 \n    1.90 \n    1.88 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n  \n  \n    23 \n    2.94 \n    2.55 \n    2.34 \n    2.21 \n    2.11 \n    2.05 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.74 \n    1.73 \n  \n  \n    24 \n    2.93 \n    2.54 \n    2.33 \n    2.19 \n    2.10 \n    2.04 \n    1.98 \n    1.94 \n    1.91 \n    1.88 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n  \n  \n    25 \n    2.92 \n    2.53 \n    2.32 \n    2.18 \n    2.09 \n    2.02 \n    1.97 \n    1.93 \n    1.89 \n    1.87 \n    1.84 \n    1.82 \n    1.80 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n    1.70 \n  \n  \n    26 \n    2.91 \n    2.52 \n    2.31 \n    2.17 \n    2.08 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.86 \n    1.83 \n    1.81 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    27 \n    2.90 \n    2.51 \n    2.30 \n    2.17 \n    2.07 \n    2.00 \n    1.95 \n    1.91 \n    1.87 \n    1.85 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.70 \n    1.69 \n    1.68 \n  \n  \n    28 \n    2.89 \n    2.50 \n    2.29 \n    2.16 \n    2.06 \n    2.00 \n    1.94 \n    1.90 \n    1.87 \n    1.84 \n    1.81 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n    1.69 \n    1.68 \n    1.67 \n  \n  \n    29 \n    2.89 \n    2.50 \n    2.28 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.89 \n    1.86 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.69 \n    1.68 \n    1.68 \n    1.67 \n    1.66 \n  \n  \n    30 \n    2.88 \n    2.49 \n    2.28 \n    2.14 \n    2.05 \n    1.98 \n    1.93 \n    1.88 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.69 \n    1.68 \n    1.67 \n    1.66 \n    1.65 \n  \n  \n    35 \n    2.85 \n    2.46 \n    2.25 \n    2.11 \n    2.02 \n    1.95 \n    1.90 \n    1.85 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.69 \n    1.67 \n    1.66 \n    1.65 \n    1.64 \n    1.63 \n    1.62 \n    1.62 \n  \n  \n    40 \n    2.84 \n    2.44 \n    2.23 \n    2.09 \n    2.00 \n    1.93 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.74 \n    1.71 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.64 \n    1.62 \n    1.61 \n    1.61 \n    1.60 \n    1.59 \n  \n  \n    45 \n    2.82 \n    2.42 \n    2.21 \n    2.07 \n    1.98 \n    1.91 \n    1.85 \n    1.81 \n    1.77 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.58 \n    1.57 \n  \n  \n    50 \n    2.81 \n    2.41 \n    2.20 \n    2.06 \n    1.97 \n    1.90 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n    1.59 \n    1.58 \n    1.57 \n    1.56 \n    1.55 \n  \n  \n    60 \n    2.79 \n    2.39 \n    2.18 \n    2.04 \n    1.95 \n    1.87 \n    1.82 \n    1.77 \n    1.74 \n    1.71 \n    1.68 \n    1.66 \n    1.64 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.56 \n    1.55 \n    1.54 \n    1.53 \n    1.53 \n  \n  \n    75 \n    2.77 \n    2.37 \n    2.16 \n    2.02 \n    1.93 \n    1.85 \n    1.80 \n    1.75 \n    1.72 \n    1.69 \n    1.66 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n    1.54 \n    1.53 \n    1.52 \n    1.51 \n    1.50 \n  \n  \n    100 \n    2.76 \n    2.36 \n    2.14 \n    2.00 \n    1.91 \n    1.83 \n    1.78 \n    1.73 \n    1.69 \n    1.66 \n    1.64 \n    1.61 \n    1.59 \n    1.57 \n    1.56 \n    1.54 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.48 \n  \n  \n    120 \n    2.75 \n    2.35 \n    2.13 \n    1.99 \n    1.90 \n    1.82 \n    1.77 \n    1.72 \n    1.68 \n    1.65 \n    1.63 \n    1.60 \n    1.58 \n    1.56 \n    1.55 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.47 \n    1.46 \n  \n  \n    140 \n    2.74 \n    2.34 \n    2.12 \n    1.99 \n    1.89 \n    1.82 \n    1.76 \n    1.71 \n    1.68 \n    1.64 \n    1.62 \n    1.59 \n    1.57 \n    1.55 \n    1.54 \n    1.52 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n  \n  \n    180 \n    2.73 \n    2.33 \n    2.11 \n    1.98 \n    1.88 \n    1.81 \n    1.75 \n    1.70 \n    1.67 \n    1.63 \n    1.61 \n    1.58 \n    1.56 \n    1.54 \n    1.53 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n  \n  \n    250 \n    2.73 \n    2.32 \n    2.11 \n    1.97 \n    1.87 \n    1.80 \n    1.74 \n    1.69 \n    1.66 \n    1.62 \n    1.60 \n    1.57 \n    1.55 \n    1.53 \n    1.51 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n  \n  \n    400 \n    2.72 \n    2.32 \n    2.10 \n    1.96 \n    1.86 \n    1.79 \n    1.73 \n    1.69 \n    1.65 \n    1.61 \n    1.59 \n    1.56 \n    1.54 \n    1.52 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n  \n  \n    1000 \n    2.71 \n    2.31 \n    2.09 \n    1.95 \n    1.85 \n    1.78 \n    1.72 \n    1.68 \n    1.64 \n    1.61 \n    1.58 \n    1.55 \n    1.53 \n    1.51 \n    1.49 \n    1.48 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n    1.41"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#normalfördelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#normalfördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Normalfördelning",
    "text": "Normalfördelning\nTabellen ger sannolikheten \\(\\Phi(z) = P(Z\\leq z)\\) för olika \\(z\\) där \\(Z\\) är standardnormal, \\(Z\\sim N(0,1)\\).\nSannolikheter i den vänstra svansen fås genom symmetri: \\(P(Z\\leq \\textminus z) = 1-P(Z\\leq z)\\).\n\n                                                                 \n\n\nAndra decimalen i \\(z\\)\n\n\n\n\n\n \n  \n      \n    0.00 \n    0.01 \n    0.02 \n    0.03 \n    0.04 \n    0.05 \n    0.06 \n    0.07 \n    0.08 \n    0.09 \n  \n \n\n  \n    0.0 \n    0.5000 \n    0.5040 \n    0.5080 \n    0.5120 \n    0.5160 \n    0.5199 \n    0.5239 \n    0.5279 \n    0.5319 \n    0.5359 \n  \n  \n    0.1 \n    0.5398 \n    0.5438 \n    0.5478 \n    0.5517 \n    0.5557 \n    0.5596 \n    0.5636 \n    0.5675 \n    0.5714 \n    0.5753 \n  \n  \n    0.2 \n    0.5793 \n    0.5832 \n    0.5871 \n    0.5910 \n    0.5948 \n    0.5987 \n    0.6026 \n    0.6064 \n    0.6103 \n    0.6141 \n  \n  \n    0.3 \n    0.6179 \n    0.6217 \n    0.6255 \n    0.6293 \n    0.6331 \n    0.6368 \n    0.6406 \n    0.6443 \n    0.6480 \n    0.6517 \n  \n  \n    0.4 \n    0.6554 \n    0.6591 \n    0.6628 \n    0.6664 \n    0.6700 \n    0.6736 \n    0.6772 \n    0.6808 \n    0.6844 \n    0.6879 \n  \n  \n    0.5 \n    0.6915 \n    0.6950 \n    0.6985 \n    0.7019 \n    0.7054 \n    0.7088 \n    0.7123 \n    0.7157 \n    0.7190 \n    0.7224 \n  \n  \n    0.6 \n    0.7257 \n    0.7291 \n    0.7324 \n    0.7357 \n    0.7389 \n    0.7422 \n    0.7454 \n    0.7486 \n    0.7517 \n    0.7549 \n  \n  \n    0.7 \n    0.7580 \n    0.7611 \n    0.7642 \n    0.7673 \n    0.7704 \n    0.7734 \n    0.7764 \n    0.7794 \n    0.7823 \n    0.7852 \n  \n  \n    0.8 \n    0.7881 \n    0.7910 \n    0.7939 \n    0.7967 \n    0.7995 \n    0.8023 \n    0.8051 \n    0.8078 \n    0.8106 \n    0.8133 \n  \n  \n    0.9 \n    0.8159 \n    0.8186 \n    0.8212 \n    0.8238 \n    0.8264 \n    0.8289 \n    0.8315 \n    0.8340 \n    0.8365 \n    0.8389 \n  \n  \n    1.0 \n    0.8413 \n    0.8438 \n    0.8461 \n    0.8485 \n    0.8508 \n    0.8531 \n    0.8554 \n    0.8577 \n    0.8599 \n    0.8621 \n  \n  \n    1.1 \n    0.8643 \n    0.8665 \n    0.8686 \n    0.8708 \n    0.8729 \n    0.8749 \n    0.8770 \n    0.8790 \n    0.8810 \n    0.8830 \n  \n  \n    1.2 \n    0.8849 \n    0.8869 \n    0.8888 \n    0.8907 \n    0.8925 \n    0.8944 \n    0.8962 \n    0.8980 \n    0.8997 \n    0.9015 \n  \n  \n    1.3 \n    0.9032 \n    0.9049 \n    0.9066 \n    0.9082 \n    0.9099 \n    0.9115 \n    0.9131 \n    0.9147 \n    0.9162 \n    0.9177 \n  \n  \n    1.4 \n    0.9192 \n    0.9207 \n    0.9222 \n    0.9236 \n    0.9251 \n    0.9265 \n    0.9279 \n    0.9292 \n    0.9306 \n    0.9319 \n  \n  \n    1.5 \n    0.9332 \n    0.9345 \n    0.9357 \n    0.9370 \n    0.9382 \n    0.9394 \n    0.9406 \n    0.9418 \n    0.9429 \n    0.9441 \n  \n  \n    1.6 \n    0.9452 \n    0.9463 \n    0.9474 \n    0.9484 \n    0.9495 \n    0.9505 \n    0.9515 \n    0.9525 \n    0.9535 \n    0.9545 \n  \n  \n    1.7 \n    0.9554 \n    0.9564 \n    0.9573 \n    0.9582 \n    0.9591 \n    0.9599 \n    0.9608 \n    0.9616 \n    0.9625 \n    0.9633 \n  \n  \n    1.8 \n    0.9641 \n    0.9649 \n    0.9656 \n    0.9664 \n    0.9671 \n    0.9678 \n    0.9686 \n    0.9693 \n    0.9699 \n    0.9706 \n  \n  \n    1.9 \n    0.9713 \n    0.9719 \n    0.9726 \n    0.9732 \n    0.9738 \n    0.9744 \n    0.9750 \n    0.9756 \n    0.9761 \n    0.9767 \n  \n  \n    2.0 \n    0.9772 \n    0.9778 \n    0.9783 \n    0.9788 \n    0.9793 \n    0.9798 \n    0.9803 \n    0.9808 \n    0.9812 \n    0.9817 \n  \n  \n    2.1 \n    0.9821 \n    0.9826 \n    0.9830 \n    0.9834 \n    0.9838 \n    0.9842 \n    0.9846 \n    0.9850 \n    0.9854 \n    0.9857 \n  \n  \n    2.2 \n    0.9861 \n    0.9864 \n    0.9868 \n    0.9871 \n    0.9875 \n    0.9878 \n    0.9881 \n    0.9884 \n    0.9887 \n    0.9890 \n  \n  \n    2.3 \n    0.9893 \n    0.9896 \n    0.9898 \n    0.9901 \n    0.9904 \n    0.9906 \n    0.9909 \n    0.9911 \n    0.9913 \n    0.9916 \n  \n  \n    2.4 \n    0.9918 \n    0.9920 \n    0.9922 \n    0.9925 \n    0.9927 \n    0.9929 \n    0.9931 \n    0.9932 \n    0.9934 \n    0.9936 \n  \n  \n    2.5 \n    0.9938 \n    0.9940 \n    0.9941 \n    0.9943 \n    0.9945 \n    0.9946 \n    0.9948 \n    0.9949 \n    0.9951 \n    0.9952 \n  \n  \n    2.6 \n    0.9953 \n    0.9955 \n    0.9956 \n    0.9957 \n    0.9959 \n    0.9960 \n    0.9961 \n    0.9962 \n    0.9963 \n    0.9964 \n  \n  \n    2.7 \n    0.9965 \n    0.9966 \n    0.9967 \n    0.9968 \n    0.9969 \n    0.9970 \n    0.9971 \n    0.9972 \n    0.9973 \n    0.9974 \n  \n  \n    2.8 \n    0.9974 \n    0.9975 \n    0.9976 \n    0.9977 \n    0.9977 \n    0.9978 \n    0.9979 \n    0.9979 \n    0.9980 \n    0.9981 \n  \n  \n    2.9 \n    0.9981 \n    0.9982 \n    0.9982 \n    0.9983 \n    0.9984 \n    0.9984 \n    0.9985 \n    0.9985 \n    0.9986 \n    0.9986"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#student-t-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#student-t-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "Student-\\(t\\) fördelning",
    "text": "Student-\\(t\\) fördelning\n\n\n      \n\n\n\n\n\n\n\nKonfidensnivå: \n 80%\n 90%\n 95%\n 98%\n 99%\n\n\nTvåsidig sannolikhet: \n0.200\n0.100\n0.050\n0.020\n0.010\n\n\nEnsidig sannolikhet: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    3.078 \n    6.314 \n    12.706 \n    31.821 \n    63.657 \n  \n  \n    2 \n    1.886 \n    2.920 \n    4.303 \n    6.965 \n    9.925 \n  \n  \n    3 \n    1.638 \n    2.353 \n    3.182 \n    4.541 \n    5.841 \n  \n  \n    4 \n    1.533 \n    2.132 \n    2.776 \n    3.747 \n    4.604 \n  \n  \n    5 \n    1.476 \n    2.015 \n    2.571 \n    3.365 \n    4.032 \n  \n  \n    6 \n    1.440 \n    1.943 \n    2.447 \n    3.143 \n    3.707 \n  \n  \n    7 \n    1.415 \n    1.895 \n    2.365 \n    2.998 \n    3.499 \n  \n  \n    8 \n    1.397 \n    1.860 \n    2.306 \n    2.896 \n    3.355 \n  \n  \n    9 \n    1.383 \n    1.833 \n    2.262 \n    2.821 \n    3.250 \n  \n  \n    10 \n    1.372 \n    1.812 \n    2.228 \n    2.764 \n    3.169 \n  \n  \n    11 \n    1.363 \n    1.796 \n    2.201 \n    2.718 \n    3.106 \n  \n  \n    12 \n    1.356 \n    1.782 \n    2.179 \n    2.681 \n    3.055 \n  \n  \n    13 \n    1.350 \n    1.771 \n    2.160 \n    2.650 \n    3.012 \n  \n  \n    14 \n    1.345 \n    1.761 \n    2.145 \n    2.624 \n    2.977 \n  \n  \n    15 \n    1.341 \n    1.753 \n    2.131 \n    2.602 \n    2.947 \n  \n  \n    16 \n    1.337 \n    1.746 \n    2.120 \n    2.583 \n    2.921 \n  \n  \n    17 \n    1.333 \n    1.740 \n    2.110 \n    2.567 \n    2.898 \n  \n  \n    18 \n    1.330 \n    1.734 \n    2.101 \n    2.552 \n    2.878 \n  \n  \n    19 \n    1.328 \n    1.729 \n    2.093 \n    2.539 \n    2.861 \n  \n  \n    20 \n    1.325 \n    1.725 \n    2.086 \n    2.528 \n    2.845 \n  \n  \n    21 \n    1.323 \n    1.721 \n    2.080 \n    2.518 \n    2.831 \n  \n  \n    22 \n    1.321 \n    1.717 \n    2.074 \n    2.508 \n    2.819 \n  \n  \n    23 \n    1.319 \n    1.714 \n    2.069 \n    2.500 \n    2.807 \n  \n  \n    24 \n    1.318 \n    1.711 \n    2.064 \n    2.492 \n    2.797 \n  \n  \n    25 \n    1.316 \n    1.708 \n    2.060 \n    2.485 \n    2.787 \n  \n  \n    26 \n    1.315 \n    1.706 \n    2.056 \n    2.479 \n    2.779 \n  \n  \n    27 \n    1.314 \n    1.703 \n    2.052 \n    2.473 \n    2.771 \n  \n  \n    28 \n    1.313 \n    1.701 \n    2.048 \n    2.467 \n    2.763 \n  \n  \n    29 \n    1.311 \n    1.699 \n    2.045 \n    2.462 \n    2.756 \n  \n  \n    30 \n    1.310 \n    1.697 \n    2.042 \n    2.457 \n    2.750 \n  \n  \n    32 \n    1.309 \n    1.694 \n    2.037 \n    2.449 \n    2.738 \n  \n  \n    35 \n    1.306 \n    1.690 \n    2.030 \n    2.438 \n    2.724 \n  \n  \n    40 \n    1.303 \n    1.684 \n    2.021 \n    2.423 \n    2.704 \n  \n  \n    45 \n    1.301 \n    1.679 \n    2.014 \n    2.412 \n    2.690 \n  \n  \n    50 \n    1.299 \n    1.676 \n    2.009 \n    2.403 \n    2.678 \n  \n  \n    60 \n    1.296 \n    1.671 \n    2.000 \n    2.390 \n    2.660 \n  \n  \n    75 \n    1.293 \n    1.665 \n    1.992 \n    2.377 \n    2.643 \n  \n  \n    100 \n    1.290 \n    1.660 \n    1.984 \n    2.364 \n    2.626 \n  \n  \n    120 \n    1.289 \n    1.658 \n    1.980 \n    2.358 \n    2.617 \n  \n  \n    140 \n    1.288 \n    1.656 \n    1.977 \n    2.353 \n    2.611 \n  \n  \n    180 \n    1.286 \n    1.653 \n    1.973 \n    2.347 \n    2.603 \n  \n  \n    250 \n    1.285 \n    1.651 \n    1.969 \n    2.341 \n    2.596 \n  \n  \n    400 \n    1.284 \n    1.649 \n    1.966 \n    2.336 \n    2.588 \n  \n  \n    1000 \n    1.282 \n    1.646 \n    1.962 \n    2.330 \n    2.581 \n  \n  \n    oändligt \n    1.282 \n    1.645 \n    1.960 \n    2.326 \n    2.576"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#chi2-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#chi2-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(\\chi^2\\)-fördelning",
    "text": "\\(\\chi^2\\)-fördelning\n\n\n  \n\n\n\n\n\n\n\nSannolikhet i höger svans: \n0.100\n0.050\n0.025\n0.010\n0.005\n\n\ndf \n\n\n\n\n\n\n\n\n  \n    1 \n    2.706 \n    3.841 \n    5.024 \n    6.635 \n    7.879 \n  \n  \n    2 \n    4.605 \n    5.991 \n    7.378 \n    9.210 \n    10.597 \n  \n  \n    3 \n    6.251 \n    7.815 \n    9.348 \n    11.345 \n    12.838 \n  \n  \n    4 \n    7.779 \n    9.488 \n    11.143 \n    13.277 \n    14.860 \n  \n  \n    5 \n    9.236 \n    11.070 \n    12.833 \n    15.086 \n    16.750 \n  \n  \n    6 \n    10.645 \n    12.592 \n    14.449 \n    16.812 \n    18.548 \n  \n  \n    7 \n    12.017 \n    14.067 \n    16.013 \n    18.475 \n    20.278 \n  \n  \n    8 \n    13.362 \n    15.507 \n    17.535 \n    20.090 \n    21.955 \n  \n  \n    9 \n    14.684 \n    16.919 \n    19.023 \n    21.666 \n    23.589 \n  \n  \n    10 \n    15.987 \n    18.307 \n    20.483 \n    23.209 \n    25.188 \n  \n  \n    11 \n    17.275 \n    19.675 \n    21.920 \n    24.725 \n    26.757 \n  \n  \n    12 \n    18.549 \n    21.026 \n    23.337 \n    26.217 \n    28.300 \n  \n  \n    13 \n    19.812 \n    22.362 \n    24.736 \n    27.688 \n    29.819 \n  \n  \n    14 \n    21.064 \n    23.685 \n    26.119 \n    29.141 \n    31.319 \n  \n  \n    15 \n    22.307 \n    24.996 \n    27.488 \n    30.578 \n    32.801 \n  \n  \n    16 \n    23.542 \n    26.296 \n    28.845 \n    32.000 \n    34.267 \n  \n  \n    17 \n    24.769 \n    27.587 \n    30.191 \n    33.409 \n    35.718 \n  \n  \n    18 \n    25.989 \n    28.869 \n    31.526 \n    34.805 \n    37.156 \n  \n  \n    19 \n    27.204 \n    30.144 \n    32.852 \n    36.191 \n    38.582 \n  \n  \n    20 \n    28.412 \n    31.410 \n    34.170 \n    37.566 \n    39.997 \n  \n  \n    21 \n    29.615 \n    32.671 \n    35.479 \n    38.932 \n    41.401 \n  \n  \n    22 \n    30.813 \n    33.924 \n    36.781 \n    40.289 \n    42.796 \n  \n  \n    23 \n    32.007 \n    35.172 \n    38.076 \n    41.638 \n    44.181 \n  \n  \n    24 \n    33.196 \n    36.415 \n    39.364 \n    42.980 \n    45.559 \n  \n  \n    25 \n    34.382 \n    37.652 \n    40.646 \n    44.314 \n    46.928 \n  \n  \n    26 \n    35.563 \n    38.885 \n    41.923 \n    45.642 \n    48.290 \n  \n  \n    27 \n    36.741 \n    40.113 \n    43.195 \n    46.963 \n    49.645 \n  \n  \n    28 \n    37.916 \n    41.337 \n    44.461 \n    48.278 \n    50.993 \n  \n  \n    29 \n    39.087 \n    42.557 \n    45.722 \n    49.588 \n    52.336 \n  \n  \n    30 \n    40.256 \n    43.773 \n    46.979 \n    50.892 \n    53.672 \n  \n  \n    40 \n    51.805 \n    55.758 \n    59.342 \n    63.691 \n    66.766 \n  \n  \n    50 \n    63.167 \n    67.505 \n    71.420 \n    76.154 \n    79.490 \n  \n  \n    60 \n    74.397 \n    79.082 \n    83.298 \n    88.379 \n    91.952 \n  \n  \n    70 \n    85.527 \n    90.531 \n    95.023 \n    100.425 \n    104.215 \n  \n  \n    80 \n    96.578 \n    101.879 \n    106.629 \n    112.329 \n    116.321 \n  \n  \n    90 \n    107.565 \n    113.145 \n    118.136 \n    124.116 \n    128.299 \n  \n  \n    100 \n    118.498 \n    124.342 \n    129.561 \n    135.807 \n    140.169"
  },
  {
    "objectID": "formel_tabell_samlingar/tabellsamling_print.html#f-fördelning",
    "href": "formel_tabell_samlingar/tabellsamling_print.html#f-fördelning",
    "title": "Tabellsamling - Statistik och Dataanalys I",
    "section": "\\(F\\)-fördelning",
    "text": "\\(F\\)-fördelning\n\n\\(\\alpha = 0.01\\)\\(\\alpha = 0.05\\)\\(\\alpha = 0.10\\)\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    4052.18 \n    4999.50 \n    5403.35 \n    5624.58 \n    5763.65 \n    5858.99 \n    5928.36 \n    5981.07 \n    6022.47 \n    6055.85 \n    6083.32 \n    6106.32 \n    6125.86 \n    6142.67 \n    6157.28 \n    6170.10 \n    6181.43 \n    6191.53 \n    6200.58 \n    6208.73 \n    6216.12 \n    6222.84 \n  \n  \n    2 \n    98.50 \n    99.00 \n    99.17 \n    99.25 \n    99.30 \n    99.33 \n    99.36 \n    99.37 \n    99.39 \n    99.40 \n    99.41 \n    99.42 \n    99.42 \n    99.43 \n    99.43 \n    99.44 \n    99.44 \n    99.44 \n    99.45 \n    99.45 \n    99.45 \n    99.45 \n  \n  \n    3 \n    34.12 \n    30.82 \n    29.46 \n    28.71 \n    28.24 \n    27.91 \n    27.67 \n    27.49 \n    27.35 \n    27.23 \n    27.13 \n    27.05 \n    26.98 \n    26.92 \n    26.87 \n    26.83 \n    26.79 \n    26.75 \n    26.72 \n    26.69 \n    26.66 \n    26.64 \n  \n  \n    4 \n    21.20 \n    18.00 \n    16.69 \n    15.98 \n    15.52 \n    15.21 \n    14.98 \n    14.80 \n    14.66 \n    14.55 \n    14.45 \n    14.37 \n    14.31 \n    14.25 \n    14.20 \n    14.15 \n    14.11 \n    14.08 \n    14.05 \n    14.02 \n    13.99 \n    13.97 \n  \n  \n    5 \n    16.26 \n    13.27 \n    12.06 \n    11.39 \n    10.97 \n    10.67 \n    10.46 \n    10.29 \n    10.16 \n    10.05 \n    9.96 \n    9.89 \n    9.82 \n    9.77 \n    9.72 \n    9.68 \n    9.64 \n    9.61 \n    9.58 \n    9.55 \n    9.53 \n    9.51 \n  \n  \n    6 \n    13.75 \n    10.92 \n    9.78 \n    9.15 \n    8.75 \n    8.47 \n    8.26 \n    8.10 \n    7.98 \n    7.87 \n    7.79 \n    7.72 \n    7.66 \n    7.60 \n    7.56 \n    7.52 \n    7.48 \n    7.45 \n    7.42 \n    7.40 \n    7.37 \n    7.35 \n  \n  \n    7 \n    12.25 \n    9.55 \n    8.45 \n    7.85 \n    7.46 \n    7.19 \n    6.99 \n    6.84 \n    6.72 \n    6.62 \n    6.54 \n    6.47 \n    6.41 \n    6.36 \n    6.31 \n    6.28 \n    6.24 \n    6.21 \n    6.18 \n    6.16 \n    6.13 \n    6.11 \n  \n  \n    8 \n    11.26 \n    8.65 \n    7.59 \n    7.01 \n    6.63 \n    6.37 \n    6.18 \n    6.03 \n    5.91 \n    5.81 \n    5.73 \n    5.67 \n    5.61 \n    5.56 \n    5.52 \n    5.48 \n    5.44 \n    5.41 \n    5.38 \n    5.36 \n    5.34 \n    5.32 \n  \n  \n    9 \n    10.56 \n    8.02 \n    6.99 \n    6.42 \n    6.06 \n    5.80 \n    5.61 \n    5.47 \n    5.35 \n    5.26 \n    5.18 \n    5.11 \n    5.05 \n    5.01 \n    4.96 \n    4.92 \n    4.89 \n    4.86 \n    4.83 \n    4.81 \n    4.79 \n    4.77 \n  \n  \n    10 \n    10.04 \n    7.56 \n    6.55 \n    5.99 \n    5.64 \n    5.39 \n    5.20 \n    5.06 \n    4.94 \n    4.85 \n    4.77 \n    4.71 \n    4.65 \n    4.60 \n    4.56 \n    4.52 \n    4.49 \n    4.46 \n    4.43 \n    4.41 \n    4.38 \n    4.36 \n  \n  \n    11 \n    9.65 \n    7.21 \n    6.22 \n    5.67 \n    5.32 \n    5.07 \n    4.89 \n    4.74 \n    4.63 \n    4.54 \n    4.46 \n    4.40 \n    4.34 \n    4.29 \n    4.25 \n    4.21 \n    4.18 \n    4.15 \n    4.12 \n    4.10 \n    4.08 \n    4.06 \n  \n  \n    12 \n    9.33 \n    6.93 \n    5.95 \n    5.41 \n    5.06 \n    4.82 \n    4.64 \n    4.50 \n    4.39 \n    4.30 \n    4.22 \n    4.16 \n    4.10 \n    4.05 \n    4.01 \n    3.97 \n    3.94 \n    3.91 \n    3.88 \n    3.86 \n    3.84 \n    3.82 \n  \n  \n    13 \n    9.07 \n    6.70 \n    5.74 \n    5.21 \n    4.86 \n    4.62 \n    4.44 \n    4.30 \n    4.19 \n    4.10 \n    4.02 \n    3.96 \n    3.91 \n    3.86 \n    3.82 \n    3.78 \n    3.75 \n    3.72 \n    3.69 \n    3.66 \n    3.64 \n    3.62 \n  \n  \n    14 \n    8.86 \n    6.51 \n    5.56 \n    5.04 \n    4.69 \n    4.46 \n    4.28 \n    4.14 \n    4.03 \n    3.94 \n    3.86 \n    3.80 \n    3.75 \n    3.70 \n    3.66 \n    3.62 \n    3.59 \n    3.56 \n    3.53 \n    3.51 \n    3.48 \n    3.46 \n  \n  \n    15 \n    8.68 \n    6.36 \n    5.42 \n    4.89 \n    4.56 \n    4.32 \n    4.14 \n    4.00 \n    3.89 \n    3.80 \n    3.73 \n    3.67 \n    3.61 \n    3.56 \n    3.52 \n    3.49 \n    3.45 \n    3.42 \n    3.40 \n    3.37 \n    3.35 \n    3.33 \n  \n  \n    16 \n    8.53 \n    6.23 \n    5.29 \n    4.77 \n    4.44 \n    4.20 \n    4.03 \n    3.89 \n    3.78 \n    3.69 \n    3.62 \n    3.55 \n    3.50 \n    3.45 \n    3.41 \n    3.37 \n    3.34 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n  \n  \n    17 \n    8.40 \n    6.11 \n    5.18 \n    4.67 \n    4.34 \n    4.10 \n    3.93 \n    3.79 \n    3.68 \n    3.59 \n    3.52 \n    3.46 \n    3.40 \n    3.35 \n    3.31 \n    3.27 \n    3.24 \n    3.21 \n    3.19 \n    3.16 \n    3.14 \n    3.12 \n  \n  \n    18 \n    8.29 \n    6.01 \n    5.09 \n    4.58 \n    4.25 \n    4.01 \n    3.84 \n    3.71 \n    3.60 \n    3.51 \n    3.43 \n    3.37 \n    3.32 \n    3.27 \n    3.23 \n    3.19 \n    3.16 \n    3.13 \n    3.10 \n    3.08 \n    3.05 \n    3.03 \n  \n  \n    19 \n    8.18 \n    5.93 \n    5.01 \n    4.50 \n    4.17 \n    3.94 \n    3.77 \n    3.63 \n    3.52 \n    3.43 \n    3.36 \n    3.30 \n    3.24 \n    3.19 \n    3.15 \n    3.12 \n    3.08 \n    3.05 \n    3.03 \n    3.00 \n    2.98 \n    2.96 \n  \n  \n    20 \n    8.10 \n    5.85 \n    4.94 \n    4.43 \n    4.10 \n    3.87 \n    3.70 \n    3.56 \n    3.46 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.13 \n    3.09 \n    3.05 \n    3.02 \n    2.99 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n  \n  \n    21 \n    8.02 \n    5.78 \n    4.87 \n    4.37 \n    4.04 \n    3.81 \n    3.64 \n    3.51 \n    3.40 \n    3.31 \n    3.24 \n    3.17 \n    3.12 \n    3.07 \n    3.03 \n    2.99 \n    2.96 \n    2.93 \n    2.90 \n    2.88 \n    2.86 \n    2.84 \n  \n  \n    22 \n    7.95 \n    5.72 \n    4.82 \n    4.31 \n    3.99 \n    3.76 \n    3.59 \n    3.45 \n    3.35 \n    3.26 \n    3.18 \n    3.12 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.88 \n    2.85 \n    2.83 \n    2.81 \n    2.78 \n  \n  \n    23 \n    7.88 \n    5.66 \n    4.76 \n    4.26 \n    3.94 \n    3.71 \n    3.54 \n    3.41 \n    3.30 \n    3.21 \n    3.14 \n    3.07 \n    3.02 \n    2.97 \n    2.93 \n    2.89 \n    2.86 \n    2.83 \n    2.80 \n    2.78 \n    2.76 \n    2.74 \n  \n  \n    24 \n    7.82 \n    5.61 \n    4.72 \n    4.22 \n    3.90 \n    3.67 \n    3.50 \n    3.36 \n    3.26 \n    3.17 \n    3.09 \n    3.03 \n    2.98 \n    2.93 \n    2.89 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n  \n  \n    25 \n    7.77 \n    5.57 \n    4.68 \n    4.18 \n    3.85 \n    3.63 \n    3.46 \n    3.32 \n    3.22 \n    3.13 \n    3.06 \n    2.99 \n    2.94 \n    2.89 \n    2.85 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.66 \n  \n  \n    26 \n    7.72 \n    5.53 \n    4.64 \n    4.14 \n    3.82 \n    3.59 \n    3.42 \n    3.29 \n    3.18 \n    3.09 \n    3.02 \n    2.96 \n    2.90 \n    2.86 \n    2.81 \n    2.78 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n  \n  \n    27 \n    7.68 \n    5.49 \n    4.60 \n    4.11 \n    3.78 \n    3.56 \n    3.39 \n    3.26 \n    3.15 \n    3.06 \n    2.99 \n    2.93 \n    2.87 \n    2.82 \n    2.78 \n    2.75 \n    2.71 \n    2.68 \n    2.66 \n    2.63 \n    2.61 \n    2.59 \n  \n  \n    28 \n    7.64 \n    5.45 \n    4.57 \n    4.07 \n    3.75 \n    3.53 \n    3.36 \n    3.23 \n    3.12 \n    3.03 \n    2.96 \n    2.90 \n    2.84 \n    2.79 \n    2.75 \n    2.72 \n    2.68 \n    2.65 \n    2.63 \n    2.60 \n    2.58 \n    2.56 \n  \n  \n    29 \n    7.60 \n    5.42 \n    4.54 \n    4.04 \n    3.73 \n    3.50 \n    3.33 \n    3.20 \n    3.09 \n    3.00 \n    2.93 \n    2.87 \n    2.81 \n    2.77 \n    2.73 \n    2.69 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n  \n  \n    30 \n    7.56 \n    5.39 \n    4.51 \n    4.02 \n    3.70 \n    3.47 \n    3.30 \n    3.17 \n    3.07 \n    2.98 \n    2.91 \n    2.84 \n    2.79 \n    2.74 \n    2.70 \n    2.66 \n    2.63 \n    2.60 \n    2.57 \n    2.55 \n    2.53 \n    2.51 \n  \n  \n    35 \n    7.42 \n    5.27 \n    4.40 \n    3.91 \n    3.59 \n    3.37 \n    3.20 \n    3.07 \n    2.96 \n    2.88 \n    2.80 \n    2.74 \n    2.69 \n    2.64 \n    2.60 \n    2.56 \n    2.53 \n    2.50 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n  \n  \n    40 \n    7.31 \n    5.18 \n    4.31 \n    3.83 \n    3.51 \n    3.29 \n    3.12 \n    2.99 \n    2.89 \n    2.80 \n    2.73 \n    2.66 \n    2.61 \n    2.56 \n    2.52 \n    2.48 \n    2.45 \n    2.42 \n    2.39 \n    2.37 \n    2.35 \n    2.33 \n  \n  \n    45 \n    7.23 \n    5.11 \n    4.25 \n    3.77 \n    3.45 \n    3.23 \n    3.07 \n    2.94 \n    2.83 \n    2.74 \n    2.67 \n    2.61 \n    2.55 \n    2.51 \n    2.46 \n    2.43 \n    2.39 \n    2.36 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n  \n  \n    50 \n    7.17 \n    5.06 \n    4.20 \n    3.72 \n    3.41 \n    3.19 \n    3.02 \n    2.89 \n    2.78 \n    2.70 \n    2.63 \n    2.56 \n    2.51 \n    2.46 \n    2.42 \n    2.38 \n    2.35 \n    2.32 \n    2.29 \n    2.27 \n    2.24 \n    2.22 \n  \n  \n    60 \n    7.08 \n    4.98 \n    4.13 \n    3.65 \n    3.34 \n    3.12 \n    2.95 \n    2.82 \n    2.72 \n    2.63 \n    2.56 \n    2.50 \n    2.44 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.17 \n    2.15 \n  \n  \n    75 \n    6.99 \n    4.90 \n    4.05 \n    3.58 \n    3.27 \n    3.05 \n    2.89 \n    2.76 \n    2.65 \n    2.57 \n    2.49 \n    2.43 \n    2.38 \n    2.33 \n    2.29 \n    2.25 \n    2.22 \n    2.18 \n    2.16 \n    2.13 \n    2.11 \n    2.09 \n  \n  \n    100 \n    6.90 \n    4.82 \n    3.98 \n    3.51 \n    3.21 \n    2.99 \n    2.82 \n    2.69 \n    2.59 \n    2.50 \n    2.43 \n    2.37 \n    2.31 \n    2.27 \n    2.22 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.04 \n    2.02 \n  \n  \n    120 \n    6.85 \n    4.79 \n    3.95 \n    3.48 \n    3.17 \n    2.96 \n    2.79 \n    2.66 \n    2.56 \n    2.47 \n    2.40 \n    2.34 \n    2.28 \n    2.23 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n  \n  \n    140 \n    6.82 \n    4.76 \n    3.92 \n    3.46 \n    3.15 \n    2.93 \n    2.77 \n    2.64 \n    2.54 \n    2.45 \n    2.38 \n    2.31 \n    2.26 \n    2.21 \n    2.17 \n    2.13 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.97 \n  \n  \n    180 \n    6.78 \n    4.73 \n    3.89 \n    3.43 \n    3.12 \n    2.90 \n    2.74 \n    2.61 \n    2.51 \n    2.42 \n    2.35 \n    2.28 \n    2.23 \n    2.18 \n    2.14 \n    2.10 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.96 \n    1.94 \n  \n  \n    250 \n    6.74 \n    4.69 \n    3.86 \n    3.40 \n    3.09 \n    2.87 \n    2.71 \n    2.58 \n    2.48 \n    2.39 \n    2.32 \n    2.26 \n    2.20 \n    2.15 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.98 \n    1.95 \n    1.93 \n    1.91 \n  \n  \n    400 \n    6.70 \n    4.66 \n    3.83 \n    3.37 \n    3.06 \n    2.85 \n    2.68 \n    2.56 \n    2.45 \n    2.37 \n    2.29 \n    2.23 \n    2.17 \n    2.13 \n    2.08 \n    2.05 \n    2.01 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.88 \n  \n  \n    1000 \n    6.66 \n    4.63 \n    3.80 \n    3.34 \n    3.04 \n    2.82 \n    2.66 \n    2.53 \n    2.43 \n    2.34 \n    2.27 \n    2.20 \n    2.15 \n    2.10 \n    2.06 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.85 \n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    161.45 \n    199.50 \n    215.71 \n    224.58 \n    230.16 \n    233.99 \n    236.77 \n    238.88 \n    240.54 \n    241.88 \n    242.98 \n    243.91 \n    244.69 \n    245.36 \n    245.95 \n    246.46 \n    246.92 \n    247.32 \n    247.69 \n    248.01 \n    248.31 \n    248.58 \n  \n  \n    2 \n    18.51 \n    19.00 \n    19.16 \n    19.25 \n    19.30 \n    19.33 \n    19.35 \n    19.37 \n    19.38 \n    19.40 \n    19.40 \n    19.41 \n    19.42 \n    19.42 \n    19.43 \n    19.43 \n    19.44 \n    19.44 \n    19.44 \n    19.45 \n    19.45 \n    19.45 \n  \n  \n    3 \n    10.13 \n    9.55 \n    9.28 \n    9.12 \n    9.01 \n    8.94 \n    8.89 \n    8.85 \n    8.81 \n    8.79 \n    8.76 \n    8.74 \n    8.73 \n    8.71 \n    8.70 \n    8.69 \n    8.68 \n    8.67 \n    8.67 \n    8.66 \n    8.65 \n    8.65 \n  \n  \n    4 \n    7.71 \n    6.94 \n    6.59 \n    6.39 \n    6.26 \n    6.16 \n    6.09 \n    6.04 \n    6.00 \n    5.96 \n    5.94 \n    5.91 \n    5.89 \n    5.87 \n    5.86 \n    5.84 \n    5.83 \n    5.82 \n    5.81 \n    5.80 \n    5.79 \n    5.79 \n  \n  \n    5 \n    6.61 \n    5.79 \n    5.41 \n    5.19 \n    5.05 \n    4.95 \n    4.88 \n    4.82 \n    4.77 \n    4.74 \n    4.70 \n    4.68 \n    4.66 \n    4.64 \n    4.62 \n    4.60 \n    4.59 \n    4.58 \n    4.57 \n    4.56 \n    4.55 \n    4.54 \n  \n  \n    6 \n    5.99 \n    5.14 \n    4.76 \n    4.53 \n    4.39 \n    4.28 \n    4.21 \n    4.15 \n    4.10 \n    4.06 \n    4.03 \n    4.00 \n    3.98 \n    3.96 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n  \n  \n    7 \n    5.59 \n    4.74 \n    4.35 \n    4.12 \n    3.97 \n    3.87 \n    3.79 \n    3.73 \n    3.68 \n    3.64 \n    3.60 \n    3.57 \n    3.55 \n    3.53 \n    3.51 \n    3.49 \n    3.48 \n    3.47 \n    3.46 \n    3.44 \n    3.43 \n    3.43 \n  \n  \n    8 \n    5.32 \n    4.46 \n    4.07 \n    3.84 \n    3.69 \n    3.58 \n    3.50 \n    3.44 \n    3.39 \n    3.35 \n    3.31 \n    3.28 \n    3.26 \n    3.24 \n    3.22 \n    3.20 \n    3.19 \n    3.17 \n    3.16 \n    3.15 \n    3.14 \n    3.13 \n  \n  \n    9 \n    5.12 \n    4.26 \n    3.86 \n    3.63 \n    3.48 \n    3.37 \n    3.29 \n    3.23 \n    3.18 \n    3.14 \n    3.10 \n    3.07 \n    3.05 \n    3.03 \n    3.01 \n    2.99 \n    2.97 \n    2.96 \n    2.95 \n    2.94 \n    2.93 \n    2.92 \n  \n  \n    10 \n    4.96 \n    4.10 \n    3.71 \n    3.48 \n    3.33 \n    3.22 \n    3.14 \n    3.07 \n    3.02 \n    2.98 \n    2.94 \n    2.91 \n    2.89 \n    2.86 \n    2.85 \n    2.83 \n    2.81 \n    2.80 \n    2.79 \n    2.77 \n    2.76 \n    2.75 \n  \n  \n    11 \n    4.84 \n    3.98 \n    3.59 \n    3.36 \n    3.20 \n    3.09 \n    3.01 \n    2.95 \n    2.90 \n    2.85 \n    2.82 \n    2.79 \n    2.76 \n    2.74 \n    2.72 \n    2.70 \n    2.69 \n    2.67 \n    2.66 \n    2.65 \n    2.64 \n    2.63 \n  \n  \n    12 \n    4.75 \n    3.89 \n    3.49 \n    3.26 \n    3.11 \n    3.00 \n    2.91 \n    2.85 \n    2.80 \n    2.75 \n    2.72 \n    2.69 \n    2.66 \n    2.64 \n    2.62 \n    2.60 \n    2.58 \n    2.57 \n    2.56 \n    2.54 \n    2.53 \n    2.52 \n  \n  \n    13 \n    4.67 \n    3.81 \n    3.41 \n    3.18 \n    3.03 \n    2.92 \n    2.83 \n    2.77 \n    2.71 \n    2.67 \n    2.63 \n    2.60 \n    2.58 \n    2.55 \n    2.53 \n    2.51 \n    2.50 \n    2.48 \n    2.47 \n    2.46 \n    2.45 \n    2.44 \n  \n  \n    14 \n    4.60 \n    3.74 \n    3.34 \n    3.11 \n    2.96 \n    2.85 \n    2.76 \n    2.70 \n    2.65 \n    2.60 \n    2.57 \n    2.53 \n    2.51 \n    2.48 \n    2.46 \n    2.44 \n    2.43 \n    2.41 \n    2.40 \n    2.39 \n    2.38 \n    2.37 \n  \n  \n    15 \n    4.54 \n    3.68 \n    3.29 \n    3.06 \n    2.90 \n    2.79 \n    2.71 \n    2.64 \n    2.59 \n    2.54 \n    2.51 \n    2.48 \n    2.45 \n    2.42 \n    2.40 \n    2.38 \n    2.37 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n  \n  \n    16 \n    4.49 \n    3.63 \n    3.24 \n    3.01 \n    2.85 \n    2.74 \n    2.66 \n    2.59 \n    2.54 \n    2.49 \n    2.46 \n    2.42 \n    2.40 \n    2.37 \n    2.35 \n    2.33 \n    2.32 \n    2.30 \n    2.29 \n    2.28 \n    2.26 \n    2.25 \n  \n  \n    17 \n    4.45 \n    3.59 \n    3.20 \n    2.96 \n    2.81 \n    2.70 \n    2.61 \n    2.55 \n    2.49 \n    2.45 \n    2.41 \n    2.38 \n    2.35 \n    2.33 \n    2.31 \n    2.29 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.21 \n  \n  \n    18 \n    4.41 \n    3.55 \n    3.16 \n    2.93 \n    2.77 \n    2.66 \n    2.58 \n    2.51 \n    2.46 \n    2.41 \n    2.37 \n    2.34 \n    2.31 \n    2.29 \n    2.27 \n    2.25 \n    2.23 \n    2.22 \n    2.20 \n    2.19 \n    2.18 \n    2.17 \n  \n  \n    19 \n    4.38 \n    3.52 \n    3.13 \n    2.90 \n    2.74 \n    2.63 \n    2.54 \n    2.48 \n    2.42 \n    2.38 \n    2.34 \n    2.31 \n    2.28 \n    2.26 \n    2.23 \n    2.21 \n    2.20 \n    2.18 \n    2.17 \n    2.16 \n    2.14 \n    2.13 \n  \n  \n    20 \n    4.35 \n    3.49 \n    3.10 \n    2.87 \n    2.71 \n    2.60 \n    2.51 \n    2.45 \n    2.39 \n    2.35 \n    2.31 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.17 \n    2.15 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n  \n  \n    21 \n    4.32 \n    3.47 \n    3.07 \n    2.84 \n    2.68 \n    2.57 \n    2.49 \n    2.42 \n    2.37 \n    2.32 \n    2.28 \n    2.25 \n    2.22 \n    2.20 \n    2.18 \n    2.16 \n    2.14 \n    2.12 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n  \n  \n    22 \n    4.30 \n    3.44 \n    3.05 \n    2.82 \n    2.66 \n    2.55 \n    2.46 \n    2.40 \n    2.34 \n    2.30 \n    2.26 \n    2.23 \n    2.20 \n    2.17 \n    2.15 \n    2.13 \n    2.11 \n    2.10 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n  \n  \n    23 \n    4.28 \n    3.42 \n    3.03 \n    2.80 \n    2.64 \n    2.53 \n    2.44 \n    2.37 \n    2.32 \n    2.27 \n    2.24 \n    2.20 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.08 \n    2.06 \n    2.05 \n    2.04 \n    2.02 \n  \n  \n    24 \n    4.26 \n    3.40 \n    3.01 \n    2.78 \n    2.62 \n    2.51 \n    2.42 \n    2.36 \n    2.30 \n    2.25 \n    2.22 \n    2.18 \n    2.15 \n    2.13 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.01 \n    2.00 \n  \n  \n    25 \n    4.24 \n    3.39 \n    2.99 \n    2.76 \n    2.60 \n    2.49 \n    2.40 \n    2.34 \n    2.28 \n    2.24 \n    2.20 \n    2.16 \n    2.14 \n    2.11 \n    2.09 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.98 \n  \n  \n    26 \n    4.23 \n    3.37 \n    2.98 \n    2.74 \n    2.59 \n    2.47 \n    2.39 \n    2.32 \n    2.27 \n    2.22 \n    2.18 \n    2.15 \n    2.12 \n    2.09 \n    2.07 \n    2.05 \n    2.03 \n    2.02 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n  \n  \n    27 \n    4.21 \n    3.35 \n    2.96 \n    2.73 \n    2.57 \n    2.46 \n    2.37 \n    2.31 \n    2.25 \n    2.20 \n    2.17 \n    2.13 \n    2.10 \n    2.08 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n  \n  \n    28 \n    4.20 \n    3.34 \n    2.95 \n    2.71 \n    2.56 \n    2.45 \n    2.36 \n    2.29 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.93 \n  \n  \n    29 \n    4.18 \n    3.33 \n    2.93 \n    2.70 \n    2.55 \n    2.43 \n    2.35 \n    2.28 \n    2.22 \n    2.18 \n    2.14 \n    2.10 \n    2.08 \n    2.05 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.96 \n    1.94 \n    1.93 \n    1.92 \n  \n  \n    30 \n    4.17 \n    3.32 \n    2.92 \n    2.69 \n    2.53 \n    2.42 \n    2.33 \n    2.27 \n    2.21 \n    2.16 \n    2.13 \n    2.09 \n    2.06 \n    2.04 \n    2.01 \n    1.99 \n    1.98 \n    1.96 \n    1.95 \n    1.93 \n    1.92 \n    1.91 \n  \n  \n    35 \n    4.12 \n    3.27 \n    2.87 \n    2.64 \n    2.49 \n    2.37 \n    2.29 \n    2.22 \n    2.16 \n    2.11 \n    2.07 \n    2.04 \n    2.01 \n    1.99 \n    1.96 \n    1.94 \n    1.92 \n    1.91 \n    1.89 \n    1.88 \n    1.87 \n    1.85 \n  \n  \n    40 \n    4.08 \n    3.23 \n    2.84 \n    2.61 \n    2.45 \n    2.34 \n    2.25 \n    2.18 \n    2.12 \n    2.08 \n    2.04 \n    2.00 \n    1.97 \n    1.95 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.85 \n    1.84 \n    1.83 \n    1.81 \n  \n  \n    45 \n    4.06 \n    3.20 \n    2.81 \n    2.58 \n    2.42 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.05 \n    2.01 \n    1.97 \n    1.94 \n    1.92 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.82 \n    1.81 \n    1.80 \n    1.78 \n  \n  \n    50 \n    4.03 \n    3.18 \n    2.79 \n    2.56 \n    2.40 \n    2.29 \n    2.20 \n    2.13 \n    2.07 \n    2.03 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    60 \n    4.00 \n    3.15 \n    2.76 \n    2.53 \n    2.37 \n    2.25 \n    2.17 \n    2.10 \n    2.04 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.86 \n    1.84 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n  \n  \n    75 \n    3.97 \n    3.12 \n    2.73 \n    2.49 \n    2.34 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.85 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    100 \n    3.94 \n    3.09 \n    2.70 \n    2.46 \n    2.31 \n    2.19 \n    2.10 \n    2.03 \n    1.97 \n    1.93 \n    1.89 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.68 \n    1.66 \n    1.65 \n  \n  \n    120 \n    3.92 \n    3.07 \n    2.68 \n    2.45 \n    2.29 \n    2.18 \n    2.09 \n    2.02 \n    1.96 \n    1.91 \n    1.87 \n    1.83 \n    1.80 \n    1.78 \n    1.75 \n    1.73 \n    1.71 \n    1.69 \n    1.67 \n    1.66 \n    1.64 \n    1.63 \n  \n  \n    140 \n    3.91 \n    3.06 \n    2.67 \n    2.44 \n    2.28 \n    2.16 \n    2.08 \n    2.01 \n    1.95 \n    1.90 \n    1.86 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.62 \n  \n  \n    180 \n    3.89 \n    3.05 \n    2.65 \n    2.42 \n    2.26 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.88 \n    1.84 \n    1.81 \n    1.77 \n    1.75 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n  \n  \n    250 \n    3.88 \n    3.03 \n    2.64 \n    2.41 \n    2.25 \n    2.13 \n    2.05 \n    1.98 \n    1.92 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.73 \n    1.71 \n    1.68 \n    1.66 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n  \n  \n    400 \n    3.86 \n    3.02 \n    2.63 \n    2.39 \n    2.24 \n    2.12 \n    2.03 \n    1.96 \n    1.90 \n    1.85 \n    1.81 \n    1.78 \n    1.74 \n    1.72 \n    1.69 \n    1.67 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n  \n  \n    1000 \n    3.85 \n    3.00 \n    2.61 \n    2.38 \n    2.22 \n    2.11 \n    2.02 \n    1.95 \n    1.89 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.65 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n  \n\n\n\n\n\n\n\n\n\n\n\n  \n\nKolumnerna är frihetsgraderna i täljaren.\nRaderna är frihetsgraderna i nämnaren.\n\n\n\n\n \n\n\nFrihetsgrader i täljaren\n\n  \n      \n     1 \n     2 \n     3 \n     4 \n     5 \n     6 \n     7 \n     8 \n     9 \n    10 \n    11 \n    12 \n    13 \n    14 \n    15 \n    16 \n    17 \n    18 \n    19 \n    20 \n    21 \n    22 \n  \n \n\n  \n    1 \n    39.86 \n    49.50 \n    53.59 \n    55.83 \n    57.24 \n    58.20 \n    58.91 \n    59.44 \n    59.86 \n    60.19 \n    60.47 \n    60.71 \n    60.90 \n    61.07 \n    61.22 \n    61.35 \n    61.46 \n    61.57 \n    61.66 \n    61.74 \n    61.81 \n    61.88 \n  \n  \n    2 \n    8.53 \n    9.00 \n    9.16 \n    9.24 \n    9.29 \n    9.33 \n    9.35 \n    9.37 \n    9.38 \n    9.39 \n    9.40 \n    9.41 \n    9.41 \n    9.42 \n    9.42 \n    9.43 \n    9.43 \n    9.44 \n    9.44 \n    9.44 \n    9.44 \n    9.45 \n  \n  \n    3 \n    5.54 \n    5.46 \n    5.39 \n    5.34 \n    5.31 \n    5.28 \n    5.27 \n    5.25 \n    5.24 \n    5.23 \n    5.22 \n    5.22 \n    5.21 \n    5.20 \n    5.20 \n    5.20 \n    5.19 \n    5.19 \n    5.19 \n    5.18 \n    5.18 \n    5.18 \n  \n  \n    4 \n    4.54 \n    4.32 \n    4.19 \n    4.11 \n    4.05 \n    4.01 \n    3.98 \n    3.95 \n    3.94 \n    3.92 \n    3.91 \n    3.90 \n    3.89 \n    3.88 \n    3.87 \n    3.86 \n    3.86 \n    3.85 \n    3.85 \n    3.84 \n    3.84 \n    3.84 \n  \n  \n    5 \n    4.06 \n    3.78 \n    3.62 \n    3.52 \n    3.45 \n    3.40 \n    3.37 \n    3.34 \n    3.32 \n    3.30 \n    3.28 \n    3.27 \n    3.26 \n    3.25 \n    3.24 \n    3.23 \n    3.22 \n    3.22 \n    3.21 \n    3.21 \n    3.20 \n    3.20 \n  \n  \n    6 \n    3.78 \n    3.46 \n    3.29 \n    3.18 \n    3.11 \n    3.05 \n    3.01 \n    2.98 \n    2.96 \n    2.94 \n    2.92 \n    2.90 \n    2.89 \n    2.88 \n    2.87 \n    2.86 \n    2.85 \n    2.85 \n    2.84 \n    2.84 \n    2.83 \n    2.83 \n  \n  \n    7 \n    3.59 \n    3.26 \n    3.07 \n    2.96 \n    2.88 \n    2.83 \n    2.78 \n    2.75 \n    2.72 \n    2.70 \n    2.68 \n    2.67 \n    2.65 \n    2.64 \n    2.63 \n    2.62 \n    2.61 \n    2.61 \n    2.60 \n    2.59 \n    2.59 \n    2.58 \n  \n  \n    8 \n    3.46 \n    3.11 \n    2.92 \n    2.81 \n    2.73 \n    2.67 \n    2.62 \n    2.59 \n    2.56 \n    2.54 \n    2.52 \n    2.50 \n    2.49 \n    2.48 \n    2.46 \n    2.45 \n    2.45 \n    2.44 \n    2.43 \n    2.42 \n    2.42 \n    2.41 \n  \n  \n    9 \n    3.36 \n    3.01 \n    2.81 \n    2.69 \n    2.61 \n    2.55 \n    2.51 \n    2.47 \n    2.44 \n    2.42 \n    2.40 \n    2.38 \n    2.36 \n    2.35 \n    2.34 \n    2.33 \n    2.32 \n    2.31 \n    2.30 \n    2.30 \n    2.29 \n    2.29 \n  \n  \n    10 \n    3.29 \n    2.92 \n    2.73 \n    2.61 \n    2.52 \n    2.46 \n    2.41 \n    2.38 \n    2.35 \n    2.32 \n    2.30 \n    2.28 \n    2.27 \n    2.26 \n    2.24 \n    2.23 \n    2.22 \n    2.22 \n    2.21 \n    2.20 \n    2.19 \n    2.19 \n  \n  \n    11 \n    3.23 \n    2.86 \n    2.66 \n    2.54 \n    2.45 \n    2.39 \n    2.34 \n    2.30 \n    2.27 \n    2.25 \n    2.23 \n    2.21 \n    2.19 \n    2.18 \n    2.17 \n    2.16 \n    2.15 \n    2.14 \n    2.13 \n    2.12 \n    2.12 \n    2.11 \n  \n  \n    12 \n    3.18 \n    2.81 \n    2.61 \n    2.48 \n    2.39 \n    2.33 \n    2.28 \n    2.24 \n    2.21 \n    2.19 \n    2.17 \n    2.15 \n    2.13 \n    2.12 \n    2.10 \n    2.09 \n    2.08 \n    2.08 \n    2.07 \n    2.06 \n    2.05 \n    2.05 \n  \n  \n    13 \n    3.14 \n    2.76 \n    2.56 \n    2.43 \n    2.35 \n    2.28 \n    2.23 \n    2.20 \n    2.16 \n    2.14 \n    2.12 \n    2.10 \n    2.08 \n    2.07 \n    2.05 \n    2.04 \n    2.03 \n    2.02 \n    2.01 \n    2.01 \n    2.00 \n    1.99 \n  \n  \n    14 \n    3.10 \n    2.73 \n    2.52 \n    2.39 \n    2.31 \n    2.24 \n    2.19 \n    2.15 \n    2.12 \n    2.10 \n    2.07 \n    2.05 \n    2.04 \n    2.02 \n    2.01 \n    2.00 \n    1.99 \n    1.98 \n    1.97 \n    1.96 \n    1.96 \n    1.95 \n  \n  \n    15 \n    3.07 \n    2.70 \n    2.49 \n    2.36 \n    2.27 \n    2.21 \n    2.16 \n    2.12 \n    2.09 \n    2.06 \n    2.04 \n    2.02 \n    2.00 \n    1.99 \n    1.97 \n    1.96 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.92 \n    1.91 \n  \n  \n    16 \n    3.05 \n    2.67 \n    2.46 \n    2.33 \n    2.24 \n    2.18 \n    2.13 \n    2.09 \n    2.06 \n    2.03 \n    2.01 \n    1.99 \n    1.97 \n    1.95 \n    1.94 \n    1.93 \n    1.92 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.88 \n  \n  \n    17 \n    3.03 \n    2.64 \n    2.44 \n    2.31 \n    2.22 \n    2.15 \n    2.10 \n    2.06 \n    2.03 \n    2.00 \n    1.98 \n    1.96 \n    1.94 \n    1.93 \n    1.91 \n    1.90 \n    1.89 \n    1.88 \n    1.87 \n    1.86 \n    1.86 \n    1.85 \n  \n  \n    18 \n    3.01 \n    2.62 \n    2.42 \n    2.29 \n    2.20 \n    2.13 \n    2.08 \n    2.04 \n    2.00 \n    1.98 \n    1.95 \n    1.93 \n    1.92 \n    1.90 \n    1.89 \n    1.87 \n    1.86 \n    1.85 \n    1.84 \n    1.84 \n    1.83 \n    1.82 \n  \n  \n    19 \n    2.99 \n    2.61 \n    2.40 \n    2.27 \n    2.18 \n    2.11 \n    2.06 \n    2.02 \n    1.98 \n    1.96 \n    1.93 \n    1.91 \n    1.89 \n    1.88 \n    1.86 \n    1.85 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.81 \n    1.80 \n  \n  \n    20 \n    2.97 \n    2.59 \n    2.38 \n    2.25 \n    2.16 \n    2.09 \n    2.04 \n    2.00 \n    1.96 \n    1.94 \n    1.91 \n    1.89 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.82 \n    1.81 \n    1.80 \n    1.79 \n    1.79 \n    1.78 \n  \n  \n    21 \n    2.96 \n    2.57 \n    2.36 \n    2.23 \n    2.14 \n    2.08 \n    2.02 \n    1.98 \n    1.95 \n    1.92 \n    1.90 \n    1.87 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.78 \n    1.77 \n    1.76 \n  \n  \n    22 \n    2.95 \n    2.56 \n    2.35 \n    2.22 \n    2.13 \n    2.06 \n    2.01 \n    1.97 \n    1.93 \n    1.90 \n    1.88 \n    1.86 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.79 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n  \n  \n    23 \n    2.94 \n    2.55 \n    2.34 \n    2.21 \n    2.11 \n    2.05 \n    1.99 \n    1.95 \n    1.92 \n    1.89 \n    1.87 \n    1.84 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.74 \n    1.73 \n  \n  \n    24 \n    2.93 \n    2.54 \n    2.33 \n    2.19 \n    2.10 \n    2.04 \n    1.98 \n    1.94 \n    1.91 \n    1.88 \n    1.85 \n    1.83 \n    1.81 \n    1.80 \n    1.78 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n  \n  \n    25 \n    2.92 \n    2.53 \n    2.32 \n    2.18 \n    2.09 \n    2.02 \n    1.97 \n    1.93 \n    1.89 \n    1.87 \n    1.84 \n    1.82 \n    1.80 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.74 \n    1.73 \n    1.72 \n    1.71 \n    1.70 \n  \n  \n    26 \n    2.91 \n    2.52 \n    2.31 \n    2.17 \n    2.08 \n    2.01 \n    1.96 \n    1.92 \n    1.88 \n    1.86 \n    1.83 \n    1.81 \n    1.79 \n    1.77 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.71 \n    1.70 \n    1.69 \n  \n  \n    27 \n    2.90 \n    2.51 \n    2.30 \n    2.17 \n    2.07 \n    2.00 \n    1.95 \n    1.91 \n    1.87 \n    1.85 \n    1.82 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.70 \n    1.69 \n    1.68 \n  \n  \n    28 \n    2.89 \n    2.50 \n    2.29 \n    2.16 \n    2.06 \n    2.00 \n    1.94 \n    1.90 \n    1.87 \n    1.84 \n    1.81 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.73 \n    1.71 \n    1.70 \n    1.69 \n    1.69 \n    1.68 \n    1.67 \n  \n  \n    29 \n    2.89 \n    2.50 \n    2.28 \n    2.15 \n    2.06 \n    1.99 \n    1.93 \n    1.89 \n    1.86 \n    1.83 \n    1.80 \n    1.78 \n    1.76 \n    1.75 \n    1.73 \n    1.72 \n    1.71 \n    1.69 \n    1.68 \n    1.68 \n    1.67 \n    1.66 \n  \n  \n    30 \n    2.88 \n    2.49 \n    2.28 \n    2.14 \n    2.05 \n    1.98 \n    1.93 \n    1.88 \n    1.85 \n    1.82 \n    1.79 \n    1.77 \n    1.75 \n    1.74 \n    1.72 \n    1.71 \n    1.70 \n    1.69 \n    1.68 \n    1.67 \n    1.66 \n    1.65 \n  \n  \n    35 \n    2.85 \n    2.46 \n    2.25 \n    2.11 \n    2.02 \n    1.95 \n    1.90 \n    1.85 \n    1.82 \n    1.79 \n    1.76 \n    1.74 \n    1.72 \n    1.70 \n    1.69 \n    1.67 \n    1.66 \n    1.65 \n    1.64 \n    1.63 \n    1.62 \n    1.62 \n  \n  \n    40 \n    2.84 \n    2.44 \n    2.23 \n    2.09 \n    2.00 \n    1.93 \n    1.87 \n    1.83 \n    1.79 \n    1.76 \n    1.74 \n    1.71 \n    1.70 \n    1.68 \n    1.66 \n    1.65 \n    1.64 \n    1.62 \n    1.61 \n    1.61 \n    1.60 \n    1.59 \n  \n  \n    45 \n    2.82 \n    2.42 \n    2.21 \n    2.07 \n    1.98 \n    1.91 \n    1.85 \n    1.81 \n    1.77 \n    1.74 \n    1.72 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.58 \n    1.57 \n  \n  \n    50 \n    2.81 \n    2.41 \n    2.20 \n    2.06 \n    1.97 \n    1.90 \n    1.84 \n    1.80 \n    1.76 \n    1.73 \n    1.70 \n    1.68 \n    1.66 \n    1.64 \n    1.63 \n    1.61 \n    1.60 \n    1.59 \n    1.58 \n    1.57 \n    1.56 \n    1.55 \n  \n  \n    60 \n    2.79 \n    2.39 \n    2.18 \n    2.04 \n    1.95 \n    1.87 \n    1.82 \n    1.77 \n    1.74 \n    1.71 \n    1.68 \n    1.66 \n    1.64 \n    1.62 \n    1.60 \n    1.59 \n    1.58 \n    1.56 \n    1.55 \n    1.54 \n    1.53 \n    1.53 \n  \n  \n    75 \n    2.77 \n    2.37 \n    2.16 \n    2.02 \n    1.93 \n    1.85 \n    1.80 \n    1.75 \n    1.72 \n    1.69 \n    1.66 \n    1.63 \n    1.61 \n    1.60 \n    1.58 \n    1.57 \n    1.55 \n    1.54 \n    1.53 \n    1.52 \n    1.51 \n    1.50 \n  \n  \n    100 \n    2.76 \n    2.36 \n    2.14 \n    2.00 \n    1.91 \n    1.83 \n    1.78 \n    1.73 \n    1.69 \n    1.66 \n    1.64 \n    1.61 \n    1.59 \n    1.57 \n    1.56 \n    1.54 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.48 \n  \n  \n    120 \n    2.75 \n    2.35 \n    2.13 \n    1.99 \n    1.90 \n    1.82 \n    1.77 \n    1.72 \n    1.68 \n    1.65 \n    1.63 \n    1.60 \n    1.58 \n    1.56 \n    1.55 \n    1.53 \n    1.52 \n    1.50 \n    1.49 \n    1.48 \n    1.47 \n    1.46 \n  \n  \n    140 \n    2.74 \n    2.34 \n    2.12 \n    1.99 \n    1.89 \n    1.82 \n    1.76 \n    1.71 \n    1.68 \n    1.64 \n    1.62 \n    1.59 \n    1.57 \n    1.55 \n    1.54 \n    1.52 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n  \n  \n    180 \n    2.73 \n    2.33 \n    2.11 \n    1.98 \n    1.88 \n    1.81 \n    1.75 \n    1.70 \n    1.67 \n    1.63 \n    1.61 \n    1.58 \n    1.56 \n    1.54 \n    1.53 \n    1.51 \n    1.50 \n    1.48 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n  \n  \n    250 \n    2.73 \n    2.32 \n    2.11 \n    1.97 \n    1.87 \n    1.80 \n    1.74 \n    1.69 \n    1.66 \n    1.62 \n    1.60 \n    1.57 \n    1.55 \n    1.53 \n    1.51 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n  \n  \n    400 \n    2.72 \n    2.32 \n    2.10 \n    1.96 \n    1.86 \n    1.79 \n    1.73 \n    1.69 \n    1.65 \n    1.61 \n    1.59 \n    1.56 \n    1.54 \n    1.52 \n    1.50 \n    1.49 \n    1.47 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n  \n  \n    1000 \n    2.71 \n    2.31 \n    2.09 \n    1.95 \n    1.85 \n    1.78 \n    1.72 \n    1.68 \n    1.64 \n    1.61 \n    1.58 \n    1.55 \n    1.53 \n    1.51 \n    1.49 \n    1.48 \n    1.46 \n    1.45 \n    1.44 \n    1.43 \n    1.42 \n    1.41"
  },
  {
    "objectID": "observable/storatalenslag_bernoulli.html",
    "href": "observable/storatalenslag_bernoulli.html",
    "title": "Stora talens lag - slantsingling",
    "section": "",
    "text": "Den interaktiva grafen visar hur Stora talens lag: dvs hur t ex andelen Krona vid ett stort antal slantsinglingar tenderar att närma sig p = P(Krona) när antalet slantsinglingar (n) ökar."
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html",
    "href": "datorlab/lab5/DatorLab5.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "I den här datorlabben kommer vi att arbeta med fördelningar i R, bland annat lära oss göra sannolikhetsberäkningar och simulera från olika fördelningar, dvs dra slumptal från fördelningar.\n\n\n\n\n\n\n\nInstallera paket\n\n\n\nDen här labben förutsätter inga installerade paket.\n\n\n\n\n\n\n\n\nSkapa mapp för labben\n\n\n\nSkapa en mapp Lab5 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din Lab5 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar.\n\n\n\n\nR har en massa statistiska fördelningar inbyggda från start, och ytterligare många, många mer i olika R-paket. För varje fördelning finns det fyra typer av funktioner:\n\nr-funktionen som genererar slumptal från fördelningen, t ex rnorm(n = 5, mean = 2, sd = 3) genererar 5 slumptal från normalfördelningen \\(X\\sim N(2,3)\\). Argumentet sd betyder standard deviation, dvs standardavvikelse. Tio slumptal från Poissonfördelningen \\(\\mathrm{Pois}(\\lambda = 2)\\) får man med rpois(n = 10, lambda = 2) osv. r-funktionen har fått sitt namn från random.\np-funktionen som beräknar sannolikheten att slumpvariabeln är mindre än ett visst tal, dvs \\(P(X\\leq x)\\) för något \\(x\\). p-funktionen har fått sitt namn från engelskans probability.\npnorm(q = 1, mean = 2, sd = 3) beräknar sannolikheten att \\(X\\sim N(2,3)\\) är mindre än 1.\nd-funktionen som för en diskret variabel \\(X\\) beräknar sannolikheten \\(P(X=x)\\). För en kontinuerlig variabel beräknar d-funktionen täthetsfunktionen \\(f(x)\\) i en given punkt \\(x\\). Det är från det kontinuerliga fallet som d-funktionen fått sitt namn, d som i density. Kommandot dnorm(x = 0, mean = 2, sd = 3) beräknar täthetsfunktionens värde i punkten \\(x=0\\), dvs \\(f(0)\\) för en \\(X\\sim N(2,3)\\) variabel.\nq-funktionen beräknar \\(p\\)-kvantilen för en fördelning, dvs det värde \\(x\\) där \\(P(X \\leq x)=p\\). Vi kan t ex beräkna 25% eller 0.25-kvantilen för en normalfördelad variabel \\(X\\sim N (2,3)\\) med kommandot qnorm(p = 0.25, mean = 2, sd = 3).\n\n\nVisa mig koden!\nm = 2       # mean for the normal distribution\ns = 3       # standard deviation for the normal distribution\nx = -1      # point where the density is evaluated\nx_grid = seq(-10, 10, by = 0.1) # a vector of x-values for which we evaluate the density f(x)\nx_sample = rnorm(n = 1000, mean = m, sd = s)\ndens_norm = dnorm(x_grid, mean = m, sd = s)  # density (x) for all values in vector xgrid\nquantile10 = qnorm(0.1, mean = m, sd = s)    # 10% percentile\n\n# Plotting - a lot of code because I want pretty colors and legends. Sorry.\nhist(x_sample, breaks = 50, freq = F, main = \"X ~ N(2,3²)\", ylim = c(0,0.15), \n     xlim = c(-10,10), xlab = \"x\", ylab = \"f(x)\", col = \"cornflowerblue\") # freq = F gives us proportions\nlines(x_grid, dens_norm, lwd = 3, col = \"orange\")\ndensity_at_x = dnorm(x, mean = m, sd = s)\npoints(x, density_at_x)\nlines(x = c(x,x), c(0,density_at_x), col = \"gray\", lty = 2, lwd = 3)\nlines(x = c(-10,x), c(density_at_x,density_at_x), col = \"gray\", lty = 2, lwd = 2)\nx_lower = x_grid[x_grid < quantile10]\npolygon(x = c(x_lower, rev(x_lower)), border = NA,\n        y = c(rep(0, length(x_lower)), rev(dnorm(x_lower, mean = m, sd = s))), \n        col = rgb(1,0.8431373,0, alpha = 0.7)\n)\nlegend(\"topleft\", inset=.01, \n       legend=c(\"histogram data\", \"density function\", \"density evaluation\", \"P(X<=-1)\"),\n       col=c(\"cornflowerblue\", \"orange\", \"gray\"), \n       lty = c(NA, 1, 3, NA), \n       lwd = c(NA, 2, 2, NA), \n       fill = c(\"cornflowerblue\", NA, NA, rgb(1,0.8431373,0, alpha = 0.7)), \n       border = c(1,0,0,1), cex=1\n)\n\n\n\n\n\n\n\n\ndnorm to compute density at -1: f(x) = 0.0806569081730478\n\n\npnorm to compute prob that X is lower than -1: P(X<=x) = 0.158655253931457\n\n\nqnorm to compute 10% quantile of X as  -1.8446546966338\n\n\n\n\n\n\n\n\nGlöm inte Rs hjälp!\n\n\n\nSkriv t ex ?rnorm i Console för att se hjälpfilen för normalfördelningen.\n\n\n\n\n\n\n\n\nObservera\n\n\n\nJag har skrivit ut namnen på alla funktionsargumenten ovan, t ex n=5, mean = 2 och sd = 3 i rnorm(n = 5, mean = 2, sd = 3). Det hade dock gått lika bra att skriva rnorm(5, 2, 3), då förstår R att jag menar n=5, mean = 2 och sd = 3 . Det fungerar dock bara om man använder exakt den ordning på argumenten som man ser när man skriver ?rnorm. Annars kan R inte veta vilka argument som ska matchas mot vilka siffror. Om man skriver ut argumentens namn så kan man ha vilken ordning som helst, t ex rnorm(mean = 2, sd = 3, n = 5).\n\n\n\n\n\n\n\n\nVektorisera mera\n\n\n\nKommandot dnorm(0, mean = 0, sd = 1) räknar ut täthetsfunktionens värde i punkten x=0 för en standard normalfördelning. Om man vill räkna ut tätheten i flera punkter? Ett sätt är att använda en for-loop som upprepar dnorm(x, mean = 0, sd = 1) för olika x-värden (se Lab1). Men det finns ett enklare sätt! Många av Rs funktioner är vektoriserade. Det betyder att du kan räkna ut funktionen för alla värden i en vektor ‘på en gång’. 😍\nSå här beräknar man t ex täthetsfunktionen för tre olika x-värden -1, 0, och 1:\n\ndnorm(x = c(-1,0,1), mean = 0, sd = 1)\n\n[1] 0.2419707 0.3989423 0.2419707\n\n\nOk, snyggt, men om man vill ha olika väntevärden för var och ett av x-värdena, då? Yep, funkar:\n\ndnorm(x = c(-1,0,1), mean = c(0, 0.5, 3), sd = 1)\n\n[1] 0.24197072 0.35206533 0.05399097\n\n\n\n\n\n\n\n\n\n\nNormalfördelning med varians eller standardavvikelse?\n\n\n\nI funktionen rnorm() anger man fördelningens spridning som en standardavvikelse med argumentet sd. Det motsvarar att man skriver \\(N(\\mu,\\sigma)\\) för en normalfördelning i matematisk/symbolisk notation. Många böcker skriver dock normalfördelningen med variansen som andra argument i den symboliska beskrivningen: \\(N(\\mu,\\sigma^2)\\). Man får helt enkelt se upp och kontrollera om en normalfördelning skrivs med en standardavvikelse eller varians. I formelsamlingen och på tentan har jag kommer jag skriva \\(N(\\mu,\\sigma)\\), som boken gör.\n\n\n\n\n\nVi ska nu försöka göra ett stapeldiagram för sannolikhetsfördelningen för en binomialfördelad variabel med parametrarna \\(n=10\\) och \\(p=0.4\\), dvs för slumpvariabeln \\(X\\sim \\mathrm{Binom}(n,p)\\). Vi har ju just sett att vi kan beräkna sannolikheterna \\(P(X=x)\\) för en massa olika \\(x\\)-värden genom vektorisering, så låt oss börja där:\n\nn = 10\np = 0.4\nxvalues = seq(0,n) # en vektor med alla möjliga utfall på X, dvs 0,1,2,...,n\nprobs = dbinom(x = xvalues, size = n, prob = p) # vektoriserat \nprobs\n\n [1] 0.0060466176 0.0403107840 0.1209323520 0.2149908480 0.2508226560\n [6] 0.2006581248 0.1114767360 0.0424673280 0.0106168320 0.0015728640\n[11] 0.0001048576\n\n\nNotera hur jag först skapade en vektor med alla x-värden (xvalues) mellan \\(0\\) och \\(n=10\\) (vilket ju är alla möjliga x-värden för en \\(\\mathrm{Bin}(10,p)\\)-fördelad variabel). Den vektorn matade jag sen in i dbinom() funktionen för att få sannolikheten \\(P(X=x)\\) för varje x-värde. Vi ser att sannolikheten för \\(x=0\\) är väldigt låg \\(P(X=0)=0.0060466176\\). Den sannolikheten är lätt att räkna för hand som kontroll: det enda sätt vi kan få 0 lyckade försök i 10 Bernoulliförsök är om vi misslyckas (vars sannolikhet är \\(q=1-p=1-0.4=0.6\\)) på alla 10 försök: \\(0.6^{10}=0.006046618\\). Yes, checks out.\nKoden nedan gör nu ett stapeldiagram över sannolikhetsfördelningen. Notera att vi måste använda names() funktionen för sätta ett “namn” på varje sannolikhet (dvs det x-värde som sannolikheten hör ihop med) för att vi ska få \\(x\\)-värdena utskrivna på \\(x\\)-axeln.\n\nnames(probs) <- xvalues\nbarplot(probs, col = \"cornflowerblue\", ylab = \"P(X=x)\", xlab = \"x\", main = \"X ~ Binom(10,0.4)\")\n\n\n\n\nHur gör man om slumpvariabeln kan anta ett oändligt antal värden, som t ex Poissonfördelningen där \\(x=0,1,2,….\\) utan övre gräns? Lösningen är att låta vektorn med x-värden innehålla alla x-värden där sannolikheten \\(P(X=x)\\) är tillräckligt stor för att spela roll i figuren. Här kan prova sig fram, dvs öka på antalet x-värden tills sannolikheten för större x-värden är nära noll. Så här kan vi t ex göra ett stapeldiagram över sannolikhetsfördelningen för en \\(\\mathrm{Pois}(\\lambda = 2)\\) variabel:\n\nxvalues = 0:5\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"orange\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lite för få x-värden\")\n\n\n\n\nSom du ser var jag lite för snål med antal x-värden, det verkar som om x-värden större än 5 borde ha varit med i plotten eftersom sannolikheten för x=5 är inte riktigt nära noll. Låt oss prova med värden från 0 till 10:\n\nxvalues = 0:10\nprobs = dpois(x = xvalues, lambda = 2)\nnames(probs) <- xvalues\nbarplot(probs, col = \"yellow\", xlab  = \"x\", ylab = \"P(X=x)\", main = \"Poisson med lagom många x-värden\")\n\n\n\n\n\n\n\nHur kan man rita upp sannolikheterna för en kontinuerlig variabel? Kontinuerliga variabler antar ju alla värden, även decimaltal, så här måste vi göra lite annorlunda. En kontinuerlig variabel har ju också sannolikhet noll för alla \\(x\\): \\(P(X=x)=0\\). Vi använder oss därför av täthetsfunktionen \\(f(x)\\), där arean under täthetsfunktionen mellan två x-värden \\(a\\) och \\(b\\) är sannolikheten \\(P(a \\leq X \\leq b)\\). Den s k d-funktionen (t ex dnorm för normalfördelning) ger tätheten för en kontinuerlig variabel. För att plotta upp en täthetsfunktion:\n\nskapa en vektor med en massa x-värden med ganska litet avstånd mellan värdena\nberäkna d-funktionen för vektorn med x-värden\nplotta täthetsfunktionen som en kurva med kommandot plot() eller lines() (används om det inte redan finns något uppritat i grafen).\n\nHär plottar vi täthetsfunktionen för en standard normalfördelningen:\n\nxvalues = seq(-3, 3, by = 0.01) # by=0.01 talar om att vi vill ha avstånd 0.01 mellan värdena.\ndensity_values = dnorm(xvalues, mean = 0, sd = 1)\nplot(xvalues, density_values, type = \"l\", xlab = \"x\", ylab = \"density\", main = \"N(0,1)\",\n     col = \"steelblue\", lwd = 2) # lwd är line width, dvs tjocklek på linje.\n\n\n\n\nI det här fallet var det ganska lätt att välja start- och slutpunkt för x-värdena: vi vet ju från 68-95-99.7 regeln att 99.7% av sannolikhetsmassan ligger mellan -3 och 3 för standard normalfördelning. I andra fall kan det vara svårare att bestämma lämpliga x-värden och man får prova sig fram (om man har en q-funktion, dvs kvantilfunktion, för fördelningen kan man använda den för att beräkna lämpliga start- och slutvärden på x). Hur väljer man avståndet mellan olika x-värden (dvs by = 0.01 i min kod)? Det brukar spela mindre roll. Väljer man för stora avstånd blir kurvan hackig. Väljer man verkligt små avstånd blir det många olika x-värden och det kan ta tid för R beräkna alla täthetsvärden."
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#räkna-med-sannolikhetsfördelningar",
    "href": "datorlab/lab5/DatorLab5.html#räkna-med-sannolikhetsfördelningar",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Räkna med sannolikhetsfördelningar",
    "text": "1. Räkna med sannolikhetsfördelningar\n\n💪 Uppgift 1.1\nLåt \\(X\\sim \\mathrm{Pois}(\\lambda)\\) med \\(\\lambda = 2\\). Beräkna \\(P(X=2)\\) och \\(P(X\\leq 3)\\). Hint: ?ppois\n\n# Write your code here\n\n\n\n💪 Uppgift 1.2\nI valet 2022 fick Liberalerna 4.61% av rösterna. I en undersökning bland totalt 1046 personser angav 30 personer att de skulle rösta på Liberalerna om det var val idag. Kan det vara så att Liberalernas röstningsandel är (ungefär) oförändrad på 4.61%, eller tyder den nya undersökningen på något annat? Undersök detta genom att rita upp ett stapeldiagram över sannolikhetsfördelningen \\(P(X=x)\\) för \\(X \\sim \\mathrm{Binom}\\operatorname{}(n= 1046, p = 0.0461)\\) för x-värdena xvalues = 0:100. Är resultatet från valundersökningen ett sannolikt utfall? Om inte, vilket slutsats drar du, genom att titta i stapeldiagramet, om Liberalernas faktiska väljarandel?\n\n# Write your code here\n\n\n\n💪 Uppgift 1.3\nBeräkna \\(P(X \\leq 30)\\) för \\(X \\sim \\mathrm{Binom}(n= 1046, p = 0.0461)\\) genom att använda binomialfördelningen. Jämför svaret med samma sannolikhet från en normalapproximation (se F15):\n\\[\nX\\sim \\mathrm{Binom}(n,p) \\text{ approximeras med } X\\sim \\mathrm{N}\\Big(\\mu=np, \\sigma = \\sqrt{n p (1-p)}\\Big)\n\\]\nObservera att jag skrivit normalfördelningen med standardavvikelse som andra argument här. Precis som R gör.\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#simulera-slumpvariabler",
    "href": "datorlab/lab5/DatorLab5.html#simulera-slumpvariabler",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Simulera slumpvariabler",
    "text": "2. Simulera slumpvariabler\n\n💪 Uppgift 2.1\nSimulera nu 1000 slumptal från Poissonfördelningen \\(\\mathrm{Pois}(\\lambda)\\) med \\(\\lambda = 2\\) och spara i variabeln (vektorn) x. Beräkna medelvärdet (mean(x)) och standardavvikelsen (sd(x)) för slumptalen. Stämmer de värdena ungefär med vad vi kan förvänta oss? [hint: Poissonfördelningens teoretiska väntevärde]. Simulera nu 10000 slumptal från samma fördelning och beräkna återigen medelvärdet. Vad tror du skulle hända om du fortsatte så här och simulerade fler och fler slumptal? (bortsett från att datorns minne skulle ta slut). [Hint: stora talens lag].\n\n# Write your code here\n\n\n\n💪 Uppgift 2.2\nAntag att du inte känner till funktionen dpois och att det matematiska uttrycket för Poissonsannolikheterna som ges i SDM boken är för skrämmande för dig. Kan du använda slumptalen i Uppgift 2.1 för att uppskatta sannolikheten \\(P(X=3)\\)?\n\n# Write your code here\n\n\n\n💪 Uppgift 2.3\nSimulera 1000 slumptal från exponentialfördelningen med parametern rate = 2 (vilket är det som boken kallar \\(\\lambda\\)) och spara i en vektor x. Beräkna medelvärdet av slumptalen och verifiera att det är hyfsat nära det teoretiska väntevärdet för denna exponentialfördelning.\n\n# Write your code here\n\n\n\n💪 Uppgift 2.4\nRita ett histogram för slumptalen från förra uppgiften med argumentet breaks = 40 (gör att du får ungefär 40 staplar i histogrammet). Plotta också den teoretiska täthetsfunktionen för \\(\\mathrm{Expon}(\\lambda = 2)\\) i samma figur.\n\n\n\n\n\n\nPlottips\n\n\n\nAnvänd lines() när du plottar täthetsfunktionen, annars kommer histogrammet att skrivas över. Använd argumentet freq = FALSE i hist()-funktionen så du får andelen observationer i varje bin, och inte antalet. Annars kommer histogrammet och täthetsfunktionen inte att ha samma skala på y-axeln.\n\n\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#simulering-för-att-beräkna-nya-fördelningar",
    "href": "datorlab/lab5/DatorLab5.html#simulering-för-att-beräkna-nya-fördelningar",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Simulering för att beräkna nya fördelningar",
    "text": "3. Simulering för att beräkna nya fördelningar\nEn mycket trevlig egenskap med simulering är att det är väldigt enkelt att beräkna fördelningen för en funktion av slumpvariabler. Vi vet ju t ex att om \\(X\\sim \\operatorname{N}(\\mu,\\sigma^2)\\) så är fördelningen för linjärkombinationen \\(Y=c+aX\\) också normalfördelad: \\(Y\\sim \\operatorname{N}(c+a\\mu, a^2 \\sigma ^2)\\). Men det är långt ifrån alla fall där vi matematiskt kan bevisa sådana goa resultat. Med simulering kan vi få fram fördelningen för alla funktioner och även fördelningen för en summa av slumpvariabler, och mer. Den kan vi även göra om fördelningen för \\(X\\) är något annat än normalfördelad. Låt oss testa direkt i en övning!\n\n💪 Uppgift 3.1\nDin vän och du ska beställa hem mat. Ni har olika smak och du vill beställa från restaurang X, din vän vill beställa från restaurang Y. Ni vill såklart gärna äta maten samtidigt och lovar varandra att vänta med att äta tills båda fått maten. Låt \\(X \\sim \\mathrm{Expon}(\\lambda = 2)\\) vara väntetiden i timmar tills restaurang X levererar mat hem till dig, och \\(Y \\sim \\mathrm{Expon}(\\lambda = 4)\\) är väntetiden för restaurang Y. Antag att \\(X\\) och \\(Y\\) är oberoende slumpvariabler. Slumpvariabeln \\(Z=60(X-Y)\\) mäter då hur många minuter du måste vänta på maten efter att din vän redan fått maten, dvs hur länge din artiga vän måste vänta innan hen kan börja äta. Om \\(Z\\) är negativ har du alltså fått maten före din vän. Här ser man direkt att \\(Z=60(X-Y)\\) inte kan vara exponentialfördelad, \\(Z\\) kan ju vara negativ! Använd simulering för att simulera från fördelningen för \\(Z\\) och rita upp ett histogram för att representera täthetsfunktionen (använd argumentet freq = FALSE för att få andelar inom varje bin). Använd simuleringen för att uppskatta sannolikheten att du får maten efter din vän. [Hint1: Prova att skriva Z>0 i Console. Hint2: R hanterar TRUE som 1 och FALSE som 0, så t ex sum(c(TRUE, FALSE, TRUE)) blir 2 i R].\n\n# Write your code here\n\n\n\n💪 Uppgift 3.2\nUppskatta variansen för \\(Z\\) genom simulering. Verifiera att uppskattningen är hyfsat nära den teoretiska variansen för för \\(Z\\). [Hint: F14 gav oss formler för variansen av en summa och en differens av oberoende variabler och F16 har egenskaper för exponentialfördelade variabler, t ex deras varians.]\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab5/DatorLab5.html#analys-av-antalet-besök-till-webbsida",
    "href": "datorlab/lab5/DatorLab5.html#analys-av-antalet-besök-till-webbsida",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "4. Analys av antalet besök till webbsida",
    "text": "4. Analys av antalet besök till webbsida\nEn webbsida registrerade när besökare besökte deras webbsida under ett dygn. Här är en grafisk illustration av antalet besök under dygnet, varje streck är ett besök vid en viss tidpunkt:\n\n\n\n\n\nAntalet besök för var och ett av dygnets timmar var\n\nvisits_per_hour = c(0, 1,  6,  0,  1,  0,  1,  0,  3,  0,  0,  0,  0,  2,  2, \n                    0,  1,  9,  1,  1,  0,  1,  0,  0)\n\nAntag att antalet besök per timme kan modelleras som oberoende Poissonfördelade variabler med parameter \\(\\lambda\\). Vi vill nu bestämma det bästa värdet på \\(\\lambda\\) genom att använda data. En vanlig skattning av \\(\\lambda\\) i en Poissonfördelning är medelvärdet \\(\\bar x\\) av data (det är t ex den skattning man får med den s k maximum likelihoodmetoden).\n\n💪 Uppgift 4.1\nSkatta parametern \\(\\lambda\\) från variabeln visits_per_hour .\n\n# Write your code here\n\n\n\n💪 Uppgift 4.2\nFöretaget som driver webbsidan vill veta sannolikheten att de får fler än 5 besökare under åtminstone någon av morgondagens 24 timmar. Använd din skattade Poissonmodell för att beräkna den sannolikheten. [hint: union och komplement].\n\n# Write your code here\n\n\n\n💪 Uppgift 4.2\n\nUndersök om Poissonfördelningen verkar anpassa dessa data bra. Du kan t ex undersöka om det teoretiska väntevärdet och variansen i den skattade Poissonmodellen ligger hyfsat nära medelvärdet och stickprovsvariansen i data. Du kan också kolla hur sannolikt det faktiskt är att observera 9 st besök under en timme (som vi ju ser i data mellan kl 17-18) i den skattade Poissonmodellen.\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html",
    "href": "datorlab/lab6/DatorLab6.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "I den här datorlabben kommer vi att arbeta med konfidensintervall och hypotestest\n\n\n\n\n\n\n\nInstallera paket\n\n\n\nDen här labben förutsätter inga installerade paket.\n\n\n\n\n\n\n\n\nSkapa mapp för labben\n\n\n\nSkapa en mapp Lab6 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din Lab6 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar.\n\n\n\n\nI den här uppgiften kommer ni behöva upprepa beräkningar ett stort antal gånger. Då använder vi loopar, framförallt den s k for-loopen. Här är en enkel loop som beräknar kvadraten av alla tal mellan 1 och 10 och sparar resultaten i en vektor kvadrater:\n\nkvadrater = rep(0, 10) # Skapar vektor med nollor där vi sen sparar varje kvadrat\nfor (i in 1:10){\n  kvadrater[i] = i^2\n}\nkvadrater\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nVi kan göra precis samma loop på lite annorlunda sätt:\n\nkvadrater = rep(0, 10) \nmin_loop_vektor = 1:10\nfor (i in min_loop_vektor){\n  kvadrater[i] = i^2\n}\n\nNotera att R alltså kan loop:a över vilken vektor som helst. R läser for-loopen ovan som ’upprepa kommandot print(i^2) för alla värden på i tagna från vektorn min_loop_vektor och spara resultatet i den i:te positionen i vektorn kvadrater.\nGenom att använda seq() funktionen kan vi t ex loop:a över värdena 0.1, 0.2,…, 0.9, 1 så här:\n\nmin_loop_vektor = seq(0.1, 1, by = 0.1)\nfor (i in min_loop_vektor){\n  print(i^2)\n}\n\n[1] 0.01\n[1] 0.04\n[1] 0.09\n[1] 0.16\n[1] 0.25\n[1] 0.36\n[1] 0.49\n[1] 0.64\n[1] 0.81\n[1] 1\n\n\nMen hur gör vi om vi vill spara dessa kvadrater i en vektor kvadrater som vi gjorde ovan? Vi kan inte längre använda loop-variabeln i för tala om för R att placera kvadraten i^2 på den i:te positionen i kvadraten. Variabeln i räknar ju inte längre från 1 till 10! Den räknar ju 0.1, 0.2,…, 0.9, 1.\nLösningen är att skapa ytterligare en variabel som håller reda på var i vektorn kvadrater som resultat ska sparas. Jag kallar den variabel count, men den kan heta vad som helst.\n\nkvadrater = rep(0, 10)\nmin_loop_vektor = seq(0, 1, by = 0.1)\ncount = 0\nfor (i in min_loop_vektor){\n  count = count + 1\n  kvadrater[count] = i^2\n}\nkvadrater\n\n [1] 0.00 0.01 0.04 0.09 0.16 0.25 0.36 0.49 0.64 0.81 1.00\n\n\nNotera hur jag först satte count till 0 innan loopen och hur jag sen inne i loopen ökade count med ett i varje upprepning.\nOk, nu testar vi den här kunskapen på ett lite, lite mer avancerat problem. Säg att vi vill simulera från samplingfördelningen för stickprovsandelen \\(\\hat p\\) med data från modellen\n\\[\nX_1,X_2,\\ldots,X_n \\overset{iid}{\\sim}\\mathrm{Bernoulli}(p)\n\\]\ndär p=0.3 och stickprovsstorleken n=100. Vi gör detta genom att simulera 1000 olika stickprov från modellen. För varje stickprov med n=100 observationer beräknar vi andelen \\(\\hat p\\) och sparar denna andel i en lång vektor. Sen plottar vi fördelningen av dessa 1000 st värden på \\(\\hat p\\) med ett histogram. Here we go!\n\np = 0.3              # andelen i populationen/modellen\nnsim = 1000          # vi vill simulera 1000 olika stickprov\nn = 100              # varje stickprov består av 100 observationer.\nphats = rep(0, nsim) # skapar vektor där andelen (phat) i varje stickprov sparas.\ncount = 0            \nfor (i in 1:nsim){\n  count = count + 1\n  x = rbinom(n, size = 1, prob = p) # size = 1 gör att binomialfördelningen blir en Bernoulli.\n  phats[count] = mean(x)            # mean(x) ger oss andelen phat.\n}\nhist(phats, 50)\n\n\n\n\nSom en sista övning med loopar, låt oss beräkna sannolikheten \\(P(X\\leq 0.5)\\) för en Bernoulli-variabel med sannolikheten \\(p\\) där vi varierar \\(p\\) mellan 0 och 1 i steg av 0.01:\n\nps = seq(0, 1, by = 0.01)\nprobability = rep(0, length(ps)) # funktionen length() räknar antalet element in en vektor\ncount = 0            \nfor (p in ps){   # man får använda annat namn än i som loop-variabel\n  count = count + 1\n  probability[count] = pbinom(0.5, size = 1, prob = p)  # p ändras i varje upprepning\n}\nplot(ps, probability, type = \"l\", xlab = \"p\", ylab = \"P(X<=0.5)\")"
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#introduktion",
    "href": "datorlab/lab6/DatorLab6.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den här datorlabben kommer vi att arbeta med fördelningar i R, bland annat lära oss simulera från olika fördelningar, dvs dra slumptal från fördelningar.\n\n\n💪 Uppgift 0.1\nSe till att paketen ovan är installerade i RStudio innan du fortsätter med resten.\n\n\n💪 Uppgift 0.2\nSkapa en mapp Lab5 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din nya Lab5 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar."
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test",
    "href": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Konfidensintervall och test",
    "text": "Konfidensintervall och test\n\n💪 Uppgift 1.1\nI Övning 20.65 i SDA-boken analyseras data för mängden socker i frukostflingor (gram per 100 gram flingor) för flingor som riktar sig till barn (child_sugar) och vuxna (adult_sugar).\n\nchild_sugar = c(40.3,55.0,45.7,43.3,50.3,45.9,53.5,43,44.2,44,47.4,44,33.6,55.1,48.8,50.4,37.8,60.3,46.6) \n\nadult_sugar = c(20,30.2, 2.2, 7.5, 4.4, 22.2, 16.6, 14.5, 21.4, 3.3, 6.6, 7.8, 10.6, 16.2, 14.5, 4.1, 15.8, 4.1, 2.4, 3.5, 8.5, 10, 1.0, 4.4, 1.3, 8.1, 4.7, 18.4)\n\nLåt oss först analysera child_sugar med modellen\n\\[X_1,X_2,\\ldots,X_n \\overset{iid}{\\sim}N(\\mu,\\sigma)\\]\nAnvänd R för att beräkna ett 95%-igt konfidensintervall för \\(\\mu\\), både genom att använda formeln\n\\[\\bar x \\pm t_{\\alpha/2,n-1}\\frac{s}{\\sqrt n}\\]\noch genom att använda funktionen t.test.\n\n\n💪 Uppgift 1.2\nAnvänd funktionen t.test för att utföra testet:\n\\[\n\\begin{align}\n&H_0: \\mu = 50 \\\\\n&H_1:\\mu\\neq50\n\\end{align}\n\\]\ngenom att beräkna p-värdet för testet och förkasta \\(H_0\\) om p-värdet är mindre än \\(\\alpha =0.05\\). Dvs testa på 5% signifikansnivå. Tolka resultatet från testet.\n\n\n💪 Uppgift 1.3\nUpprepa testet i uppgiften ovan för olika värden på nollhypotesens värde, \\(\\mu_0\\). Prova alla värden på nollhypotesen \\(\\mu_0\\) i vektorn seq(40, 50, by = 0.1), dvs utför testet i uppgiften ovan med \\(\\mu_0 = 40\\), sen med \\(\\mu_0=40.1\\) osv ända till \\(\\mu_0=50\\). Registera om du förkastar \\(H_0\\) eller inte för varje värde på \\(\\mu_0\\). För vilka värden på \\(\\mu_0\\) förkastar du \\(H_0\\)? Jämför med konfidensintervallet i Uppgift 1.1.\n\n\n\n\n\n\nTips\n\n\n\nAnvänd en for-loop för att loop:a över alla värden på \\(\\mu_0\\). Använd min kod ovan som beräkna sannolikheten \\(P(X\\leq 0.5)\\) för en Bernoulli-variabel med sannolikheten \\(p\\) som en mall för denna loop.\nResultatet från t.test är en lista. Så använd $-tecknet för att plocka ut *p*-värdet från resultat-listan från testet (t ex resultat$p.value) om du sparat resultatet från t.test i resultat).\n\n\n\n\n💪 Uppgift 1.4\nDu är egentligen intresserad av att bevisa att den genomsnittliga sockermängden i barnflingor är mer än 50 gram. Dvs, du vill testa den enkelsidiga hypotesen:\n\\[\n\\begin{align}\n&H_0: \\mu \\leq 50 \\\\\n&H_1: \\mu > 50\n\\end{align}\n\\]\nanvänd funktionen t.test för att testa detta. Tips: läs i hjälpen ?t.test"
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#stora-talens-lag",
    "href": "datorlab/lab6/DatorLab6.html#stora-talens-lag",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Stora talens lag",
    "text": "3. Stora talens lag\n\n💪 Uppgift 3.1\n\n\n\n\np = 0.3              # andelen i populationen/modellen\nnsim = 1000          # vi vill simulera 1000 olika stickprov\nn = 10               # varje stickprov består av 10 observationer.\nphats = rep(0, nsim) # skapar vektor där andelen (phat) i varje stickprov sparas.\ncount = 0            \nfor (i in 1:nsim){\n  count = count + 1\n  x = runif(n) \n  phats[count] = mean(x)            # mean(x) ger oss andelen phat.\n}\nhist(phats, 50)"
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#centrala-gränsvärdessatsen",
    "href": "datorlab/lab6/DatorLab6.html#centrala-gränsvärdessatsen",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Centrala gränsvärdessatsen",
    "text": "3. Centrala gränsvärdessatsen\nAntag att data kommer från en likforming (Uniform) fördelning mellan 0 och 1, dvs \\(a=0\\) och \\(b=1\\) i den likformiga fördelningen. Alltså: \\(X_1,X_2,\\ldots,X_n\\overset{iid}{\\sim}\\mathrm{Uniform}(0,1).\\)\n\n💪 Uppgift 3.1\nSimulera 10000 stickprov med vardera \\(n=2\\) observationer och beräkna medelvärdet i varje stickprov. Rita ett histogram över dessa 10000 medelvärden.\n\n\n💪 Uppgift 3.2\nUpprepa Uppgift 3.1 för \\(n=5\\), \\(n=10\\) och \\(n=30\\) observationer i varje stickprov. Kommentera resultatet.\n\n\n💪 Uppgift 3.3\nUpprepa Uppgift 3.2, men istället för att beräkna medelvärdet i varje stickprov så ska du beräkna statistikan\n\\[\nx_{\\mathrm{max}}=\\max(x_1,x_2,\\ldots,x_n)\n\\]\ndvs det högsta värdet i varje stickprov. Varför verkar centrala gränsvärdessatsen inte fungera här?"
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test-för-ett-väntevärde",
    "href": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test-för-ett-väntevärde",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Konfidensintervall och test för ett väntevärde",
    "text": "2. Konfidensintervall och test för ett väntevärde\nI Övning 20.65 i SDA-boken analyseras data för mängden socker i frukostflingor (gram per 100 gram flingor) för flingor som riktar sig till barn (child_sugar):\n\nchild_sugar = c(40.3,55.0,45.7,43.3,50.3,45.9,53.5,43,44.2,44,47.4,44,33.6,55.1,48.8,50.4,37.8,60.3,46.6)\n\nLåt oss analysera child_sugar med modellen\n\\[X_1,X_2,\\ldots,X_n \\overset{iid}{\\sim}N(\\mu,\\sigma)\\]\n\n💪 Uppgift 2.1\nAnvänd R för att beräkna ett 95%-igt konfidensintervall för \\(\\mu\\), både genom att använda formeln\n\\[\\bar x \\pm t_{\\alpha/2,n-1}\\frac{s}{\\sqrt n}\\]\noch genom att använda funktionen t.test.\n\n\n💪 Uppgift 2.2\nAnvänd funktionen t.test för att utföra testet:\n\\[\n\\begin{align}\n&H_0: \\mu = 50 \\\\\n&H_1:\\mu\\neq50\n\\end{align}\n\\]\ngenom att beräkna p-värdet för testet och förkasta \\(H_0\\) om p-värdet är mindre än \\(\\alpha =0.05\\). Dvs testa på 5% signifikansnivå. Tolka resultatet från testet.\n\n\n💪 Uppgift 2.3\nUpprepa testet i uppgiften ovan för olika värden på nollhypotesens värde, \\(\\mu_0\\). Prova alla värden på nollhypotesen \\(\\mu_0\\) i vektorn seq(40, 50, by = 0.1), dvs utför testet i uppgiften ovan med \\(\\mu_0 = 40\\), sen med \\(\\mu_0=40.1\\) osv ända till \\(\\mu_0=50\\). Registera om du förkastar \\(H_0\\) eller inte för varje värde på \\(\\mu_0\\). För vilka värden på \\(\\mu_0\\) förkastar du \\(H_0\\)? Jämför med konfidensintervallet i Uppgift 2.1.\n\n\n\n\n\n\nTips\n\n\n\nAnvänd en for-loop för att loop:a över alla värden på \\(\\mu_0\\). Använd min kod ovan som beräkna sannolikheten \\(P(X\\leq 0.5)\\) för en Bernoulli-variabel med sannolikheten \\(p\\) som en mall för denna loop.\nResultatet från t.test är en lista. Så använd $-tecknet för att plocka ut p-värdet från resultat-listan från testet (t ex resultat$p.value) om du sparat resultatet från t.test i variabeln resultat).\n\n\n\n\n💪 Uppgift 2.4\nDu är egentligen intresserad av att bevisa att den genomsnittliga sockermängden i barnflingor är mer än 40 gram. Dvs, du vill testa den enkelsidiga hypotesen på signifikansnivån \\(\\alpha =0.05\\):\n\\[\n\\begin{align}\n&H_0: \\mu \\leq 40 \\\\\n&H_1: \\mu > 40\n\\end{align}\n\\]\nanvänd funktionen t.test för att testa detta. Tips: läs i hjälpen ?t.test."
  },
  {
    "objectID": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test-för-en-andel",
    "href": "datorlab/lab6/DatorLab6.html#konfidensintervall-och-test-för-en-andel",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Konfidensintervall och test för en andel",
    "text": "1. Konfidensintervall och test för en andel\n\n💪 Uppgift 1.1\nPå föreläsningen om konfidensintervall för en andel såg vi att andelen S-väljare p skattades till 0.371 i SVT/Novus undersökning i Februari 2023 baserat på ett stickprov av n=3539 personer där alltså 1313 person angav att de skulle rösta på S. Vi såg också att ett 95% konfidensintervall för p var (0.355, 0.387).\nMånaden innan (SVT/Novus, Januari 2023) skattades andelen S-väljare till 0.347 (samma antal personer tillfrågades och 1228 personer angav att de skulle rösta på S). Använd funktionen prop.test för att beräkna ett 95% konfidensintervall för p i Januari 2023.\nBeräkna även detta konfidensintervall med formeln\n\\[\n\\hat p \\pm z_{\\alpha/2}\\cdot\\sqrt{\\frac{pq}{n}}\n\\]\nAnvänd konfidensintervallen för Januari och Februari 2023 för att förklara Novus påstående (vad gäller S):\nI den senaste undersökningen från SVT/Novus (Februari 2023) är ingen förändring statistiskt säkerställd.\n\n\n💪 Uppgift 1.2\nI senaste valet fick S 30,33% av rösterna. Använda prop.test för att testa på 5% signifikansnivå om andelen S-väljare i i Februari 2023 är förändrat sedan valet."
  },
  {
    "objectID": "datorlab/DatorLab7.html",
    "href": "datorlab/DatorLab7.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installera paket\n\n\n\nDen här labben förutsätter att följande paket finns installerade:\n\nsda1\n\nsda1 är kursens egna R-paket och måste installeras från GitHub. Det görs genom att först installera paketet remotes och därefter installera kurspaketet:\n\n# install.packages(\"remotes\") # avkommentera första gången\nlibrary(remotes)\n#install_github(\"StatisticsSU/sda1paket\")  # avkommentera första gången\nlibrary(sda1)\n\nLoading required package: ggplot2"
  },
  {
    "objectID": "datorlab/DatorLab7.html#introduktion",
    "href": "datorlab/DatorLab7.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den här datorlabben kommer vi att arbeta med fördelningar i R, bland annat lära oss simulera från olika fördelningar, dvs dra slumptal från fördelningar.\n\n\n💪 Uppgift 0.1\nSe till att paketen ovan är installerade i RStudio innan du fortsätter med resten.\n\n\n💪 Uppgift 0.2\nSkapa en mapp Lab5 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din nya Lab5 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar."
  },
  {
    "objectID": "datorlab/DatorLab7.html#z.-estimera-model",
    "href": "datorlab/DatorLab7.html#z.-estimera-model",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Z. Estimera model",
    "text": "Z. Estimera model\nEnkel regression\nEstimera på data\nTolka utskrift, gör test.\nPrediktion\nPrediktionsintervall med reg_predict\nMultipel\nSamma som ovan, men inte grafisk prediktionsintervall, bara med lm.predict och interval."
  },
  {
    "objectID": "datorlab/DatorLab7.html#y.-simulera-samplingfördelning---enkel-regression",
    "href": "datorlab/DatorLab7.html#y.-simulera-samplingfördelning---enkel-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Y. Simulera samplingfördelning - enkel regression",
    "text": "Y. Simulera samplingfördelning - enkel regression\n\nSimulera enkel regressionsmodell för hand. Ta fram samplingfördelning för b_1 genom simulering. Undersök väntevärdesriktighet. Jämför simulerad fördelning med teoretiska samplingfördelningen.\nLåt X:n vara korrelerade mer och mer korrelerade. Vad händer med standardfelen? Varför?"
  },
  {
    "objectID": "datorlab/DatorLab7.html#x.-omitted-variable-bias",
    "href": "datorlab/DatorLab7.html#x.-omitted-variable-bias",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "X. Omitted variable bias",
    "text": "X. Omitted variable bias\n\n💪 Uppgift X.1\n\nSimulera regression med två kovariater med reg_simulate i sda1 paketet. Okorrelerade x. Skatta regression med bara x_1. Undersök unbiasedness.\nSimulera regression med två kovariater med reg_simulate i sda1 paketet. korrelerade x. Skatta regression med bara x_1. Undersök unbiasedness."
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html",
    "href": "assignments/assignment2/Assignment2.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installation av nödvändiga paket\n\n\n\nDen här inlämningsuppgiften förutsätter att följande paket finns installerade:\n\nmosaic\ngplots\nremotes\nsda1\n\nDe tre första paketen kan installeras som vanligt via kommandot install.packages('packagename'), där 'packagename' är namnet på paketet, t.ex 'mosaic'.\nDet sista paketet, sda1, är kursens egna R-paket och installeras med kommandot\ninstall_github(\"StatisticsSU/sda1paket\")"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#introduktion",
    "href": "assignments/assignment2/Assignment2.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\nI denna andra inlämningsuppgift ska ni självständigt i grupper om tre analysera ett datamaterial i programmeringsspråket R, med fokus på sannolikhetslära och inferens. Till skillnad från datorlaborationerna finns det minimalt med kodexempel. Datorlaborationerna går igenom de flesta momenten som behandlas i inlämningsuppgiften, så se till att göra klart dessa innan.\n\n\n\n\n\n\n\nInstruktioner\n\n\n\nI denna inlämningsuppgift ska ni analysera ett datamaterial med 1602 australienska hushålls elkonsumption. Datamaterialet finns i kursens R-paket sda1 och heter electricitycost. När du installerat och laddat in sda1-paketet finns electricitycost tillgängligt som en dataframe, dvs en tabell där raderna är observationer (hushåll) och kolumnerna är variabler, t ex hushållets kostnad för el och information om hushållets storlek och utrustning. Se nedan för mer information.\nTill skillnad från den tidigare inlämningsuppgiften ska ni i denna inlämningsuppgift arbeta i ett separat Quarto-dokument där ni skriver alla svar. Det här dokumentet som du läser nu innehåller alltså bara instruktioner och frågorna. Quarto-dokumentet som ni ska göra analysen och skriva svaren i finns här.\nInlämningsuppgiften ska lämnas in i form av ett html dokument genererat av Quarto. Kontrollera noga att du inte har några felmeddelande och att dokumentet kompileras utan problem. Använd tydliga figurer och namnge axlarna med tydliga variabelnamn. Glöm inte att skriva era namn ovanför istället för Namn 1, Namn 2 och Namn 3."
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#läsa-in-data",
    "href": "assignments/assignment2/Assignment2.html#läsa-in-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "0. Läsa in data",
    "text": "0. Läsa in data\n\n💪 Uppgift 0.1\nLadda in dataseten Boston_census_data.Rdata och Boston_districts_to_predict.Rdata (länkar för att ladda ner data finns i Instruktioner avsnittet ovan).\n\n\n\n\n\n\nUppgift 0.1 - Svar\n\n\n\n\n# Write your code here\nload(file = url(\"https://github.com/StatisticsSU/SDA1/blob/main/assignments/assignment1/Boston_census_data.RData?raw=true\"))"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#kriminalitet-i-boston",
    "href": "assignments/assignment2/Assignment2.html#kriminalitet-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Kriminalitet i Boston",
    "text": "1. Kriminalitet i Boston\nI detta avsnitt ska ni analysera kriminaliteten i Boston med hjälp av variabeln crime_rate.\n\n💪 Uppgift 1.1\nVad kan man generellt säga om kriminaliteten i censusdistrikten? Använd lämpliga figurer samt fördelningsmått som underlag.\n\n\n\n\n\n\nUppgift 1.1 - Svar\n\n\n\nSkriv svaret här. Vid behov skrivs matematiska symboler inom dollartecken, till exempel \\(\\overline{y} = \\sum^{n}_{i=1} y_i\\). Koden skrivs i R-rutan nedanför.\n\n# Write your code here\n\n\n\n\n\n💪 Uppgift 1.2\nlorem impsun\n\n\n\n\n\n\nTips\n\n\n\nlorem impsun\n\n\n\n\n\n\n\n\nUppgift 1.2 - Svar\n\n\n\nSkriv svaret här.\n\n# Write your code her\n\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment2/Assignment2.html#fastighetsskatt-i-boston",
    "href": "assignments/assignment2/Assignment2.html#fastighetsskatt-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Fastighetsskatt i Boston",
    "text": "2. Fastighetsskatt i Boston\nI detta avsnitt ska ni analysera fastighetsskatten i Boston med hjälp av variabeln tax_rate.\n\n💪 Uppgift 2.1\nVad kan man generellt säga om fastighetsskatten i censusdistrikten? Använd lämpliga figurer samt fördelningsmått som underlag.\n\n\n\n\n\n\nUppgift 2.1 - Svar\n\n\n\nSkriv svaret här.\n\n# Write your code here"
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html",
    "href": "datorlab/lab7/DatorLab7.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installera paket\n\n\n\nDen här labben förutsätter att följande paket finns installerade:\n\nmosaic\nsda1\n\nsda1 är kursens egna R-paket och måste installeras från GitHub. Det görs genom att först installera paketet remotes och därefter installera kurspaketet:\n\nlibrary(mosaic)\n# install.packages(\"remotes\") # avkommentera första gången\nlibrary(remotes)\n#install_github(\"StatisticsSU/sda1paket\")  # avkommentera första gången\nlibrary(sda1)"
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#introduktion",
    "href": "datorlab/lab7/DatorLab7.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den här datorlabben kommer ni analysera olika datamaterial med regression. Det första datamaterialet om reklam är verkligt. I Uppgift 3 ska ni analysera datamaterial som är simulerade av mig, från olika populationsmodeller som jag har valt. Det blir ett intressant laboratorium, där ni kan utforska olika aspekter av regression i en kontrollerad miljö. Och även få veta den underliggande populationsmodellen efter att ni gjort labben!\n\n\n\n\n\n\n\nSkapa mapp för labben\n\n\n\nSkapa en mapp Lab7 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din Lab7 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar."
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#z.-estimera-model",
    "href": "datorlab/lab7/DatorLab7.html#z.-estimera-model",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Z. Estimera model",
    "text": "Z. Estimera model\nEnkel regression\nEstimera på data\nTolka utskrift, gör test.\nPrediktion\nPrediktionsintervall med reg_predict\nMultipel\nSamma som ovan, men inte grafisk prediktionsintervall, bara med lm.predict och interval."
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#y.-simulera-samplingfördelning---enkel-regression",
    "href": "datorlab/lab7/DatorLab7.html#y.-simulera-samplingfördelning---enkel-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Y. Simulera samplingfördelning - enkel regression",
    "text": "Y. Simulera samplingfördelning - enkel regression\n\nSimulera enkel regressionsmodell för hand. Ta fram samplingfördelning för b_1 genom simulering. Undersök väntevärdesriktighet. Jämför simulerad fördelning med teoretiska samplingfördelningen.\nLåt X:n vara korrelerade mer och mer korrelerade. Vad händer med standardfelen? Varför?"
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#x.-omitted-variable-bias",
    "href": "datorlab/lab7/DatorLab7.html#x.-omitted-variable-bias",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "X. Omitted variable bias",
    "text": "X. Omitted variable bias\n\n💪 Uppgift X.1\n\nSimulera regression med två kovariater med reg_simulate i sda1 paketet. Okorrelerade x. Skatta regression med bara x_1. Undersök unbiasedness.\nSimulera regression med två kovariater med reg_simulate i sda1 paketet. korrelerade x. Skatta regression med bara x_1. Undersök unbiasedness."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html",
    "href": "assignments/assignment2/Assignment2instructions.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installation av nödvändiga paket\n\n\n\nDen här inlämningsuppgiften förutsätter att följande paket finns installerade:\n\nmosaic\ngplots\nremotes\nsda1\n\nDe tre första paketen kan installeras som vanligt via kommandot install.packages('packagename'), där 'packagename' är namnet på paketet, t.ex 'mosaic'.\nDet sista paketet, sda1, är kursens egna R-paket och installeras med kommandot\ninstall_github(\"StatisticsSU/sda1paket\")\nefter att du laddat in remotes paketet."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#introduktion",
    "href": "assignments/assignment2/Assignment2instructions.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\nI denna andra inlämningsuppgift ska ni självständigt i grupper om tre analysera ett datamaterial i programmeringsspråket R, med fokus på sannolikhetslära och inferens. Till skillnad från datorlaborationerna finns det minimalt med kodexempel. Datorlaborationerna går igenom de flesta momenten som behandlas i inlämningsuppgiften, så se till att göra klart dessa innan.\n\n\n\n\n\n\n\nInstruktioner\n\n\n\nI denna inlämningsuppgift ska ni analysera ett datamaterial med 1602 australiska hushålls elkonsumption1, och finns i kursens R-paket sda1 och heter electricitycost. När du installerat och laddat in sda1-paketet finns electricitycost tillgängligt som en dataframe, dvs en tabell där raderna är observationer (hushåll) och kolumnerna är variabler, t ex hushållets kostnad för el och information om hushållets storlek och utrustning. Se nedan för mer information.\nTill skillnad från den tidigare inlämningsuppgiften ska ni i denna inlämningsuppgift arbeta i ett separat Quarto-dokument där ni skriver alla svar. Det här dokumentet som du läser nu innehåller alltså bara instruktioner och frågorna. Det Quarto-dokument som ni ska göra analysen och skriva svaren i finns här.\nI många uppgifter vill jag att ni ska använda både formelsamlingen för att beräkna en sak (t ex ett hypotestest), men även färdiga funktioner i R (t ex t.test funktionen). När ni använder formelsamlingen får ni använda R för att beräkna de saker ni behöver i formlerna, t ex sd-funktionen för att beräkna standardavvikelsen, eller qt-funktionen för att beräkna ett kritiskt värde från t-fördelningen. På det sättet tränas ni både på att hantera och förstå formeln (tentan! 😰) och hur man använder R i praktiken 😍. Det kan också vara bra träning att leta upp alla kritiska värden i tabellerna, även om jag inte ber om det.\nInlämningsuppgiften ska lämnas in i form av ett html dokument genererat av Quarto. Kontrollera noga att du inte har några felmeddelande och att dokumentet kompileras utan problem. Använd tydliga figurer och namnge axlarna med tydliga variabelnamn. Glöm inte att skriva era namn i Quarto-dokumentet istället för Namn 1, Namn 2 och Namn 3.\n\nAlla gruppmedlemmar ska vara delaktiga och bidra till alla delar av rapporten och arbetet som leder upp till rapporten, dvs skriva kod, analysera data, tolka resultat, dra slutsatser och skriva rapporten."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#läsa-in-data",
    "href": "assignments/assignment2/Assignment2instructions.html#läsa-in-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "0. Läsa in data",
    "text": "0. Läsa in data\nDatamaterialet electricitycost läses in via kurspaketet sda1:\n\nlibrary(remotes)\n#install_github(\"StatisticsSU/sda1paket\")\nlibrary(sda1)\nhead(electricitycost)\n\n  cost rooms people income onlysecondary waterheat cookel poolfilt airrev\n1  545     7      4  29900             0         0      1        0      1\n2  389     7      2  11700             0         0      1        0      0\n3  390     8      2  16900             0         0      0        0      0\n4  268     7      2   9750             1         0      1        0      1\n5  543     6      2  24700             1         0      0        0      1\n6  278     6      3   8450             1         0      0        0      0\n  aircond microwave dish dryer\n1       1         0    0     0\n2       0         1    1     0\n3       1         0    0     0\n4       1         0    0     1\n5       1         1    0     1\n6       0         0    0     1\n\n\nVarje rad i datamaterialet är ett av de 1602 australiska hushållen. Skriv ?electricitycost i Console för att få en komplett beskrivning av alla variabler. För att inte behöva skriva det långa namnet electricitycost hela tiden kan vi definera en ny variabel df (förkortning av dataframe)\n\ndf = electricitycost"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#kriminalitet-i-boston",
    "href": "assignments/assignment2/Assignment2instructions.html#kriminalitet-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Kriminalitet i Boston",
    "text": "1. Kriminalitet i Boston\nI detta avsnitt ska ni analysera kriminaliteten i Boston med hjälp av variabeln crime_rate.\n\n💪 Uppgift 1.1\nVad kan man generellt säga om kriminaliteten i censusdistrikten? Använd lämpliga figurer samt fördelningsmått som underlag.\n\n\n\n\n\n\nUppgift 1.1 - Svar\n\n\n\nSkriv svaret här. Vid behov skrivs matematiska symboler inom dollartecken, till exempel \\(\\overline{y} = \\sum^{n}_{i=1} y_i\\). Koden skrivs i R-rutan nedanför.\n\n# Write your code here\n\n\n\n\n\n💪 Uppgift 1.2\nlorem impsun\n\n\n\n\n\n\nTips\n\n\n\nlorem impsun\n\n\n\n\n\n\n\n\nUppgift 1.2 - Svar\n\n\n\nSkriv svaret här.\n\n# Write your code her\n\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#fastighetsskatt-i-boston",
    "href": "assignments/assignment2/Assignment2instructions.html#fastighetsskatt-i-boston",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Fastighetsskatt i Boston",
    "text": "2. Fastighetsskatt i Boston\nI detta avsnitt ska ni analysera fastighetsskatten i Boston med hjälp av variabeln tax_rate.\n\n💪 Uppgift 2.1\nVad kan man generellt säga om fastighetsskatten i censusdistrikten? Använd lämpliga figurer samt fördelningsmått som underlag.\n\n\n\n\n\n\nUppgift 2.1 - Svar\n\n\n\nSkriv svaret här.\n\n# Write your code here"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#läsa-in-data-och-utför-transformationer",
    "href": "assignments/assignment2/Assignment2instructions.html#läsa-in-data-och-utför-transformationer",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "0. Läsa in data och utför transformationer",
    "text": "0. Läsa in data och utför transformationer\nDatamaterialet electricitycost läses in via kurspaketet sda1:\n\nlibrary(remotes)\n#install_github(\"StatisticsSU/sda1paket\")\nlibrary(sda1)\nhead(electricitycost)\n\n  cost rooms people income onlysecondary waterheat cookel poolfilt airrev\n1  545     7      4  29900             0         0      1        0      1\n2  389     7      2  11700             0         0      1        0      0\n3  390     8      2  16900             0         0      0        0      0\n4  268     7      2   9750             1         0      1        0      1\n5  543     6      2  24700             1         0      0        0      1\n6  278     6      3   8450             1         0      0        0      0\n  aircond microwave dish dryer\n1       1         0    0     0\n2       0         1    1     0\n3       1         0    0     0\n4       1         0    0     1\n5       1         1    0     1\n6       0         0    0     1\n\n\nVarje rad i datamaterialet är ett av de total 1602 hushållen. Skriv ?electricitycost i Console för att få en komplett beskrivning av alla variabler. För att inte behöva skriva det långa namnet electricitycost hela tiden kan vi definera en ny variabel df (förkortning av dataframe)\n\ndf = electricitycost"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#antal-personer-i-hushållet",
    "href": "assignments/assignment2/Assignment2instructions.html#antal-personer-i-hushållet",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Antal personer i hushållet",
    "text": "1. Antal personer i hushållet\n\n💪 Uppgift 1.1\nVariabeln people innehåller antal personer i hushållet. Definiera variabeln extrapeople = df$people - 1, som mäter antalet personer utöver ägaren (som vi antar är bara en person). Modellera extrapeople som oberoende observationer från en \\(\\mathrm{Pois}(\\lambda)\\)-fördelning. Skatta parametern \\(\\lambda\\) från datamaterialet.\n\n\n💪 Uppgift 1.2\nUndersök grafiskt om den skattade Poisson-modellen i Uppgift 1.1 anpassar data väl.\n\n\n💪 Uppgift 1.3\nAnvänd den skattade Poisson-modellen för att beräkna sannolikheten för ett storhushåll, vilket vi definierar som ett hushåll med fler än 4 personer."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#poisson-modell-för-antal-personer-i-hushållet",
    "href": "assignments/assignment2/Assignment2instructions.html#poisson-modell-för-antal-personer-i-hushållet",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Poisson-modell för antal personer i hushållet",
    "text": "1. Poisson-modell för antal personer i hushållet\n\n💪 Uppgift 1.1\nVariabeln people innehåller antal personer i hushållet. Definiera variabeln extrapeople = df$people - 1, som mäter antalet personer utöver ägaren (som vi antar är bara en person). I den här uppgiften ska vi modellera extrapeople som oberoende observationer från en \\(\\mathrm{Pois}(\\lambda)\\)-fördelning. Skatta parametern \\(\\lambda\\) från datamaterialet.\n\n\n💪 Uppgift 1.2\nUndersök grafiskt om den skattade Poisson-modellen i Uppgift 1.1 anpassar data väl.\n\n\n💪 Uppgift 1.3\nAnvänd den skattade Poisson-modellen för att beräkna sannolikheten för ett storhushåll, vilket vi definierar som ett hushåll med fler än 4 personer.\n\n\n💪 Uppgift 1.4\nPoissonmodellen är en trevlig modell för räknedata, men är begränsad eftersom väntevärdet och variansen alltid måste vara lika in en Poissonfördelning. Verkar det vara ett problem för variabeln extrapeople?"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#log-normalmodell-för-elkostnad",
    "href": "assignments/assignment2/Assignment2instructions.html#log-normalmodell-för-elkostnad",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. (log)-normalmodell för elkostnad",
    "text": "2. (log)-normalmodell för elkostnad\nHushållens totala elkostnad, cost, är rejält skev:\n\nhist(df$cost, 30, freq = FALSE, col = \"steelblue\")\n\n\n\n\nLogaritmen av cost har en fördelning som är mycket mer symmetrisk, även om viss skevhet verkar kvarstå:\n\nhist(log(df$cost), 30, freq = FALSE, col = \"orange\")\n\n\n\n\n\n💪 Uppgift 2.1\nI den här uppgiften ska vi modellera variabeln logcost = log(df$cost) som oberoende observationer från en \\(N(\\mu,\\sigma)\\) fördelning. Skatta \\(\\mu\\) och \\(\\sigma\\) från data. [Obs! Ni behöver inte transformera tillbaka till originalskala, utan arbeta med hela Uppgift 2 på log-skala.]\n\n\n💪 Uppgift 2.2\nUndersök grafiskt hur väl den skattade normalmodellen passar variabeln logcost.\n\n\n💪 Uppgift 2.3\nJämför median av variabeln logcost med medianen från den skattade sannolikhetsmodellen från Uppgift 2.1. [hint: lösningen blir väldigt enkel här, det är meningen. Jag vill att ni ska tänka på kopplingen mellan den teoretiska sannolikhetsmodellen och hur den relaterar till data.]\n\n\n💪 Uppgift 2.4\nGör ett 95%-igt konfidensintervall för \\(\\mu\\) i modellen för logcost från Uppgift 2.1, både genom att använda formelsamlingen och genom att använda en funktion i R. Tolka intervallet. [Som jag skrev i instruktionerna ovan är det ok att använda R för att beräkna delar av konfidensintervallet även i fallet där jag ber om att ni ska använda formelsamling; t ex använda sd()-funktionen för att beräkna standardavvikelsen s. Men jag vill att ni använder formeln för konfidensintervall från formelsamlingen i den slutliga uträkningen. För att träna inför tentan. Och sen jämföra med det konfidensintervall ni får direkt från R].\n\n\n💪 Uppgift 2.5\nTesta om den genomsnittliga logcost i modellen/populationen är mindre än 6. Ställ upp noll- och alternativhypotes och testa på 5% signifikansnivå. Gör beräkningarna både med hjälp av formelsamlingen och med R.\n\n\n💪 Uppgift 2.6\nBeräkna p-värdet för testet i Uppgift 2.5 genom att använda R. Hade du förkastat nollhypotesen på 1% signifikansnivå?\n\n\n💪 Uppgift 2.7\nAntag att vi tar den skevheten som vi ser i histogrammet över logcost på allvar. Beskriv (inga uträkningar) om vi ändå kan göra ett hypotestest utan att anta att logcost är normalfördelad.\n\n\n💪 Uppgift 2.8\nTesta på 5% signifikansnivå om det finns någon skillnad i genomsnittlig logcost i modell/populationen för hushåll med och utan air conditioner. Ställ upp noll- och mothypotest och beräkna teststatistikans värde med hjälp av formelsamlingen. Använd R för att beräkna frihetsgraderna i nollhypotesens t-fördelning (som är en komplicerad beräkning eftersom vi har olika antal observationer i de två grupperna)."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#section",
    "href": "assignments/assignment2/Assignment2instructions.html#section",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3.",
    "text": "3."
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#enkel-och-multipel-linjär-regression",
    "href": "assignments/assignment2/Assignment2instructions.html#enkel-och-multipel-linjär-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel och multipel linjär regression",
    "text": "3. Enkel och multipel linjär regression\nNi ska nu analysera en regressionsmodell med logcost som responsvariabel. Vi börjar med hushållets inkomst income som förklarande variabel. Det är svårt att se om en linjär regression passar data eftersom income bara kan anta ett mindre antal värden (den verkar vara grupperad i inkomstklasser):\n\ndf$logcost = log(df$cost) # lägger in logcost i dataframen, blir mindre kod då.\nplot(logcost ~ income, data = df, pch = 19, cex = 0.5, col = \"steelblue\")\n\n\n\n\nFör att lättare se om det verkar linjärt anpassar jag en s k lowess-skattning (en slags icke-linjär regression) och plottar anpassningen, med funktionen plotLowess från gplots paketet:\n\nplotLowess(logcost ~ income, data = df, pch = 19, cex = 0.5, col = \"steelblue\")\n\n\n\n\nDet ser inte linjärt ut. Låt oss prova att gå ett steg nedåt på Tukey’s transformationsstege (i Tukey’s cirkel är vi i övre vänstra kvadraten, vilket indikerar att vi ska gå nedåt på stegen för X-variabeln) och göra en \\(\\sqrt{ }\\) -transformation (sqrt):\n\nplotLowess(logcost ~ sqrt(income), data = df, pch = 19, cex = 0.5, col = \"steelblue\")\n\n\n\n\nHmm, inte riktigt linjärt ännu. Vi provar ett steg till ned på Tukey’s stege, dvs att logaritmera x-variabeln income :\n\nplotLowess(logcost ~ log(income), data = df, pch = 19, cex = 0.5, col = \"steelblue\")\n\n\n\n\nBingo! Rätt så linjärt! Vi kör på detta och lägger även in logaritmen av income i vår dataframe df.\n\ndf$logincome = log(df$income)\nhead(df)\n\n  cost rooms people income onlysecondary waterheat cookel poolfilt airrev\n1  545     7      4  29900             0         0      1        0      1\n2  389     7      2  11700             0         0      1        0      0\n3  390     8      2  16900             0         0      0        0      0\n4  268     7      2   9750             1         0      1        0      1\n5  543     6      2  24700             1         0      0        0      1\n6  278     6      3   8450             1         0      0        0      0\n  aircond microwave dish dryer  logcost logincome\n1       1         0    0     0 6.300786 10.305614\n2       0         1    1     0 5.963579  9.367344\n3       1         0    0     0 5.966147  9.735069\n4       1         0    0     1 5.590987  9.185023\n5       1         1    0     1 6.297109 10.114559\n6       0         0    0     1 5.627621  9.041922\n\n\n\n💪 Uppgift 3.1\nAnvänd R för att skatta modellen:\n\\[\n\\texttt{logcost} = \\beta_0 + \\beta_1 \\cdot \\texttt{logincome} + \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\noch tolka skattningarna \\(b_0\\) och \\(b_1\\).\n\n\n💪 Uppgift 3.2\nAnvänd formelsamlingen för att beräkna ett 99%-igt konfidensintervall för \\(\\beta_1\\). Kontrollera att ditt svar stämmer med R’s direkta beräkning av detta konfidensintervall.\n\n\n💪 Uppgift 3.3\nAnvänd formelsamlingen för att testa om logincome är en signifikant förklarande variabel på signifikansnivån 1%. Ställ upp noll- och alternativhypotes för testet och var noga med att dra en slutsats från testet.\n\n\n💪 Uppgift 3.4\nGör en prediktion med 95% prediktionsintervall för logcost vid logincome=11 genom att använda R. [tips: argumentet newdata i predict-funktionen måste vara en dataframe, inte en vektor. Se min kod för lifespan data.]\n\n\n💪 Uppgift 3.5\nSkatta nu en multipel linjär regression:\n\\[\n\\texttt{logcost} = \\beta_0\n+\\beta_1 \\cdot \\texttt{logincome}\n+\\beta_2 \\cdot \\texttt{logrooms}\n+\\beta_3 \\cdot \\texttt{logpeople} \\\\\n+\\beta_4 \\cdot \\texttt{onlysecondary}\n+\\beta_5 \\cdot \\texttt{poolfilt}\n+\\beta_6 \\cdot \\texttt{aircond}\n+ \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\ndär logrooms = log(rooms) och logpeople = log(people) (lägg till dessa transformerade variabler i vår dataframe df). Tolka skattningarna av koefficienterna \\(\\beta_1\\) och \\(\\beta_6\\).\n\n\n💪 Uppgift 3.6\nVilka förklarande variabler är signifikanta på 5% nivån? På 1% signifikansnivå?\n\n\n💪 Uppgift 3.7\nGör en prediktion med 90% prediktionsintervall för logcost för ett hushåll med medianvärden på logincome, logrooms, logpeople och alla tre dummyvariabler satta till värdet noll."
  },
  {
    "objectID": "assignments/assignment2/Assignment2answers.html",
    "href": "assignments/assignment2/Assignment2answers.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Läs in dina paket här:"
  },
  {
    "objectID": "assignments/assignment2/Assignment2answers.html#poisson-modell-för-antal-personer-i-hushållet",
    "href": "assignments/assignment2/Assignment2answers.html#poisson-modell-för-antal-personer-i-hushållet",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Poisson-modell för antal personer i hushållet",
    "text": "1. Poisson-modell för antal personer i hushållet\n\n💪 Uppgift 1.1\n\nextrapeople = df$people - 1\nlambdaest = mean(extrapeople)\n\n\n\n💪 Uppgift 1.2\n\nplot(tally(extrapeople, format = \"proportion\"), xlab = \"antal extra personer, x\", ylab = \"P(X=x)\", col = \"steelblue\")\nlines(0:5, dpois(0:5, lambda = lambdaest), type = \"b\", col = \"orange\", lwd = 2)\nlegend(\"topleft\", legend = c(\"data\", \"model fit\"), col = c(\"steelblue\", \"orange\"), \n       lty = c(1, 1), cex = 0.8)\n\n\n\n\n\n\n💪 Uppgift 1.3\nI data:\n\nsum(extrapeople > 4)/length(extrapeople)\n\n[1] 0.006242197\n\n\nEnligt modellen:\n\n1 - ppois(4, lambda = lambdaest)\n\n[1] 0.02631038\n\n\n\n\n💪 Uppgift 1.4\nPoissonmodellen är begränsad eftersom \\(E(X)=Var(X)\\). Men för variabeln extrapeople verkar den restriktion passa ganska bra:\n\nc(mean(extrapeople), var(extrapeople))\n\n[1] 1.646067 1.420562"
  },
  {
    "objectID": "assignments/assignment2/Assignment2answers.html#log-normalmodell-för-elkostnad",
    "href": "assignments/assignment2/Assignment2answers.html#log-normalmodell-för-elkostnad",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. (log)-normalmodell för elkostnad",
    "text": "2. (log)-normalmodell för elkostnad\n\n💪 Uppgift 2.1\n\nlogcost = log(df$cost)\nxbar = mean(logcost)\ns = sd(logcost)\n\n\n\n💪 Uppgift 2.2\nNormalmodellen passar rätt bra, bortsett från att data har liten skevhet som den symmetriska normalfördelningen inte klarar av att modellera.\n\nhist(logcost, 30, freq = F, col = \"orange\")\nxgrid = seq(2, 10, by = 0.01)\nlines(xgrid, dnorm(xgrid, mean = xbar , sd = s), lw = 3, col = \"steelblue\")\n\n\n\n\n\n\n💪 Uppgift 2.3\nMedianen i datamaterialet stämmer rätt bra med den skattade modellens median:\n\nmedian(logcost)\n\n[1] 5.888878\n\nqnorm(0.5, mean = xbar, sd = s)\n\n[1] 5.829855\n\n\n\n\n💪 Uppgift 2.4\nFormelsamlingen\n\\[\\bar x \\pm t_{0.025, 1601}\\cdot \\frac{s}{\\sqrt{n}},\\]\ndär \\(t_{0.025, 1601}\\) tas från tabell (df =1000 är närmast) eller med R:\n\nn = length(logcost)\ntcrit = qt(0.975, df = n-1)\nc(xbar - tcrit*(s/sqrt(n)), xbar + tcrit*(s/sqrt(n)))\n\n[1] 5.802806 5.856904\n\n\nMed 95% säkerhet ligger den genomsnittliga logaritmerade elkostnaden i populationen ($\\mu$) i intervallet \\((5.802806, 5.856904)\\) dvs intervallet täcker \\(\\mu\\) i 95% av alla möjliga stickprov från populationen.\nMed R:\n\nt.test(logcost)\n\n\n    One Sample t-test\n\ndata:  logcost\nt = 422.75, df = 1601, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 5.802806 5.856904\nsample estimates:\nmean of x \n 5.829855 \n\n\n\n\n💪 Uppgift 2.5\nTesta om den genomsnittliga logcost i populationen är mindre än 5.8. Ställ upp noll- och alternativhypotes och testa på 5% signifikansnivå. Gör beräkningarna både med hjälp av formelsamlingen och med R.\n\\[\nH_0: \\mu < 5.8 \\\\\nH_1: \\mu \\geq 5.8\n\\]\n\\[\nT = \\frac{\\bar X - 5.8}{\\frac{s}{\\sqrt n}} \\sim t_{1601}\n\\]\n\ntobs  = (xbar - 5.8)/(s/sqrt(n))\ntobs\n\n[1] 2.164928\n\n\n\ntcrit = qt(0.95, df = n-1)\ntobs > tcrit\n\n[1] TRUE\n\n\nså vi förkastar nollhypotesen att genomsnittliga logcost i populationen är mindre än 5.8.\n\n\n💪 Uppgift 2.6\nBeräkna p-värdet för testet i Uppgift 2.5. Hade du förkastat nollhypotesen på 1% signifikansnivå?\n\n1 - pt(tobs, df = n-1)\n\n[1] 0.01527029\n\n\np-värdet är större än 0.01 så vi hade inte förkastat på 1% signifikansnivå.\n\n\n💪 Uppgift 2.7\n\\(n=1602 > 30\\) så vi kan använda centrala gränsvärdessatsen: \\(\\bar x\\) är approximativt normalfördelat och testet kan utföras med Z-tabellen.\n\n\n💪 Uppgift 2.8\nTeststatistikan från formelsamling\n\nlogcost_aircond = logcost[df$aircond == 1]\nlogcost_no_aircond = logcost[df$aircond == 0]\nxbar1 = mean(logcost_aircond)\nxbar2 = mean(logcost_no_aircond)\ns1 = sd(logcost_aircond)\ns2 = sd(logcost_no_aircond)\nn1 = length(logcost_aircond)\nn2 = length(logcost_no_aircond)\ntobs = (xbar1-xbar2 - 0 )/sqrt(s1^2/n1 + s2^2/n2)\ntobs\n\n[1] 8.665919\n\n\nVi kan få frihetsgraderna df = 951.14 från t.test-funktionen in R:\n\nt.test(logcost ~ df$aircond)\n\n\n    Welch Two Sample t-test\n\ndata:  logcost by df$aircond\nt = -8.6659, df = 951.14, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.3143814 -0.1982845\nsample estimates:\nmean in group 0 mean in group 1 \n       5.656406        5.912739 \n\n\nDet kritiska värdet på 5% signifikansnivå är\n\nqt(0.975, df = 951.14)\n\n[1] 1.962461\n\n\nEftersom \\(\\vert t_{obs} = 8.665919 > t_{crit} = 1.962461\\) så förkastar vi \\(H_0\\) på signifikansnivån \\(\\alpha = 0.05\\)."
  },
  {
    "objectID": "assignments/assignment2/Assignment2answers.html#enkel-regression",
    "href": "assignments/assignment2/Assignment2answers.html#enkel-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel regression",
    "text": "3. Enkel regression"
  },
  {
    "objectID": "assignments/assignment2/Assignment2handin.html",
    "href": "assignments/assignment2/Assignment2handin.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Inlämning\n\n\n\nInlämningsuppgiften ska lämnas in i form av ett html dokument genererat av det här Quarto-dokumentet. Öppna upp code chunks under de uppgifter de behövs.\nKontrollera noga att du inte har några felmeddelande och att dokumentet kompileras utan problem. Använd tydliga figurer och namnge axlarna med tydliga variabelnamn. Glöm inte att skriva era namn ovanför istället för Namn 1, Namn 2 och Namn 3.\nLäs in dina paket här:\noch definiera vår dataframe df med datamaterialet:"
  },
  {
    "objectID": "assignments/assignment2/Assignment2handin.html#poisson-modell-för-antal-personer-i-hushållet",
    "href": "assignments/assignment2/Assignment2handin.html#poisson-modell-för-antal-personer-i-hushållet",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Poisson-modell för antal personer i hushållet",
    "text": "1. Poisson-modell för antal personer i hushållet\n\n💪 Uppgift 1.1\n\n\n💪 Uppgift 1.2\n\n\n💪 Uppgift 1.3\n\n\n💪 Uppgift 1.4"
  },
  {
    "objectID": "assignments/assignment2/Assignment2handin.html#log-normalmodell-för-elkostnad",
    "href": "assignments/assignment2/Assignment2handin.html#log-normalmodell-för-elkostnad",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. (log)-normalmodell för elkostnad",
    "text": "2. (log)-normalmodell för elkostnad\n\n💪 Uppgift 2.1\n\n\n💪 Uppgift 2.2\n\n\n💪 Uppgift 2.3\n\n\n💪 Uppgift 2.4\n\n\n💪 Uppgift 2.5\n\n\n💪 Uppgift 2.6\n\n\n💪 Uppgift 2.7\n\n\n💪 Uppgift 2.8"
  },
  {
    "objectID": "assignments/assignment2/Assignment2handin.html#enkel-och-multipel-linjär-regression",
    "href": "assignments/assignment2/Assignment2handin.html#enkel-och-multipel-linjär-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel och multipel linjär regression",
    "text": "3. Enkel och multipel linjär regression\n\n💪 Uppgift 3.1\n\n\n💪 Uppgift 3.2\n\n\n💪 Uppgift 3.3\n\n\n💪 Uppgift 3.4\n\n\n💪 Uppgift 3.5\n\n\n💪 Uppgift 3.6\n\n\n💪 Uppgift 3.7"
  },
  {
    "objectID": "assignments/assignment2/Assignment2answers.html#enkel-och-multipel-linjär-regression",
    "href": "assignments/assignment2/Assignment2answers.html#enkel-och-multipel-linjär-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel och multipel linjär regression",
    "text": "3. Enkel och multipel linjär regression\n\n💪 Uppgift 3.1\n\ndf$logincome = log(df$income)\ndf$logrooms = log(df$rooms)\ndf$logpeople = log(df$people)\nfitsimple = lm(logcost ~ logincome, data = df)\nsummary(fitsimple)\n\n\nCall:\nlm(formula = logcost ~ logincome, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.24889 -0.29136  0.02225  0.31546  1.79446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.46486    0.16350   15.08   <2e-16 ***\nlogincome    0.34770    0.01685   20.64   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4907 on 1600 degrees of freedom\nMultiple R-squared:  0.2103,    Adjusted R-squared:  0.2098 \nF-statistic:   426 on 1 and 1600 DF,  p-value: < 2.2e-16\n\n\n\n\n💪 Uppgift 3.2\n\\[\nb_1 \\pm t_{0.005, 1602-2}\\cdot s_{b_1}\n\\]\ndär \\(s_{b_1}= 0.01685\\) från utskrift och qt(0.995, df = 1600)=2.578906 . Så:\n\nc(0.34770 - 2.578906*0.01685,0.34770 + 2.578906*0.01685)\n\n[1] 0.3042454 0.3911546\n\n\nDirekt med R:\n\nconfint(fitsimple, level = 0.99)\n\n                0.5 %    99.5 %\n(Intercept) 2.0432176 2.8865078\nlogincome   0.3042576 0.3911492\n\n\n\n\n💪 Uppgift 3.3\n\\[\nH_0: \\beta_1 = 0 \\\\\nH_A: \\beta_1 \\neq 0\n\\]\n\\[\nT = \\frac{b_1-0}{s_{b_1}} = \\frac{0.34770}{0.01685} = 20.64\n\\]\n\\[\nt_{crit} = qt(0.995, df = 1600)=2.578906\n\\]\nEfter \\(\\vert t_{obs} \\vert > t_{crit}\\) förkastar vi nollhypotesen på 1% signifikansnivå. Variabeln logincome är en signifikant förklarande variabel för logcost.\n\n\n💪 Uppgift 3.4\n\npredict(fitsimple, newdata = data.frame(logincome = 11), interval = \"prediction\")\n\n       fit      lwr      upr\n1 6.289601 5.325905 7.253296\n\n\n\n\n💪 Uppgift 3.5\n\nfitmultiple = lm(logcost ~ logincome + logrooms + logpeople + onlysecondary + poolfilt + aircond, data = df)\nsummary(fitmultiple)\n\n\nCall:\nlm(formula = logcost ~ logincome + logrooms + logpeople + onlysecondary + \n    poolfilt + aircond, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1166 -0.2582  0.0040  0.2799  1.6112 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.70092    0.17220  15.684  < 2e-16 ***\nlogincome      0.17874    0.01750  10.216  < 2e-16 ***\nlogrooms       0.55819    0.06213   8.984  < 2e-16 ***\nlogpeople      0.30927    0.02597  11.909  < 2e-16 ***\nonlysecondary -0.04647    0.02263  -2.053  0.04023 *  \npoolfilt       0.12453    0.04063   3.065  0.00221 ** \naircond        0.13048    0.02407   5.421 6.84e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4397 on 1595 degrees of freedom\nMultiple R-squared:  0.3677,    Adjusted R-squared:  0.3653 \nF-statistic: 154.6 on 6 and 1595 DF,  p-value: < 2.2e-16\n\n\nSkattningen \\(b_1=0.17874\\) av \\(\\beta_1\\): logcost ökar med 0.17874 enheter när logincome ökar med en enhet, och alla andra förklarande variabler hålls konstanta.\nSkattningen \\(b_5\\) av \\(\\beta_5\\): logcost är 0.12453 enheter högre för ett hus med poolfilter, givet alla andra variabler hålls konstanta.\n\n\n💪 Uppgift 3.6\nAlla variabler är signifikanta på 5% nivån (alla p-värden mindre än 0.05).\nAlla variabler utom onlysecondary (p-värde 0.04023>0.01) är också signifikanta på den strängare 1% nivån.\n\n\n💪 Uppgift 3.7\n\npredict(fitmultiple, newdata = data.frame(\n  logincome = median(df$logincome),\n  logrooms = median(df$logrooms),\n  logpeople = median(df$logpeople),\n  onlysecondary = 0,\n  poolfilt = 0,\n  aircond = 0\n  ), \n  interval = \"prediction\")\n\n       fit      lwr      upr\n1 5.741489 4.877802 6.605176"
  },
  {
    "objectID": "hidden/assignment_solutions/Assignment2answers.html",
    "href": "hidden/assignment_solutions/Assignment2answers.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Läs in dina paket här:"
  },
  {
    "objectID": "hidden/assignment_solutions/Assignment2answers.html#poisson-modell-för-antal-personer-i-hushållet",
    "href": "hidden/assignment_solutions/Assignment2answers.html#poisson-modell-för-antal-personer-i-hushållet",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Poisson-modell för antal personer i hushållet",
    "text": "1. Poisson-modell för antal personer i hushållet\n\n💪 Uppgift 1.1\n\nextrapeople = df$people - 1\nlambdaest = mean(extrapeople)\n\n\n\n💪 Uppgift 1.2\n\nplot(tally(extrapeople, format = \"proportion\"), xlab = \"antal extra personer, x\", ylab = \"P(X=x)\", col = \"steelblue\")\nlines(0:5, dpois(0:5, lambda = lambdaest), type = \"b\", col = \"orange\", lwd = 2)\nlegend(\"topleft\", legend = c(\"data\", \"model fit\"), col = c(\"steelblue\", \"orange\"), \n       lty = c(1, 1), cex = 0.8)\n\n\n\n\n\n\n💪 Uppgift 1.3\nI data:\n\nsum(extrapeople > 4)/length(extrapeople)\n\n[1] 0.006242197\n\n\nEnligt modellen:\n\n1 - ppois(4, lambda = lambdaest)\n\n[1] 0.02631038\n\n\n\n\n💪 Uppgift 1.4\nPoissonmodellen är begränsad eftersom \\(E(X)=Var(X)\\). Men för variabeln extrapeople verkar den restriktion passa ganska bra:\n\nc(mean(extrapeople), var(extrapeople))\n\n[1] 1.646067 1.420562"
  },
  {
    "objectID": "hidden/assignment_solutions/Assignment2answers.html#log-normalmodell-för-elkostnad",
    "href": "hidden/assignment_solutions/Assignment2answers.html#log-normalmodell-för-elkostnad",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. (log)-normalmodell för elkostnad",
    "text": "2. (log)-normalmodell för elkostnad\n\n💪 Uppgift 2.1\n\nlogcost = log(df$cost)\nxbar = mean(logcost)\ns = sd(logcost)\n\n\n\n💪 Uppgift 2.2\nNormalmodellen passar rätt bra, bortsett från att data har liten skevhet som den symmetriska normalfördelningen inte klarar av att modellera.\n\nhist(logcost, 30, freq = F, col = \"orange\")\nxgrid = seq(2, 10, by = 0.01)\nlines(xgrid, dnorm(xgrid, mean = xbar , sd = s), lw = 3, col = \"steelblue\")\n\n\n\n\n\n\n💪 Uppgift 2.3\nMedianen i datamaterialet stämmer rätt bra med den skattade modellens median:\n\nmedian(logcost)\n\n[1] 5.888878\n\nqnorm(0.5, mean = xbar, sd = s)\n\n[1] 5.829855\n\n\n\n\n💪 Uppgift 2.4\nFormelsamlingen\n\\[\\bar x \\pm t_{0.025, 1601}\\cdot \\frac{s}{\\sqrt{n}},\\]\ndär \\(t_{0.025, 1601}\\) tas från tabell (df =1000 är närmast) eller med R:\n\nn = length(logcost)\ntcrit = qt(0.975, df = n-1)\nc(xbar - tcrit*(s/sqrt(n)), xbar + tcrit*(s/sqrt(n)))\n\n[1] 5.802806 5.856904\n\n\nMed 95% säkerhet ligger den genomsnittliga logaritmerade elkostnaden i populationen ($\\mu$) i intervallet \\((5.802806, 5.856904)\\) dvs intervallet täcker \\(\\mu\\) i 95% av alla möjliga stickprov från populationen.\nMed R:\n\nt.test(logcost)\n\n\n    One Sample t-test\n\ndata:  logcost\nt = 422.75, df = 1601, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 5.802806 5.856904\nsample estimates:\nmean of x \n 5.829855 \n\n\n\n\n💪 Uppgift 2.5\nTesta om den genomsnittliga logcost i populationen är mindre än 5.8. Ställ upp noll- och alternativhypotes och testa på 5% signifikansnivå. Gör beräkningarna både med hjälp av formelsamlingen och med R.\n\\[\nH_0: \\mu < 5.8 \\\\\nH_1: \\mu \\geq 5.8\n\\]\n\\[\nT = \\frac{\\bar X - 5.8}{\\frac{s}{\\sqrt n}} \\sim t_{1601}\n\\]\n\ntobs  = (xbar - 5.8)/(s/sqrt(n))\ntobs\n\n[1] 2.164928\n\n\n\ntcrit = qt(0.95, df = n-1)\ntobs > tcrit\n\n[1] TRUE\n\n\nså vi förkastar nollhypotesen att genomsnittliga logcost i populationen är mindre än 5.8.\n\n\n💪 Uppgift 2.6\nBeräkna p-värdet för testet i Uppgift 2.5. Hade du förkastat nollhypotesen på 1% signifikansnivå?\n\n1 - pt(tobs, df = n-1)\n\n[1] 0.01527029\n\n\np-värdet är större än 0.01 så vi hade inte förkastat på 1% signifikansnivå.\n\n\n💪 Uppgift 2.7\n\\(n=1602 > 30\\) så vi kan använda centrala gränsvärdessatsen: \\(\\bar x\\) är approximativt normalfördelat och testet kan utföras med Z-tabellen.\n\n\n💪 Uppgift 2.8\nTeststatistikan från formelsamling\n\nlogcost_aircond = logcost[df$aircond == 1]\nlogcost_no_aircond = logcost[df$aircond == 0]\nxbar1 = mean(logcost_aircond)\nxbar2 = mean(logcost_no_aircond)\ns1 = sd(logcost_aircond)\ns2 = sd(logcost_no_aircond)\nn1 = length(logcost_aircond)\nn2 = length(logcost_no_aircond)\ntobs = (xbar1-xbar2 - 0 )/sqrt(s1^2/n1 + s2^2/n2)\ntobs\n\n[1] 8.665919\n\n\nVi kan få frihetsgraderna df = 951.14 från t.test-funktionen in R:\n\nt.test(logcost ~ df$aircond)\n\n\n    Welch Two Sample t-test\n\ndata:  logcost by df$aircond\nt = -8.6659, df = 951.14, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -0.3143814 -0.1982845\nsample estimates:\nmean in group 0 mean in group 1 \n       5.656406        5.912739 \n\n\nDet kritiska värdet på 5% signifikansnivå är\n\nqt(0.975, df = 951.14)\n\n[1] 1.962461\n\n\nEftersom \\(\\vert t_{obs} = 8.665919 > t_{crit} = 1.962461\\) så förkastar vi \\(H_0\\) på signifikansnivån \\(\\alpha = 0.05\\)."
  },
  {
    "objectID": "hidden/assignment_solutions/Assignment2answers.html#enkel-och-multipel-linjär-regression",
    "href": "hidden/assignment_solutions/Assignment2answers.html#enkel-och-multipel-linjär-regression",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Enkel och multipel linjär regression",
    "text": "3. Enkel och multipel linjär regression\n\n💪 Uppgift 3.1\n\ndf$logincome = log(df$income)\ndf$logrooms = log(df$rooms)\ndf$logpeople = log(df$people)\nfitsimple = lm(logcost ~ logincome, data = df)\nsummary(fitsimple)\n\n\nCall:\nlm(formula = logcost ~ logincome, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.24889 -0.29136  0.02225  0.31546  1.79446 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.46486    0.16350   15.08   <2e-16 ***\nlogincome    0.34770    0.01685   20.64   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4907 on 1600 degrees of freedom\nMultiple R-squared:  0.2103,    Adjusted R-squared:  0.2098 \nF-statistic:   426 on 1 and 1600 DF,  p-value: < 2.2e-16\n\n\n\n\n💪 Uppgift 3.2\n\\[\nb_1 \\pm t_{0.005, 1602-2}\\cdot s_{b_1}\n\\]\ndär \\(s_{b_1}= 0.01685\\) från utskrift och qt(0.995, df = 1600)=2.578906 . Så:\n\nc(0.34770 - 2.578906*0.01685,0.34770 + 2.578906*0.01685)\n\n[1] 0.3042454 0.3911546\n\n\nDirekt med R:\n\nconfint(fitsimple, level = 0.99)\n\n                0.5 %    99.5 %\n(Intercept) 2.0432176 2.8865078\nlogincome   0.3042576 0.3911492\n\n\n\n\n💪 Uppgift 3.3\n\\[\nH_0: \\beta_1 = 0 \\\\\nH_A: \\beta_1 \\neq 0\n\\]\n\\[\nT = \\frac{b_1-0}{s_{b_1}} = \\frac{0.34770}{0.01685} = 20.64\n\\]\n\\[\nt_{crit} = qt(0.995, df = 1600)=2.578906\n\\]\nEfter \\(\\vert t_{obs} \\vert > t_{crit}\\) förkastar vi nollhypotesen på 1% signifikansnivå. Variabeln logincome är en signifikant förklarande variabel för logcost.\n\n\n💪 Uppgift 3.4\n\npredict(fitsimple, newdata = data.frame(logincome = 11), interval = \"prediction\")\n\n       fit      lwr      upr\n1 6.289601 5.325905 7.253296\n\n\n\n\n💪 Uppgift 3.5\n\nfitmultiple = lm(logcost ~ logincome + logrooms + logpeople + onlysecondary + poolfilt + aircond, data = df)\nsummary(fitmultiple)\n\n\nCall:\nlm(formula = logcost ~ logincome + logrooms + logpeople + onlysecondary + \n    poolfilt + aircond, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1166 -0.2582  0.0040  0.2799  1.6112 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    2.70092    0.17220  15.684  < 2e-16 ***\nlogincome      0.17874    0.01750  10.216  < 2e-16 ***\nlogrooms       0.55819    0.06213   8.984  < 2e-16 ***\nlogpeople      0.30927    0.02597  11.909  < 2e-16 ***\nonlysecondary -0.04647    0.02263  -2.053  0.04023 *  \npoolfilt       0.12453    0.04063   3.065  0.00221 ** \naircond        0.13048    0.02407   5.421 6.84e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4397 on 1595 degrees of freedom\nMultiple R-squared:  0.3677,    Adjusted R-squared:  0.3653 \nF-statistic: 154.6 on 6 and 1595 DF,  p-value: < 2.2e-16\n\n\nSkattningen \\(b_1=0.17874\\) av \\(\\beta_1\\): logcost ökar med 0.17874 enheter när logincome ökar med en enhet, och alla andra förklarande variabler hålls konstanta.\nSkattningen \\(b_5\\) av \\(\\beta_5\\): logcost är 0.12453 enheter högre för ett hus med poolfilter, givet alla andra variabler hålls konstanta.\n\n\n💪 Uppgift 3.6\nAlla variabler är signifikanta på 5% nivån (alla p-värden mindre än 0.05).\nAlla variabler utom onlysecondary (p-värde 0.04023>0.01) är också signifikanta på den strängare 1% nivån.\n\n\n💪 Uppgift 3.7\n\npredict(fitmultiple, newdata = data.frame(\n  logincome = median(df$logincome),\n  logrooms = median(df$logrooms),\n  logpeople = median(df$logpeople),\n  onlysecondary = 0,\n  poolfilt = 0,\n  aircond = 0\n  ), \n  interval = \"prediction\")\n\n       fit      lwr      upr\n1 5.741489 4.877802 6.605176"
  },
  {
    "objectID": "assignments/assignment2/Assignment2instructions.html#fördjupningkuriosa",
    "href": "assignments/assignment2/Assignment2instructions.html#fördjupningkuriosa",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Fördjupning/kuriosa",
    "text": "Fördjupning/kuriosa\nEn av mina doktorander, Feng Li, har tillsammans med mig och professor Robert Kohn vid UNSW i Sydney analyserat det här datamaterialet i hans doktorsavhandling2 vid statistiska institutionen vid SU. Feng utvecklade en flexibel regressionsmodell med fördelningar för feltermerna som bl a tillåts ha:\n\nheteroskedastisk varians (dvs olika varians för olika värden på t ex logincome)\ntunga svansar (likt t-fördelningen)\nskevhet\n\nHela artikeln är publicerad som ett kapitel in en bok3, men finns även fritt tillgänglig som ett working paper.\nHär är en bild från avhandlingen, där man ser den prediktiva sannolikhetsfördelningen för cost för olika värden på logrooms, för tre olika varianter av modellen (svarta och röda streckade linjer). Genom att utveckla en modell som kan modellera skevhet behövde vi inte transformera cost innan analysen, vilket blir trevligare att tolka."
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#enkel-regression-för-reklamdata",
    "href": "datorlab/lab7/DatorLab7.html#enkel-regression-för-reklamdata",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Enkel regression för reklamdata",
    "text": "1. Enkel regression för reklamdata\nDatamaterialet reklam.csv innehåller data på n=200 produkters försäljning (sales) i tusentals US dollar och hur mycket (i s k reklamenheter) produkten har marknadsförts i olika reklamkanaler: tv, radio och newspaper. Vi läser in data med kommandot:\n\nreklam = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/reklam.csv')\nhead(reklam)\n\n     tv radio newspaper sales\n1 230.1  37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3  12.0\n4 151.5  41.3      58.5  16.5\n5 180.8  10.8      58.4  17.9\n6   8.7  48.9      75.0   7.2\n\n\nVi börjar med en enkel regressionsmodell med enbart tv som förklarande variabel. Vi utforskar data genom histogram för responsvariabeln sales och scatterplot mot tv.\n\npar(mfrow = c(1,2))\nhist(reklam$sales, col = \"orange\", main = \"\")\nplot(sales ~ tv, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\n\n\n\n\n\n💪 Uppgift 1.1\nSkatta den enkla linjära regressionsmodellen i R:\n\\[\n\\texttt{sales} = \\beta_0 + \\beta_1 \\cdot \\texttt{tv} + \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\noch tolka skattningen av intercept och lutningskoefficient. Vilken skattning av \\(\\sigma_{\\varepsilon}\\) ger R, och hur tolkar du denna?\n\n\n💪 Uppgift 1.2\nTesta om variabeln tv är en signifikant förklarande variabel på 5% signifikansnivå. Ställ upp noll- och alternativhypotes, teststatistiska med fördelning under nollhypotesen. Utför testet med hjälp av formelsamlingen och formulera din slutsats. Du får använda information från R, men du ska ställa upp formeln för teststatistikan och beräkna med den formeln.\n\n\n💪 Uppgift 1.3\nVisa hur R har beräknat p-värdet i regression-utskriften (från summary) genom att göra beräkningen själv med relevant s k p,d,q, eller r-funktion.\n\n\n💪 Uppgift 1.4\nGör en residualanalys med funktionen reg_residuals i sda1-paketet, och kommentera om var och ett av de fyra grundläggande antaganden för populationsmodellen verkar uppfyllda.\n\n\n💪 Uppgift 1.5\nGör en prediktion med 95%-igt prediktionsintervall för sales vid tv=100. [tips: argumentet newdata i predict-funktionen måste vara en dataframe, inte en vektor. Se min kod för lifespan data.]"
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#multipel-regression-för-reklamdata",
    "href": "datorlab/lab7/DatorLab7.html#multipel-regression-för-reklamdata",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Multipel regression för reklamdata",
    "text": "2. Multipel regression för reklamdata\nVi går nu vidare med en multipel regressionsmodell med alla tre förklarande variabler: tv, radio och newspaper. Först en titt på data:\n\npar(mfrow = c(2,2))\nhist(reklam$sales, col = \"orange\", main = \"\")\nplot(sales ~ tv, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\nplot(sales ~ radio, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\nplot(sales ~ newspaper, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\n\n\n\n\n\n💪 Uppgift 2.1\nAnpassa följande multipla regressionsmodell:\n\\[\n\\texttt{sales} = \\beta_0\n+ \\beta_1 \\cdot \\texttt{tv}\n+ \\beta_2 \\cdot \\texttt{radio}\n+ \\beta_3 \\cdot \\texttt{newspaper}\n+ \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\noch tolka skattningen av regressionskoefficienten för tv.\n\n\n💪 Uppgift 2.2\nTesta om variabeln tv är en signifikant förklarande variabel på 5% signifikansnivå. Ställ upp noll- och alternativhypotes, teststatistiska med fördelning under nollhypotesen. Utför testet och formulera din slutsats. Du får använda information från R, men du ska ställa upp formeln för teststatistikan och beräkna den.\nKommentera kortfattat utifrån utskriften om radio och newspaper är signifikanta på 5% signifikansnivå.\n\n\n💪 Uppgift 2.3\nVilken modell, den enkla regressionen eller den multipla, föredrar du? Motivera med relevant R² värde och genom att göra 5-fold korsvalidering med funktionen reg_crossval i sda1-paketet."
  },
  {
    "objectID": "datorlab/lab7/DatorLab7.html#residualanalys-på-simulerade-data",
    "href": "datorlab/lab7/DatorLab7.html#residualanalys-på-simulerade-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Residualanalys på simulerade data",
    "text": "3. Residualanalys på simulerade data\nJag har simulerat fem olika datamaterial simdata1-5 från en linjär regressionsmodell:\n\\[\n\\texttt{y} = \\beta_0\n+ \\beta_1 \\cdot \\texttt{X1}\n+ \\beta_2 \\cdot \\texttt{X2}\n+ \\varepsilon\n\\]\ndär i vissa datamaterial har feltermer \\(\\varepsilon\\) som inte uppfyller alla av de fyra antagandena, och eventuellt kan det också finnas ett icke-linjärt samband mellan någon förklarande variabel och y. Er uppgift är att utföra residualanalys med funktionen reg_residuals i sda1-paketet för att försöka upptäcka vilka antaganden som inte är uppfyllda i respektive datamaterial (Uppgift 3.1-3.5 nedan). Ni bör också titta på plot(simdata1) för varje datamaterial för att upptäcka icke-linjära samband.\nHär är de fem datamaterialen:\n\nsimdata1 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata1.csv')\nsimdata2 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata2.csv')\nsimdata3 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata3.csv')\nsimdata4 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata4.csv')\nsimdata5 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata5.csv')\n\n\n💪 Uppgift 3.1 - simdata1\n\n\n💪 Uppgift 3.2 - simdata2\n\n\n💪 Uppgift 3.3 - simdata3\n\n\n💪 Uppgift 3.4 - simdata4\n\n\n💪 Uppgift 3.5 - simdata5"
  },
  {
    "objectID": "hidden/lab7/DatorLab7solution.html",
    "href": "hidden/lab7/DatorLab7solution.html",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "",
    "text": "Installera paket\n\n\n\nDen här labben förutsätter att följande paket finns installerade:\n\nmosaic\nsda1\n\nsda1 är kursens egna R-paket och måste installeras från GitHub. Det görs genom att först installera paketet remotes och därefter installera kurspaketet:\n\nlibrary(mosaic)\n# install.packages(\"remotes\") # avkommentera första gången\nlibrary(remotes)\n#install_github(\"StatisticsSU/sda1paket\")  # avkommentera första gången\nlibrary(sda1)"
  },
  {
    "objectID": "hidden/lab7/DatorLab7solution.html#introduktion",
    "href": "hidden/lab7/DatorLab7solution.html#introduktion",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "Introduktion",
    "text": "Introduktion\n\nI den här datorlabben kommer ni analysera olika datamaterial med regression. Det första datamaterialet om reklam är verkligt. I Uppgift 3 ska ni analysera datamaterial som är simulerade av mig, från olika populationsmodeller som jag har valt. Det blir ett intressant laboratorium, där ni kan utforska olika aspekter av regression i en kontrollerad miljö. Och även få veta den underliggande populationsmodellen efter att ni gjort labben!\n\n\n\n\n\n\n\nSkapa mapp för labben\n\n\n\nSkapa en mapp Lab7 i din kursmapp SDA1. Ladda ner Quarto-filen för denna lab genom att högerklicka här och välj ‘Spara länk’ eller något likande från menyn som dyker upp. Spara filen i din Lab7 mapp. Öppna Quarto-filen i RStudio och fortsätt med denna laboration direkt i Quarto-dokumentet, där du också fyller i svaren på dina laborationsövningar."
  },
  {
    "objectID": "hidden/lab7/DatorLab7solution.html#enkel-regression-för-reklamdata",
    "href": "hidden/lab7/DatorLab7solution.html#enkel-regression-för-reklamdata",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "1. Enkel regression för reklamdata",
    "text": "1. Enkel regression för reklamdata\nDatamaterialet reklam.csv innehåller data på n=200 produkters försäljning (sales) i tusentals US dollar och hur mycket (i s k reklamenheter) produkten har marknadsförts i olika reklamkanaler: tv, radio och newspaper. Vi läser in data med kommandot:\n\nreklam = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/reklam.csv')\nhead(reklam)\n\n     tv radio newspaper sales\n1 230.1  37.8      69.2  22.1\n2  44.5  39.3      45.1  10.4\n3  17.2  45.9      69.3  12.0\n4 151.5  41.3      58.5  16.5\n5 180.8  10.8      58.4  17.9\n6   8.7  48.9      75.0   7.2\n\n\nVi börjar med en enkel regressionsmodell med enbart tv som förklarande variabel. Vi utforskar data genom histogram för responsvariabeln sales och scatterplot mot tv.\n\npar(mfrow = c(1,2))\nhist(reklam$sales, col = \"orange\", main = \"\")\nplot(sales ~ tv, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\n\n\n\n\n\n💪 Uppgift 1.1\nSkatta den enkla linjära regressionsmodellen i R:\n\\[\n\\texttt{sales} = \\beta_0 + \\beta_1 \\cdot \\texttt{tv} + \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\noch tolka skattningen av intercept och lutningskoefficient. Vilken skattning av \\(\\sigma_{\\varepsilon}\\) ger R, och hur tolkar du denna?\n\nfit = lm(sales ~ tv, data = reklam)\nsummary(fit)\n\n\nCall:\nlm(formula = sales ~ tv, data = reklam)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4438 -1.4857  0.0218  1.5042  5.6932 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.974821   0.322553   21.62   <2e-16 ***\ntv          0.055465   0.001896   29.26   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.296 on 198 degrees of freedom\nMultiple R-squared:  0.8122,    Adjusted R-squared:  0.8112 \nF-statistic: 856.2 on 1 and 198 DF,  p-value: < 2.2e-16\n\n\nIntercept: \\(b_0=6.974821\\) innebär att genomsnittlig försäljning är ca 6.97 tusen dollar om man inte spenderar något alls på tv-reklam (tv=0).\nLutning: \\(b_1=0.055465\\) innebär att varje ökning av tv-reklam för produkten med en reklamenhet leder till ökad försäljning med 0.055465 tusen dollar (dvs 55.465 dollar).\n\\(\\sigma_{\\varepsilon}\\) skattas med ‘Residual standard error: 2.296’. Det är genomsnittliga avvikelsen från regressionlinjen, dvs 2.296 tusen US dollar i genomsnittligt “fel”.\n\n\n💪 Uppgift 1.2\nTesta om variabeln tv är en signifikant förklarande variabel på 5% signifikansnivå. Ställ upp noll- och alternativhypotes, teststatistiska med fördelning under nollhypotesen. Utför testet med hjälp av formelsamlingen och formulera din slutsats. Du får använda information från R, men du ska ställa upp formeln för teststatistikan beräkna alla delar av den formeln.\n\nt_obs = (0.055465-0)/0.001896\nt_crit = qt(0.975, df = 198) # n-2 = 198 df\nabs(t_obs) > t_crit # så förkastar H0. tv är signifikant.\n\n[1] TRUE\n\n\n\n\n💪 Uppgift 1.3\nVisa hur R har beräknat p-värdet i regression-utskriften (från summary) genom att göra beräkningen själv med relevant s k p,d,q, eller r-funktion.\n\n2*(1-pt(t_obs, df = 198)) # 2*P(T>t_obs). Multiplicerar med 2 pga tvåsidigt test\n\n[1] 0\n\n\n\n\n💪 Uppgift 1.4\nGör en residualanalys med funktionen reg_residuals i sda1-paketet, och kommentera om var och ett av de fyra grundläggande antaganden för populationsmodellen verkar uppfyllda.\nMöjligen är antagandet om lika varians (homoskedasticitet) tveksamt, variansen ser ut att öka med fitted values (och tv, se tidigare plott). Kanske lite skev fördelning också. Inga outliers, så inte tunga svansar. Ingen autokorrelation med avseende på observationsordning i alla fall.\n\nfit = lm(sales ~ tv, data = reklam)\nreg_residuals(fit)\n\n\n\n\n\n\n💪 Uppgift 1.5\nGör en prediktion med 95%-iga prediktionsintervall för sales vid tv=100. [tips: argumentet newdata i predict-funktionen måste vara en dataframe, inte en vektor. Se min kod för lifespan data.]\n\npredict(fit, newdata = data.frame(tv = 100), interval = \"prediction\")\n\n      fit      lwr      upr\n1 12.5213 7.979338 17.06326"
  },
  {
    "objectID": "hidden/lab7/DatorLab7solution.html#multipel-regression-för-reklamdata",
    "href": "hidden/lab7/DatorLab7solution.html#multipel-regression-för-reklamdata",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "2. Multipel regression för reklamdata",
    "text": "2. Multipel regression för reklamdata\nVi går nu vidare med en multipel regressionsmodell med alla tre förklarande variabler: tv, radio och newspaper. Först en titt på data:\n\npar(mfrow = c(2,2))\nhist(reklam$sales, col = \"orange\", main = \"\")\nplot(sales ~ tv, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\nplot(sales ~ radio, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\nplot(sales ~ newspaper, data = reklam, pch = 19, cex = 0.7, col = \"steelblue\")\n\n\n\n\n\n💪 Uppgift 2.1\nAnpassa följande multipla regressionsmodell:\n\\[\n\\texttt{sales} = \\beta_0\n+ \\beta_1 \\cdot \\texttt{tv}\n+ \\beta_2 \\cdot \\texttt{radio}\n+ \\beta_3 \\cdot \\texttt{newspaper}\n+ \\varepsilon, \\hspace{1cm} \\varepsilon\\overset{iid}{\\sim}N(0,\\sigma_{\\varepsilon})\n\\]\noch tolka skattningen av regressionskoefficienten för tv.\n\nfitmultiple = lm(sales ~ tv + radio + newspaper, data = reklam)\nsummary(fitmultiple)\n\n\nCall:\nlm(formula = sales ~ tv + radio + newspaper, data = reklam)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3034 -0.8244 -0.0008  0.8976  3.7473 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.6251241  0.3075012  15.041   <2e-16 ***\ntv          0.0544458  0.0013752  39.592   <2e-16 ***\nradio       0.1070012  0.0084896  12.604   <2e-16 ***\nnewspaper   0.0003357  0.0057881   0.058    0.954    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.662 on 196 degrees of freedom\nMultiple R-squared:  0.9026,    Adjusted R-squared:  0.9011 \nF-statistic: 605.4 on 3 and 196 DF,  p-value: < 2.2e-16\n\n\nTolkning: hur sales förändras om tv ökar med en enhet, och radio och newspaper är oförändrade.\n\n\n💪 Uppgift 2.2\nTesta om variabeln tv är en signifikant förklarande variabel på 5% signifikansnivå. Ställ upp noll- och alternativhypotes, teststatistiska med fördelning under nollhypotesen. Utför testet och formulera din slutsats. Du får använda information från R, men du ska ställa upp formeln för teststatistikan och beräkna den.\nKommentera kortfattat utifrån utskriften om radio och newspaper är signfikanta på 5% signifikansnivå.\n\nt_obs = (0.0544458-0)/0.0013752\nt_crit = qt(0.975, df = 196) # n-4 = 196 df\nabs(t_obs) > t_crit # så förkastar H0. tv är signifikant.\n\n[1] TRUE\n\n\nradio är signifikant på alla rimliga nivåer (p-värdet är litet extremt litet, 2e-16). newspaper är inte signifikant på någon rimlig nivå, p-värdet 0.954 är nära 1.\n\n\n💪 Uppgift 2.3\nVilken modell, den enkla regressionen eller den multipla, föredrar du? Motivera med relevant R² värde och genom att göra 5-fold korsvalidering med funktionen reg_crossval i sda1-paketet.\nVariablerna tv och radio är starkt signifikanta och adjusted R² (vilket är det rätta R² måttet för att jämföra modeller) ökar från 0.8112 till 0.9011 när vi lägger till radio och newspaper. Vi skulle antagligen vilja ta bort newspaper, som inte verkar tillföra något.\nEn 5-fold korsvalidering för modellerna ger samma resultat (notera dock att detta svar kan variera en aning pga slumpen).\n\ncvsimple = reg_crossval(sales ~ tv, data = reklam, nfolds = 4)\ncvmultiple = reg_crossval(sales ~ tv + radio + newspaper, data = reklam, nfolds = 4)\nmessage(paste(\"RMSEs på testdata - enkel regression\", cvsimple))\n\nRMSEs på testdata - enkel regression 2.30631128613184\n\nmessage(paste(\"RMSEs på testdata - multipel regression\", cvmultiple))\n\nRMSEs på testdata - multipel regression 1.66968066997548"
  },
  {
    "objectID": "hidden/lab7/DatorLab7solution.html#residualanalys-på-simulerade-data",
    "href": "hidden/lab7/DatorLab7solution.html#residualanalys-på-simulerade-data",
    "title": "Statistik och dataanalys I, 15 hp",
    "section": "3. Residualanalys på simulerade data",
    "text": "3. Residualanalys på simulerade data\nJag har simulerat fem olika datamaterial simdata1-6 från en linjär regressionsmodell:\n\\[\n\\texttt{y} = \\beta_0\n+ \\beta_1 \\cdot \\texttt{X1}\n+ \\beta_2 \\cdot \\texttt{X2}\n+ \\varepsilon\n\\]\ndär i vissa datamaterial har feltermer \\(\\varepsilon\\) som inte uppfyller alla av de fyra antagandena, och eventuellt kan det också finnas ett icke-linjärt samband mellan någon förklarande variabel och y. Er uppgift är att utföra residualanalys med funktionen reg_residuals i sda1-paketet för att försöka upptäcka vilka antaganden som inte är uppfyllda i respektive datamaterial (Uppgift 3.1-3-5 nedan). Ni bör också titta på plot(simdata1) för varje datamaterial för att upptäcka icke-linjära samband.\nHär är de fem datamaterialen:\n\nsimdata1 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata1.csv')\nsimdata2 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata2.csv')\nsimdata3 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata3.csv')\nsimdata4 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata4.csv')\nsimdata5 = read.csv(file = 'https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab7/simdata5.csv')\n\n\n💪 Uppgift 3.1 - simdata1\n\nLinjärt samband? Inga tydliga mönster i residualerna mot fitted values. Så OK!\nOberoende \\(\\varepsilon\\)? Residualerna verkar oberoende, i alla fall med avseende på observationsnumret. OK!\nSamma varians? residualerna har en rejäl outlier, men verkar inte har andra mönster i residualerna plottade mot fitted value. Variansen verkar konstant. OK!\nNormalfördelade \\(\\varepsilon\\)? har en rejäl outlier och det finns också tydliga outliers i QQ-ploten i övre vänstra hörnet (avvikelser från 45-graders linjen). Inte OK.\n\n\nplot(simdata1, pch = 19, col = \"steelblue\")\n\n\n\n\n\nreg_residuals(lm(y ~ X1 + X2, data = simdata1))\n\n\n\n\n\n\n💪 Uppgift 3.2 - simdata2\n\nLinjärt samband? Inga tydliga mönster i residualerna mot fitted values. Så OK!\nOberoende \\(\\varepsilon\\)? Residualerna verkar oberoende, i alla fall med avseende på observationsnumret. OK!\nSamma varians? Variansen verkar öka med fitted values. Inte OK.\nNormalfördelade \\(\\varepsilon\\)? Det finns några observationer som kan se ut som outliers, t ex men är nog inte det om man tar hänsyn till att variansen inte är konstant. För de x-värden där variansen är stor ska vi också förväntas oss stora \\(\\varepsilon\\). Dessa är alltsp inte outliers, om man tar hänsyn till deras (större) varians. antagligen OK!\n\n\nplot(simdata2, pch = 19, col = \"steelblue\")\n\n\n\n\n\nreg_residuals(lm(y ~ X1 + X2, data = simdata2))\n\n\n\n\n\n\n💪 Uppgift 3.3 - simdata3\n\nLinjärt samband? Inga tydliga mönster i residualerna mot fitted values. Så OK!\nOberoende \\(\\varepsilon\\)? Residualerna verkar oberoende, i alla fall med avseende på observationsnumret. OK!\nSamma varians? Variansen verkar inte öka med fitted values. Se konstant ut. OK!\nNormalfördelade \\(\\varepsilon\\)? Inga outliers i sikte. OK!\n\n\nplot(simdata3, pch = 19, col = \"steelblue\")\n\n\n\n\n\nreg_residuals(lm(y ~ X1 + X2, data = simdata3))\n\n\n\n\n\n\n💪 Uppgift 3.4 - simdata4\n\nLinjärt samband? Inga tydliga mönster i residualerna mot fitted values. Så OK!\nOberoende \\(\\varepsilon\\)? Residualerna verkar inte oberoende, det finns tydliga svängningar upp och ner med avseende på observationsnumret. Typiskt tidsseriemönster. Om en residual är negativ så är det sannolikt att flera efterföljande residualer också är negativa. Och vice versa. Inte OK.\nSamma varians? Variansen verkar inte öka med fitted values. Se konstant ut. OK!\nNormalfördelade \\(\\varepsilon\\)? Inga outliers i sikte. OK!\n\n\nplot(simdata4, pch = 19, col = \"steelblue\")\n\n\n\n\n\nreg_residuals(lm(y ~ X1 + X2, data = simdata4))\n\n\n\n\n\n\n💪 Uppgift 3.5 - simdata5\n\nLinjärt samband? Tydliga icke-linjära mönster med avseende på X1. Inte OK.\nOberoende \\(\\varepsilon\\)? Residualerna verkar inte oberoende, men det beror antagligen på att den linjära modellen inte har lyckats fånga upp det icke-linjära (kvadratiska sambandet).\nSamma varians? Variansen verkar inte öka med fitted values. Se konstant ut. OK!\nNormalfördelade \\(\\varepsilon\\)? Inga outliers i sikte. OK!\n\n\nplot(simdata5, pch = 19, col = \"steelblue\")\n\n\n\n\n\nreg_residuals(lm(y ~ X1 + X2, data = simdata5))"
  }
]