---
title: "Statistik och dataanalys I, 15 hp "
subtitle: "Datorlaboration 4"
author: 
  - Matias Quiroz
date: last-modified
format: 
  html:
    self-contained: true
toc: true
execute:
  error: false
language: 
  title-block-author-single: " "
toc-title-document: "Inneh친ll"
crossref-fig-title: "Figur"
theme: Superhero
title-block-banner-color: Primary
title-block-published: "Publicerad"
callout-warning-caption: "Varning"
callout-note-caption: "Observera"
callout-tip-caption: "Tips"
editor: visual
---


::: callout-warning
Den h칛r labben f칬ruts칛tter att f칬ljande paket finns installerade:

-   `mosaic`

-   `corrplot`

Paket kan installeras via kommandot `install.packages('packagename')`, d칛r `'packagename'` 칛r namnet p친 paketet, t.ex `'mosaic'`.
:::

## Introduktion

> I den h칛r datorlabben kommer vi att beskriva samband mellan tv친 numeriska variabler via punktdiagram och korrelation. Vi kommer ocks친 att modellera samband via b친de enkel och multiple linj칛r regression och l칛ra oss tolka resultaten samt modellvalidering. Vi kommer att l칛ra oss prediktion i linj칛r regression och hur man kan genomf칬ra modellval genom korsvalidering. N칛r data inte uppvisar ett linj칛rt samband ska vi l칛ra oss hur man kan transformera data och anpassa en icke-linj칛r regression. Icke-linj칛r regression 칛r sv친rare att tolka, men har klart b칛ttre prediktionsf칬rm친ga om det finns icke-linj칛ra samband mellan variabler. F칬r de studenterna som 칛r intresserade s친 finns det ett extra avsnitt som dyker lite djupare i R.

#### 游눩 Uppgift 0.1

Se till att paketen ovan 칛r installerade innan du forts칛tter med resten.

#### 游눩 Uppgift 0.2

Skapa en mapp `Lab4` i din kursmapp SDA1 (s친som ni gjorde i Lab 1). Ladda ner Quarto-filen f칬r denna lab genom att h칬gerklicka [h칛r](https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab4/DatorLab4.qmd) och v칛lj 'Spara l칛nk' eller n친got likande fr친n menyn som dyker upp. Spara filen i din nya `Lab4` mapp. 칐ppna Quarto-filen i RStudio. Du kan nu forts칛tta med denna laboration direkt i Quarto-dokumentet, d칛r du ocks친 fyller i svaren p친 dina laborations칬vningar. Du kan allts친 l칛mna den h칛r webbsidan nu och forts칛tta arbetet i RStudio.

V칛l inne i RStudio med 칬ppnat Quarto-dokument i 'Editor' kan ni g친 칬ver till 'Source mode' genom att klicka p친 'Source' i det v칛nstra h칬rnet av din 'Editor'. Source mode 칛r detaljerat och bra att skriva kod i eftersom man har full kontroll p친 dokumentet, men det 칛r sv친rt att f친 en 칬versikt av dokumentet. Prova nu att g친 칬ver till 'Visual mode' genom att klicka p친 'Visual' i det v칛nstra h칬rnet av din 'Editor'. Vi rekommenderar att ni mestadels arbetar i Visual mode, men att g친 칬ver till Source mode n칛r man verkligen vill f친 till n친gon detalj som 칛r sv친r att 칛ndra i Visual mode. 췂

#### 游눩 Uppgift 0.3

Klicka p친 knappen Render i Editor-f칬nstret f칬r att **kompilera** filen till en webbsida (html). Webbsidan kommer antingen att visas i Viewer-f칬nstret i RStudio eller i webbl칛saren p친 din dator. Om din webbsida visas i webbl칛saren rekommenderar vi att du 칛ndrar inst칛llningarna i RStudio s친 webbsidan visas i Viewer-f칬nstret. Du st칛ller in detta p친 menyn [T]{.underline}ools/[G]{.underline}lobal Options... och sen v칛ljer du *Viewer Pane* vid *Show output preview in*:

![](https://github.com/StatisticsSU/SDA1/raw/main/datorlab/lab2/QuartoInViewerPane.png){fig-align="center" width="333"}

#### 游눩 Uppgift 0.4

Quarto s칛kerst칛ller att man befinner sig i korrekt arbetsmapp n칛r koden i dokumentet exekveras. Med korrekt arbetsmapp menas den mappen ni sparade `.qmd` filen i. Vill du komma 친t dataseten via `load()` kommandot **m친ste dataseten vara sparade i samma mapp**.

Ett vanligt arbetss칛tt 칛r att man jobbar i RStudio i en separat `.R` fil, d칛r man kan testa att k칬ra kod innan den kopieras 칬ver till Quarto dokumentet. Den `.R` filen kommer inte att ha samma 'working directory' som Quarto filen. Du m친ste d친 anv칛nda `setwd()` funktionen i `.R` filen f칬r att st칛lla in 'working directory'. Notera att man ocks친 v칛lja att skriva kod i `Console` som finns l칛ngst ner i RStudio. D칛r m친ste du ocks친 st칛lla in r칛tt 'working directory'. Det 칛r inte rekommenderat att anv칛nda `Console` eftersom koden inte sparas d칛r. Du kanske kommer p친 n친got j칛ttesmart som du gl칬mmer att kopiera 칬ver till Quarto dokumentet och kan senare inte hitta det du skrev.

::: callout-note
### RStudios Editor 칛ndras beroende p친 vilken sorts fil du har 칬ppen

Notera att ikonerna i Editor 칛r annorlunda n칛r du har ett Quarto-dokument 칬ppet j칛mf칬rt med tidigare n칛r vi hade en fil med ren R-kod (dvs en `.R` fil) 칬ppen.
:::

Skapa en ny `.R` som du d칬per till `Lab4_test_code.R` och sparar i din `Lab 4` mapp. St칛ll in 'working directory' till den nya mappen genom att f칬lja anvisningarna fr친n [Lab 1](https://statisticssu.github.io/SDA1/datorlab/lab1/DatorLab1.html#st%C3%A4lla-in-arbetsmappen-working-directory-i-r).

#### 游눩 Uppgift 0.5

Ladda ner `CAPM_data.RData` ([h칛r](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/CAPM_data.RData?raw=true)), `FevChildren.RData` ([h칛r](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true)), `RealEstate.RData` ([h칛r](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/RealEstate.RData?raw=true)), och `Penguins.RData` ([h칛r](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/Penguins.RData?raw=true)). Filerna kommer automatiskt att sparas ner, oftast i download mappen p친 datorn ni sitter vid. Kopiera 칬ver filerna till `Lab4` mappen ni skapade ovan.

Som vi gick igenom i Lab 3 finns det olika s칛tt att l칛sa in `.RData` filer genom `load()` funktionen. Ett s칛tt 칛r att skriva t.ex `load("FevChildren.RData")`. Notera att om du g칬r detta i `Lab4_test_code.R` f칬ruts칛tter det att `FevChildren.RData` ligger i den arbetsmappen man angivit genom `setwd()` funktionen. Ett annat s칛tt att ladda in en `.RData` fil 칛r att l칛sa in den direkt fr친n webben med en kombination av `load()` funktionen och `url()` funktionen.


::: {.cell}

```{.r .cell-code}
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true"))
FevChildren_from_URL <- FevChildren
```
:::


Argumentet till `url()` funktionen 칛r en str칛ng som inneh친ller l칛nken till kurshemsidans git repository d칛r `FevChildren.RData` finns lagrad. I raden efter har vi sparat dataframen i en variabel som heter `FevChildren_from_URL` s친 att du i n칛sta uppgift kan j칛mf칬ra mot den du l칛ser in fr친n din lokala fil som du sparade ovan i i `Lab3` mappen.

#### 游눩 Uppgift 0.6

Anv칛nd `load()` funktionen (utan `url()` funktionen) f칬r att l칛sa in `FevChildren.RData` lokalt fr친n din dator. J칛mf칬r den lokalt inl칛sta filen med den du l칛ste in fr친n webben (finns sparad i `FevChildren_from_URL`).


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


::: callout-tip
F칬r att j칛mf칬ra dataseten h칛r r칛cker det att anv칛nda `str()` och `head()`.
:::

Det 칛r viktigt att ni vet hur man l칛ser in `.RData` filer lokalt. Det kan vara s친 att github 칛r tillf칛lligt nere, eller att ni tempor칛rt jobbar utan tillg친ng till internet. I resten av labben s친 l칛ses filerna in fr친n webben, men nu vet ni hur ni kan g칬ra om webben av n친gon anledning skulle vara nere.

## 1. Samband mellan tv친 numeriska variabler

**Numeriska variabler** 칛r variabler vars utfall 칛r numeriska v칛rden som har betydelse. En **kategorisk variabel** kan visserligen vara kodad som ett numeriskt v칛rde, men v칛rdet 칛r godtyckligt. Ett exempel 칛r variabeln `smoking` i `FevChildren.RData`, d칛r ja 칛r kodat som 1 och nej kodat som 0. Vi skulle lika g칛rna ha kodat ja som 0 och nej som 1. Eller till och med ja som -1 och nej som 1. Det 칛r s친ledes viktigt att f칬rst친 att 칛ven kategoriska variabler kan ha numeriska utfall, men de r칛knas inte som numeriska variabler f칬r det.

Ett vanligt sambandsm친tt mellan **tv친 numeriska variabler** 칛r korrelation. Korrelation m칛ter det linj칛ra sambandet mellan variablerna. Stickprovskorrelationen r칛knas enligt $$r_{xy}=\frac{\sum z_xz_y}{n-1},$$

d칛r $z_x$ och $z_y$ 칛r z-v칛rden f칬r $x$ och $y$, respektive. Som vanligt r칛knas dessa som $$z_x=\frac{x-\overline{x}}{s_x}\,\,\text{och} \,\,z_y=\frac{y-\overline{y}}{s_y},$$ d칛r $\overline{x}$ och $\overline{y}$ 칛r stickprovsmedelv칛rden samt $s_x$ och $s_y$ 칛r stickprovsstandardavvikelser. Boken anv칛nder notationen $r$ ist칛llet f칬r $r_{xy}$ i ekvationen ovan. Notationen $r_{xy}$ betonar att man r칛knar korrelationen mellan de tv친 variablerna $x$ och $y$.

I Lab 3 introducerades datasetet `CAPM_data.RData`, som inneh친ller tidsserier 칬ver m친nadsavkastningar f칬r olika finansiella tillg친ngar samt makroekonomiska variabler. [Lab 3](https://statisticssu.github.io/SDA1/datorlab/lab3/DatorLab3.html#tidsserier) inneh친ller detaljerad information om datasetet `CAPM_data.RData`. Vi ska illustrera korrelationsbegreppet med hj칛lp av det h칛r datasetet, men det 칛r viktigt att f칬rst친 att **korrelation 칛r ett allm칛nt m친tt f칬r det linj칛ra sambandet mellan tv친 variabler**, oavsett om variablerna 칛r tidsserier eller inte! Den enda f칬ruts칛ttningen f칬r att ber칛kna korrelationen 칛r att variablerna 칛r numeriska.

L친t oss r칛kna korrelationen mellan tv친 tillg친ngar, till exempel `IBM` och `CITCRP` med hj칛lp av funktionen `cor()` i `mosaic`-paketet.


::: {.cell}

```{.r .cell-code}
suppressMessages(library(mosaic))
```

::: {.cell-output .cell-output-stderr}
```
Warning: package 'mosaic' was built under R version 4.2.2
```
:::

```{.r .cell-code}
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/CAPM_data.RData?raw=true"))
cor(IBM ~ CITCRP, data = CAPM)
```

::: {.cell-output .cell-output-stdout}
```
[1] 0.4237027
```
:::
:::


Vi ser att korrelationen 칛r positiv och har ett v칛rde runt 0.43.

#### 游눩 Uppgift 1.1

Ber칛kna den omv칛nda korrelationen, dvs korrelationen `CITCRP` och `IBM`. Kan du f칬rklara varf칬r svaret 칛r samma som ovan?

::: callout-tip
Betrakta formeln f칬r $r_{xy}$ ovan. Vad h칛nder om man ist칛llet r칛knar $r_{yx}$, dvs kastar om ordningen p친 $x$ och $y$?
:::


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Eftersom korrelation endast beskriver ett linj칛rt samband, antas det att variablerna f칬rh친ller sig approximativt linj칛rt till varandra f칬r att den ska anses vara ett l칛mpligt sambandsm친tt. Vi kan g칬ra ett punktdiagram f칬r att validera antagandet.


::: {.cell}

```{.r .cell-code}
plot(IBM ~ CITCRP, data = CAPM, col = "cornflowerblue")
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-5-1.png){width=672}
:::
:::


Vi ser inga tydliga avvikelser fr친n det linj칛ra antagandet och s친ledes 칛r korrelationen ett rimligt m친tt p친 sambandet. Figuren visar ett positivt samband mellan variablerna.

Antag att vi vill r칛kna den parvisa korrelationen mellan flera variabler. Vi skulle kunna repetera koden `cor(IBM ~ CITCRP, data = CAPM)`, d칛r vi byter ut `IBM` och `CITCRP` mot alla parvisa kombinationer av de variablerna vi 칛r intresserade utav. Mer elegant (och mindre tidskr칛vande!) s친 kan vi skapa en s친kallad korrelationsmatris. F칬r att illustrera korrelationsmatrisen, l친t oss betrakta f칬ljande variabler: `MARKET`, `RKFREE`, `WEYER`, `BOISE`, `CONED`, `CITCRP` `DATGEN`, `DEC`,`DELTA` och `CPI`. Alla dessa f칬rutom `MARKET`, `RKFREE` och `CPI` 칛r m친nadsavkastningar f칬r stora b칬rsnoterade f칬retag. `MARKET` 칛r marknadens m친nadsavkastning, `RKFREE` 칛r avkastningen p친 en riskfri tillg친ng (statsobligationsr칛nta) och `CPI` 칛r konsumentprisindex. L친t oss skapa en ny dataframe d칛r vi enbart beh친ller variablerna av instresse.


::: {.cell}

```{.r .cell-code}
CAPM_10_variables <- CAPM[, c("MARKET", "RKFREE", "WEYER", "BOISE", "CONED", "CITCRP", "DATGEN", "DEC", "DELTA", "CPI")]
head(CAPM_10_variables)
```

::: {.cell-output .cell-output-stdout}
```
  MARKET  RKFREE  WEYER  BOISE  CONED CITCRP DATGEN    DEC  DELTA   CPI
1 -0.045 0.00487 -0.116 -0.079 -0.079 -0.115 -0.084 -0.100 -0.028 166.7
2  0.010 0.00494 -0.135  0.013 -0.003 -0.019 -0.097 -0.063 -0.033 167.1
3  0.050 0.00526  0.084  0.070  0.022  0.059  0.063  0.010  0.070 167.5
4  0.063 0.00491  0.144  0.120 -0.005  0.127  0.179  0.165  0.150 168.2
5  0.067 0.00513 -0.031  0.071 -0.014  0.005  0.052  0.038 -0.031 169.2
6  0.007 0.00527  0.005 -0.098  0.034  0.007 -0.023 -0.021  0.023 170.1
```
:::
:::


Vi kan nu skapa och spara korrelationsmatrisen i en variabel `correlation_matrix_CAPM` genom `cor()`. Notera att input till funktionen 칛r den nya dataframen vi har skapat och att ingen formula-syntax anv칛nds.


::: {.cell}

```{.r .cell-code}
correlation_matrix_CAPM <- cor(CAPM_10_variables)
round(correlation_matrix_CAPM, 3)
```

::: {.cell-output .cell-output-stdout}
```
       MARKET RKFREE  WEYER  BOISE CONED CITCRP DATGEN    DEC  DELTA    CPI
MARKET  1.000 -0.100  0.656  0.652 0.124  0.564  0.551  0.581  0.349 -0.060
RKFREE -0.100  1.000 -0.142 -0.176 0.057  0.001 -0.102 -0.139  0.007 -0.456
WEYER   0.656 -0.142  1.000  0.751 0.158  0.540  0.481  0.590  0.490  0.067
BOISE   0.652 -0.176  0.751  1.000 0.209  0.590  0.534  0.552  0.454  0.059
CONED   0.124  0.057  0.158  0.209 1.000  0.269  0.096  0.108  0.092  0.054
CITCRP  0.564  0.001  0.540  0.590 0.269  1.000  0.533  0.489  0.397  0.090
DATGEN  0.551 -0.102  0.481  0.534 0.096  0.533  1.000  0.576  0.330 -0.048
DEC     0.581 -0.139  0.590  0.552 0.108  0.489  0.576  1.000  0.429  0.029
DELTA   0.349  0.007  0.490  0.454 0.092  0.397  0.330  0.429  1.000 -0.034
CPI    -0.060 -0.456  0.067  0.059 0.054  0.090 -0.048  0.029 -0.034  1.000
```
:::
:::


Ovan har `round()` funktionen anv칛nts f칬r avrunda till tre decimaler s친 att utskriften blir tydligare. Korrelationsmatrisen anger korrelationen f칬r alla parvisa kombinationer av variabeln. Exempelvis, om vi kollar p친 rad 4 och kolumn 7 s친 친terfinns korrelationen mellan `BOISE` och `DATGEN` i den cellen, som har v칛rdet 0.534. Korrelationsmatrisen 칛r symmetrisk: om vi kollar p친 rad 7 och kolumn 4 hittar vi ocks친 v칛rdet 0.534, eftersom korrelationen inte tar h칛nsyn till ordningen.

#### 游눩 Uppgift 1.2

Varf칬r 칛r diagonalelementen i korrelationsmatrisen 1?

#### 游눩 Uppgift 1.3

Anv칛nd `cor()` med formula-syntax f칬r att ber칛kna korrelationen mellan `DELTA` och `DEC`. St칛m av att resultatet 칛r densamma som korrelationsmatrisen visar (t칛nk p친 att vi avrundade, s친 resultaten kommer inte st칛mma exakt).


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Informationen i en korrelationsmatris kan vara sv친r att utl칛sa pga alltf칬r m친nga siffror. En korrelationsplot illustrerar korrelationerna med f칛rgskalor och 칛r mycket enklare att utl칛sa. Funktionen `corrplot()` fr친n `corrplot`-paketet tar en korrelationsmatris som argument f칬r att skapa plotten. Vi skapade korrelationsmatrisen ovan (`correlation_matrix_CAPM`).


::: {.cell}

```{.r .cell-code}
suppressMessages(library(corrplot))
```

::: {.cell-output .cell-output-stderr}
```
Warning: package 'corrplot' was built under R version 4.2.2
```
:::

```{.r .cell-code}
corrplot(correlation_matrix_CAPM)
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-9-1.png){width=672}
:::
:::


#### 游눩 Uppgift 1.4

Svara p친 f칬ljande fr친gor:

-   Hitta tv친 variabler som har en svag negativ korrelation p친 ungef칛r -0.2. Anv칛nd `plot()` f칬r att plotta variablerna mot varandra.

-   Hitta tv친 variabler som har en svag positiv korrelation p친 ungef칛r 0.2. Anv칛nd `plot()` f칬r att plotta variablerna mot varandra.

-   Hitta de tv친 variabler som har starkast negativ korrelation. 츿r det rimligt att dessa variabler 칛r negativt korrelerade?


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Bara f칬r att en korrelation mellan tv친 variabler 칛r n칛ra noll betyder det inte att det inte finns n친got samband. L친t oss illustrera detta med ett exempel d칛r vi anv칛nder slumptal f칬r att skapa tv친 variabler $x$ och $y$ som har ett icke-linj칛rt samband, men en korrelation som 칛r n칛ra noll. Simulering av slumptal tas upp i andra delen av kursen. Ni beh칬ver inte f칬rst친 koden nu, men det 칛r viktigt att ni f칬rst친r slutsatsen som snart att presenteras.


::: {.cell}

```{.r .cell-code}
set.seed(10) # Same random numbers generated every run
x <- rnorm(n = 1000, sd = 1) # Simulate a normal variable with standard deviation 1
y <- -5*x^2 + rnorm(n = 1000)
plot(x, y, col = "cornflowerblue")
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-11-1.png){width=672}
:::
:::


Det finns ett uppenbart kvadratiskt samband $y$ och $x$. L친t oss ber칛kna korrelationen.


::: {.cell}

```{.r .cell-code}
cor(x, y)
```

::: {.cell-output .cell-output-stdout}
```
[1] -0.003297157
```
:::
:::


Korrelationen 칛r n칛stan noll! Slutsatsen 칛r att om vi bara hade hade fokuserat p친 korrelationen, utan att plotta $y$ mot $x$, s친 hade vi allts친 missat detta uppenbara samband.

I korrelationsplotten ovan 칛r det m친nga korrelationer som 칛r n칛ra noll och vi m친ste f칬rs칛kra oss om att vi inte har missat n친gra uppenbara icke-linj칛ra samband. Vi kan plotta alla parvisa kombinationer av de variablerna vi 칛r intresserade utav med hj칛lp av `plot()` funktionen. Mer elegant (och mindre tidskr칛vande!) s친 kan vi anv칛nda funktionen `pairs()` som g칬r punktdiagram av alla parvisa kombinationer av variablerna i en dataframe.


::: {.cell}

```{.r .cell-code}
pairs(CAPM_10_variables, col = "cornflowerblue")
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-13-1.png){width=672}
:::
:::


#### 游눩 Uppgift 1.5

Finns det uppenbara icke-linj칛ra samband f칬r de variablerna som hade n칛ra noll korrelation enligt korrelationsplotten?

#### 游눩 Uppgift 1.6

Studera plottarna f칬r variablerna som var korrelerade enligt korrelationsplotten. Kan ni utl칛sa tecknena p친 korrelationerna (positiva eller negativa) utifr친n punktdiagrammen?

## 2. Enkel linj칛r regression

En linj칛r regression 칛r anv칛ndbar f칬r att beskriva det linj칛ra sambandet mellan en responsvariabel $y$ och en f칬rklarande variabel $x$. Med en anpassad linj칛r regressionsmodell kan man, likt Avsnitt 1, ber칛kna korrelationen mellan $y$ och $x$. Men en linj칛r regressionsmodell erbjuder mer 칛n s친. Vi kan t.ex kvantifiera hur en f칬r칛ndring i $x$ 칛r associerad med en f칬r칛ndring i $y$. Och kanske viktigast (och roligast!) av allt: vi kan givet ett nytt $x$ prediktera det genomsnittliga v칛rdet p친 $y$.

L친t oss illustrera enkel linj칛r regression med hj칛lp av datasetet `FevChildren.RData` som illustrerades i [Lab 3](https://statisticssu.github.io/SDA1/datorlab/lab3/DatorLab3.html#samband-mellan-en-numerisk-och-en-kategorisk-variabel). Vi anpassar en enkel linj칛r regression med responsvariabel utandningsvolymen (`fev`) och f칬rklarande variabel l칛ngd (`height`) med hj칛lp av funktionen `lm()` som st친r f칬r linear model och sparar resultatet i en variabel vi d칬per till `lm_fev_vs_height`.


::: {.cell}

```{.r .cell-code}
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab3/FevChildren.RData?raw=true"))
lm_fev_vs_height <- lm(fev ~ height, data = FevChildren)
```
:::


Vi ser ovan att `lm()` funktionen anv칛nder samma alternativa formula-syntax som `plot()` funktionen, dvs av typen `y ~ x`.

::: {.callout-note icon="false"}
## Extra material f칬r de nyfikna studenterna (detta avsnitt kan skippas)

Funktionen `lm()` returnerar ett **objekt** som 칛r en instans (en realiserad kopia) av **klass** `lm`. En klass 칛r enkelt beskrivet en abstrakt kodmall d칛r det anges vilka variabler som lagras i objektet, s친 kallade **attribut**, och vilka funktioner som g친r att anv칛nda p친 objektet. Vi kan se klasstypen genom att anropa `class()` funktionen.


::: {.cell}

```{.r .cell-code}
class(lm_fev_vs_height)
```

::: {.cell-output .cell-output-stdout}
```
[1] "lm"
```
:::
:::


Inneh친llet i objektet kan visas med anropet `str(lm_fev_vs_height)`, som visar objektets struktur p친 ett kompakt s칛tt.

#### 游눩 Extra Uppgift 1

Anv칛nd `str()` enligt ovan f칬r att f친 en 칬versikt av inneh친llet i objektet `lm_fev_vs_height`. K칛nner du igen n친gra av namnen (som f칬ljer efter `$`-tecknet) fr친n f칬rel칛sningarna?


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Vi har st칬tt p친 `$`-tecknet i samband med att vi h칛mtade ut en variabel fr친n en dataframe i [Lab 3](https://statisticssu.github.io/SDA1/datorlab/lab3/DatorLab3.html#tidsserier): Om `my_data` 칛r en dataframe som inneh친ller en variabel `x` kommer vi 친t den via `my_data$x`. Vi 친terkommer snart till `$`-tecknet, men l친t oss f칬rst dyka lite djupare i R.

Vi n칛mnde inte det i Lab 3, men `my_data` 칛r ocks친 ett objekt! Den 칛r en instans av klassen `dataframe`. **I sj칛lva verket 칛r allt i R objekt!** R 칛r vad man kallar ett objektorienterat programmeringsspr친k. Allt vi skapar i R, vare sig det 칛r en variabel, funktion eller till och med en tabell, 칛r objekt, dvs instanser av olika klasser.


::: {.cell}

```{.r .cell-code}
x <- -3
class(x)
```

::: {.cell-output .cell-output-stdout}
```
[1] "numeric"
```
:::

```{.r .cell-code}
f <- function(x) {x^2} # Simple function that squares a number.
class(f)
```

::: {.cell-output .cell-output-stdout}
```
[1] "function"
```
:::

```{.r .cell-code}
t <- tally(age.group ~ smoking, data = FevChildren)
class(t)
```

::: {.cell-output .cell-output-stdout}
```
[1] "table"
```
:::
:::


#### 游눩 Extra Uppgift 2

Anv칛nd funktionen 'f()' ovan f칬r att r칛kna ut $3^2$ och spara resultatet i en variabel `y`. Vilken klass 칛r objektet `y` en instans av? Fundera p친 svaret innan ni tar reda p친 det med hj칛lp av funktionen `class()`.


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Det g친r att dyka djupare i Rs objektorienterade v칛rld, men vi l친ter bli och h칛nvisar ist칛llet till institutionens [Introduktionskurs i R-programmering](https://www.su.se/sok-kurser-och-program/st1901-1.617486).

칀ter till anv칛ndandet av `$`-tecknet. Vi anv칛nder `$`-tecknet f칬r att h칛mta ett objekts attribut (en variabel som lagras i objektet). Funktionen `attributes()` listar namnen p친 de olika attributen.


::: {.cell}

```{.r .cell-code}
attributes(lm_fev_vs_height)
```

::: {.cell-output .cell-output-stdout}
```
$names
 [1] "coefficients"  "residuals"     "effects"       "rank"         
 [5] "fitted.values" "assign"        "qr"            "df.residual"  
 [9] "xlevels"       "call"          "terms"         "model"        

$class
[1] "lm"
```
:::
:::


Exempelvis s친 lagras minsta kvadratskattningarna i attributet `coefficients`.


::: {.cell}

```{.r .cell-code}
lm_fev_vs_height$coefficients
```

::: {.cell-output .cell-output-stdout}
```
(Intercept)      height 
-5.74145229  0.05380877 
```
:::
:::


#### 游눩 Extra Uppgift 3

G칬r ett histogram f칬r residualerna f칬r den anpassade modellen ovan.


::: {.cell}

```{.r .cell-code}
# Write your code here.
```
:::

:::

Funktionen `lm()` returnerar ett s친kallat objekt (som vi sparat i variabeln `lm_fev_vs_height`) av klass `lm` som f칬rklaras i extra materialet ovan. Vi beh칬ver inte veta detaljerna, men en viktig sak att veta 칛r att det finns m친nga anv칛ndbara funktioner vi kan applicera p친 v친rt objekt. En s친dan funktion 칛r `summary()` som skriver ut resultaten fr친n regressionen i ett snyggt format.


::: {.cell}

```{.r .cell-code}
summary(lm_fev_vs_height)
```

::: {.cell-output .cell-output-stdout}
```

Call:
lm(formula = fev ~ height, data = FevChildren)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.76006 -0.25417  0.00064  0.23903  2.10393 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -5.741452   0.210370  -27.29   <2e-16 ***
height       0.053809   0.001337   40.25   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.4327 on 604 degrees of freedom
Multiple R-squared:  0.7284,	Adjusted R-squared:  0.7279 
F-statistic:  1620 on 1 and 604 DF,  p-value: < 2.2e-16
```
:::
:::


Efter Del 2 av kursen kommer ni k칛nna igen i princip allt i utskriften ovan. Det vi har g친tt p친 Del 1 칛r:

-   `Residuals`: Visar f칬rdelningsm친tten f칬r residualerna, samt minsta och st칬rsta v칛rde.

-   `Coefficients`: `Estimate` kolumnen visar minsta kvadratskattningarna. `Intercept` och `height` betecknar vi med, respektive, $b_0$ och $b_1$ p친 f칬rel칛sningarna.

-   `Residual standard error`: Residualernas standardavvikelse som vi betecknar med $s_e$ p친 f칬rel칛sningarna.

-   `Multiple R-squared`: R-kvadrat som vi betecknar med $R^2$ p친 f칬rel칛sningarna.

-   `Adjusted R-squared`: Justerat R-kvadrat som vi betecknar med $R_{\mathrm{adj}}^2$ p친 f칬rel칛sningarna.

L친t oss tolka resultaten ovan. 72.84% av variationen i forcerad utadningsvolym f칬rklaras av variabeln l칛ngd. Minsta kvadratanpassningen 칛r $$\widehat{fev} = b_0 + b_1height =-5.741 + 0.054height.$$ Tolkningen f칬r $b_0=-5.741$ 칛r den predikterade genomsnittliga forcerade utandningsvolymen f칬r barn och ungdomar som 칛r 0 cm l친nga, vilket inte 칛r meningsfullt. Vi kan inte g칬ra en kausal tolkning f칬r $b_1$ eftersom det inte 칛r s친 att l칛ngden medf칬r b칛ttre eller s칛mre lugnkapacitet. Ist칛llet s칛ger vi att barn och ungdomar som 칛r 1 cm l칛ngre tenderar att i genomsnitt ha $b_1=0.054$ fler enheter forcerad utandningsvolym (칛n de som 칛r 1 cm kortare). Vi kan ocks친 anv칛nda oss av $b_1$ f칬r att till exempel s칛ga att barn och ungdomar som 칛r 10 cm l칛ngre tenderar att ha $10\cdot b_1 = 0.54$ fler enheter forcerad utandningsvolym (칛n de som 칛r 10 cm kortare).

V친rt dataset inneh친ller forcerad utandningsvolym och l칛ngd hos 606 individuella barn och ungdomar. V친r anpassade modell ger oss 606 prediktioner av de genomsnittliga forcerade utandningsvolymerna, dvs en prediktion $\hat{y}_i$ (`fev`) f칬r varje $x_i$ (`height`) i datasetet. Dessa kan f친s genom funktionen `predict()`. L친t oss plotta data tillsammans med de predikterade v칛rden i samma figur med hj칛lp av funktionen `lines()` som anv칛ndes i [Lab 3](https://statisticssu.github.io/SDA1/datorlab/lab3/DatorLab3.html#tidsserier). Vi anv칛nder ocks친 funktionen `abline()` som ritar den r칛ta linjen (minsta kvadratanpassningen).


::: {.cell}

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue", ylim = c(0, 7))
y_hat <- predict(lm_fev_vs_height)
head(y_hat)
```

::: {.cell-output .cell-output-stdout}
```
       1        2        3        4        5        6 
2.048981 3.484061 1.707295 1.502284 2.048981 2.595678 
```
:::

```{.r .cell-code}
lines(FevChildren$height, y_hat, type = "p", col = "lightcoral")
abline(lm_fev_vs_height, col = "lightcoral")
legend(x = "topleft", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c("cornflowerblue", "lightcoral", "lightcoral"), legend=c("Data", "Predicted", "Fitted line"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-23-1.png){width=672}
:::
:::


Det enda argumentet ni inte har st칬tt p친 tidigare 칛r `pch = c(1, 1, NA)` som anger att de tv친 f칬rsta ska vara cirkelsymboler i legendtexten och anger ingen cirkelsymbol f칬r den sista. Argumentet `lty = c(NA, NA, 1)` anger en linje f칬r den sista men ingen linje f칬r de tv친 f칬rsta.

Antag att vi vill prediktera genomsnittliga forcerade utandningsvolymen f칬r l칛ngder som inte finns med bland de 606 observationerna, exempelvis $x=150$ och $x=160$. Vi kan anv칛nda `predict()` funktionens argument `newdata` som 칛r en dataframe med samma variabelnamn som vi anv칛nde n칛r vi anpassade modellen (`height`) i v친rt fall. F칬ljande kod skapar dataframen i en variabel vi v칛ljer att kalla `new_x` och predikterar de genomsnittliga forcerade utandningsvolymerna f칬r de nya $x$ v칛rden ovan.


::: {.cell}

```{.r .cell-code}
new_x <- data.frame(height = c(160, 170))
predict(lm_fev_vs_height, newdata = new_x)
```

::: {.cell-output .cell-output-stdout}
```
       1        2 
2.867951 3.406038 
```
:::
:::


Exempelvis ser vi att ett barn (eller en ungdom) p친 170 cm har i genomsnitt ett `fev`-v칛rde p친 ca 3.4.

#### 游눩 Uppgift 2.1

Prediktera responsen f칬r $x=180$ och $x=190$. Tolka resultaten.


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


F칬r att kolla modellens rimlighet kan vi g칬ra en residualanalys. F칬ljande tre kriterier 칛r viktiga:

-   Residualerna ska bete sig slumpm칛ssigt, dvs de ska inte uppvisa ett m칬nster.

-   Residualernas varians ska vara konstant, dvs inte bero p친 $x$.

-   Residualerna ska vara approximativt normalf칬rdelade.

De tv친 senare kriterierna blir viktiga n칛r vi g칬r inferens i regressionsmodellen (Del 2) av kursen. N칛r f칬rsta kriterier inte 칛r uppfyllt betyder det ofta att sambandet i data 칛r icke-linj칛rt.

Residualerna kan f친s genom funktionen `residuals()`:


::: {.cell}

```{.r .cell-code}
resid <- residuals(lm_fev_vs_height)
head(resid)
```

::: {.cell-output .cell-output-stdout}
```
          1           2           3           4           5           6 
-0.34098108 -1.76006091  0.01270459  0.05571600 -0.15398108 -0.25967816 
```
:::
:::


F칬ljande kod g칬r residualanalysen.


::: {.cell}

```{.r .cell-code}
plot(FevChildren$height, resid, xlab= "height", ylab='Residuals', col = "cornflowerblue") 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-27-1.png){width=672}
:::

```{.r .cell-code}
qqnorm(resid, col = "cornflowerblue") # Create normal probability plot for residuals
qqline(resid, col = "red") # Add a straight line to normal probability plot 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-27-2.png){width=672}
:::
:::


F칬rsta plotten visar att residualerna inte ter sig slumpm칛ssigt --- de visar ett, om 칛n svagt, kvadratiskt samband. Plotten visar ocks친 en tydlig indikation p친 att residualernas varians inte 칛r konstant, eftersom de varierar mer ju st칬rre `height` blir.

Dessa resultat 칛r inte 칬verraskande om vi noga betraktar punktdiagrammet `fev` mot `height` igen samt den anpasssade linjen.


::: {.cell}

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue")
abline(lm_fev_vs_height, col = "lightcoral")
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-28-1.png){width=672}
:::
:::


Residualerna ber칛knas som avst친ndet mellan observationerna och dess predikterade v칛rden (som ligger p친 linjen). St칬rre avvikelser f칬rekommer f칬r st칬rre v칛rden p친 `height` j칛mf칬rt med mindre v칛rden, d칛rav en h칬gre residualvarians. Data verkar inte heller f칬lja den r칛ta linjen eftersom en liten grad av icke-linjaritet verkar finnas. I Avsnitt 3 g친r vi i igenom hur vi kan anpassa en icke-linj칛r regression f칬r att f친 b칛ttre resultat.

#### 游눩 Uppgift 2.2

Exemplet ovan visar hur man anpassar en enkel linj칛r regression, tolkar resultaten, predikterar responsen f칬r nya $x$ v칛rden och slutligen hur man validerar modellen. G칬r en regressionsanalys med responsvariabel `IBM` och f칬rklarande variabel `MARKET` i `CAPM_data.RData` som inkluderar dessa steg. F칬r prediktion, antag att vi vill f칬rutsp친 vad som h칛nder med IBM aktien om det sker en b칬rskrasch och marknadsportf칬ljen faller med 15% under en m친nad. Vad kan man f칬ruts칛ga om IBM aktiens m친nadsavkastning i ett s친dant scenario?


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


## 3. Enkel icke-linj칛r regression

I Avsnitt 2 s친g vi att regressionslinjen $$\widehat{fev} = b_0 + b_1height$$ inte var tillr칛cklig. Vi kan anv칛nda icke-linj칛r regression f칬r att f친 en b칛ttre anpassning till data. Icke-linj칛r regression transformerar data s친 att sambandet blir linj칛rt efter att transformering. Tranformationerna syfte 칛r allts친 att "r칛ta ut" data och vi kan visuellt inspektera om s친 칛r fallet. Ett annat syfte med transformationer 칛r att de ibland g칬r antagandet om konstant residualvarians mer troligt, vilket ocks친 kan studeras visuellt.

Vi anv칛nder oss av den s친 kallade **ladder of powers** (stege av potenstransformationer) f칬r att "r칛ta ut" data med hj칛lp av potenstransformationer. Stegen av potenstransformationer visas nedan.

| Stegniv친 |     $y$     |     $x$     |
|:---------|:-----------:|:-----------:|
| 1        |    $y^2$    |    $x^2$    |
| 2        |     $y$     |     $x$     |
| 3        |  $y^{1/2}$  |  $x^{1/2}$  |
| 4        |  $\log(y)$  |  $\log(x)$  |
| 5        | $-y^{-1/2}$ | $-x^{-1/2}$ |
| 6        |  $-y^{-1}$  |  $-x^{-1}$  |

: Potenstransformationer f칬r $y$ och $x$.

Tukeys cirkel 칛r en tumregel f칬r hur vi flyttar oss upp och ner i stegen.

![Tukeys cirkel.](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/Tukeys_circle_MV.png?raw=true){fig-align="center" width="333"}

Vi b칬rjar med att b친de $y$ och $x$ befinner sig p친 stegniv친 2 och flyttar sig sedan upp친t eller ned친t beroende p친 var i Tukeys cirkel vi befinner oss. Plotten `fev` mot `height` indikerar att vi befinner oss i fj칛rde kvadranten i Tukeys cirkel. Vi ska allts친 g친 ner i stegen f칬r $y$ och/eller upp i stegen f칬r $x$ tills f칬rh친llandet ser mer linj칛rt ut. Och/eller h칛r betyder att man "flyttar b친da"/"flyttar enbart en". Notera ocks친 att en av variablerna kan stanna i stegen medan man flyttar den andra upp친t eller ned친t fler 칛n ett steg.


::: {.cell}

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue")  # Starting point: Both y and x  untransformed (Step 2 in the ladder of powers) 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-30-1.png){width=672}
:::

```{.r .cell-code}
plot(sqrt(fev) ~ height, data = FevChildren, col = "cornflowerblue") # y down in the ladder of powers
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-30-2.png){width=672}
:::

```{.r .cell-code}
plot(fev ~ I(height^2), data = FevChildren, col = "cornflowerblue") # x up in the ladder of powers
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-30-3.png){width=672}
:::

```{.r .cell-code}
plot(sqrt(fev) ~ I(height^2), data = FevChildren, col = "cornflowerblue") # y down and x up in the ladder of powers
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-30-4.png){width=672}
:::

```{.r .cell-code}
plot(log(fev) ~ I(height), data = FevChildren, col = "cornflowerblue") # y down two steps
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-30-5.png){width=672}
:::
:::


Vi kommenterar den mystiska funktionen `I()` som dyker upp i h칬gerledet p친 formula-syntaxen `y ~ I(x^2)` i rutan nedan. Man kan hoppa 칬ver rutan, det enda viktiga 칛r att veta att **funktionen `I()` beh칬ver anv칛ndas i h칬gerledet av formula-syntax om man vill transformera `x` f칬r att inga misstolkningar ska ske.**

::: {.callout-note icon="false"}
## Extra f칬rklaring f칬r de nyfikna studenterna (detta avsnitt kan skippas)

Formula-syntaxen till친ter att man applicerar en transformation i v칛nsterledet utan att anv칛nda `I()`, dvs vi kan skriva till exempel `sqrt(y) ~ x` ist칛llet f칬r `I(sqrt(y)) ~ x`. Detsamma g칛ller inte h칬gerledet eftersom i formula-syntax s친 har vissa operationer en annan betydelse n칛r de utf칬rs p친 den f칬rklarande variabeln. Till exempel anpassar `lm(y ~ x*z)` en linj칛r regression med s친 kallade interakationseffekter[^1] mellan de f칬rklarande variablerna $x$ och $z$, vilket har formen $$\hat{y} = b_0 + b_1x + b_2 z  + b_3xz.$$ N칛r man anv칛nder funktionen `I()` i h칬gerledet undg친r man att formula-syntax tolkar fel.
:::

[^1]: Interaktionseffekter g친s igenom i Statistisk och Dataanalys II.

Vi skulle kunna utv칛rdera vilken av transformationerna 칛r att f칬redra med korsvalidering (se Avsnitt 5). H칛r n칬jer vi oss med en utv칛rdering baserad p친 grafernas utseende. Vi ser att alla transformationerna resulterar i ett mer linj칛rt f칬rh친llande j칛mf칬rt med ursprungsdatan (innan transformationerna). Visuellt konstaterar vi att de tv친 sista transformationerna verkar r칛tar ut data b칛st. Vi v칛ljer den sista transformationen eftersom den verkar uppn친 en j칛mnare spridning runt linjen, vilket kommer resultera i residualer med en mer konstant varians.

Den anpassade linjen har formen $$\widehat{\log(fev)} = b_0 + b_1height,$$ d칛r vi snart ska anv칛nda `lm()` f칬r att ber칛kna koefficienterna $b_0$ och $b_1$. Men f칬rst en viktig varning.

::: callout-warning
I linj칛r regression tolkade vi $b_1$ som f칬r칛ndringen i responsvariablen $y$ som 칛r associerad med en en-enhets f칬r칛ndring i den f칬rklarande variabeln $x$.

N칛r man transformerar $x$ s친 finns det inga enkla tolkningar av $b_1$, oavsett om $y$ 칛r transformerad eller inte!

N칛r man enbart transformerar $y$ men inte $x$ 칛r tolkningen i den transformerade skalan. I v친rt exempel 칛r $b_1$ den f칬r칛ndringen i $\log(y)$ som 칛r associerad med en en-enhets f칬r칛ndring i den f칬rklarande variabeln $x$. Man kan ibland, beroende p친 transformationen av $y$, anv칛nda $b_1$ f칬r att f친 en enkel tolkning 칛ven i den originala skalan. Vi g친r inte igenom s친dana tolkningar av $b_1$ f칬r icke-linj칛r regression i den h칛r kursen[^2].
:::

[^2]: Statistik och Dataanalys II g친r igenom ett par icke-linj칛ra modeller som 칛r tolkningsbara. Den kommande nya kursen Generaliserade Linj칛ra Modeller som l칛ses efter Statistik och Datanalys III g친r igenom m친nga fler tolkningsbara icke-linj칛ra modeller.

츿r det ens v칛rt att anpassa en modell d칛r koefficienterna inte g친r att tolka p친 ett enkelt s칛tt? Om m친let med modellen 칛r att prediktera b칛ttre (j칛mf칬rt med en linj칛r regression) s친 칛r svaret definitivt ja[^3].

[^3]: Ett modernt exempel p친 modeller som saknar tolkning men 칛r extremt bra p친 prediktera 칛r djupa neurala n칛tverk (deep learning). Ni f친r l칛ra er om dessa i v친r kurs Maskininl칛rning p친 masterniv친.

Precis som i Avsnitt 2 kan vi anv칛nda minsta kvadratmetoden (genom `lm()`) f칬r att anpassa modellen p친 de transformerade data. N칛r vi anv칛nder prediktion m친ste vi t칛nka p친 att vi har transformerat variablerna. I det h칛r specifika exemplet med tranformationen `log(fev)` kommer funktionen `predict()` att prediktera den genomsnittliga $\log(fev)$ niv친n. Vi vill prediktera i originalskala, dvs responsvariabeln $y$ (`fev`) och inte $\log(y)$ (`log(fev)`). Men vi kan anv칛nda prediktionen f칬r $\log(y)$ och "reversera transformationen", dvs f친 transformationen ogjord, f칬r att ber칛kna prediktionen f칬r $y$. En funktion som reverserar en transformation kallas f칬r en inverstransformation. Tabellen nedan anger inversetransformationerna (kolumnen till h칬ger) vi kan anv칛nda oss av n칛r vi predikterar i originalskala. Transformationerna motsvarar de i ladder of powers.

| Transformation av responsen | Prediktion i $y$-skala ($\widehat{y}$) |
|:---------------------------:|:--------------------------------------:|
|            $y^2$            |   $\left(\widehat{y^2}\right)^{1/2}$   |
|             $y$             |             $\widehat{y}$              |
|          $y^{1/2}$          |   $\left(\widehat{y^{1/2}}\right)^2$   |
|          $\log(y)$          |  $\exp\left(\widehat{\log(y)}\right)$  |
|         $-y^{-1/2}$         |  $\left(\widehat{-y^{-1/2}}\right)^2$  |
|          $-y^{-1}$          | $-\left(\widehat{-y^{-1}}\right)^{-1}$ |

: Prediktion i originalskala (kolumn till h칬ger) f칬r olika transformerade responser (kolumn till v칛nster).

::: {.callout-note icon="false"}
## Extra f칬rklaring f칬r de nyfikna studenterna (detta avsnitt kan skippas)

L친t transformationen av $y$ betecknas $\tilde{y}$. Vi kan h칛rleda den inversa transformationen genom att l칬sa f칬r $y$ i ekvationen $\tilde{y}=g(y)$ d칛r $g()$ 칛r transformationen.

L친t oss h칛rleda den inversa transformationen av log-transformationen. Eftersom $\tilde{y}=\log(y)$ s친 칛r $$\exp\left( \tilde{y} \right) = \exp(\log(y)) \implies y = \exp\left( \tilde{y} \right),$$ dvs exponential-funktionen 칛r den inversa transformen.

Notera att n칛r vi predikterar $y$ (responsen i originalskala) s친 sker det i tv친 steg. I det f칬rsta steget anv칛nder vi regressionen f칬r att prediktera $\tilde{y}$ (responsen i transformed skala, log-skala i exemplet ovan), vilket ger prediktionen $\widehat{\tilde{y}}$ ($\widehat{\log(y)}$ i exemplet ovan). I andra steget applicerar vi den inversa transformen ($\exp()$ f칬r log-transformationen) p친 $\widehat{\tilde{y}}$ f칬r att f친 $\widehat{y}$ ($\exp\left(\widehat{\log(y)}\right)$ i exemplet ovan) som 칛r prediktionen av $y$ (originalskala).

#### 游눩 Extra Uppgift 4

H칛rled alla de 칬vriga (eller s친 m친nga du orkar) inversa transformationerna i tabellen ovan.
:::

Vi 칛r nu redo att anpassa den nya regressionen $$\widehat{\log(fev)} = b_0 + b_1height,$$ samt prediktera och genomf칬ra en residualanalys.


::: {.cell}

```{.r .cell-code}
lm_logfev_vs_height <- lm(log(fev) ~ height, data = FevChildren)
summary(lm_logfev_vs_height)
```

::: {.cell-output .cell-output-stdout}
```

Call:
lm(formula = log(fev) ~ height, data = FevChildren)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.69706 -0.09037  0.01058  0.08988  0.43795 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -2.2227934  0.0717623  -30.97   <2e-16 ***
height       0.0202071  0.0004561   44.31   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.1476 on 604 degrees of freedom
Multiple R-squared:  0.7647,	Adjusted R-squared:  0.7643 
F-statistic:  1963 on 1 and 604 DF,  p-value: < 2.2e-16
```
:::
:::


Minsta kvadratskattningarna 칛r nu $b_0=-2.222$ och $b_1=0.020$. $R^2=0.76145$ betyder att ca 76% av variationen i `log(fev)` (observera log i tolkningen!) f칬rklaras av `height`.


::: {.cell}

```{.r .cell-code}
logy_hat <- predict(lm_logfev_vs_height) # log scale prediction
y_hat <- exp(logy_hat) # original scale prediction
head(logy_hat)
```

::: {.cell-output .cell-output-stdout}
```
        1         2         3         4         5         6 
0.7027882 1.2417111 0.5744732 0.4974842 0.7027882 0.9080922 
```
:::

```{.r .cell-code}
head(y_hat)
```

::: {.cell-output .cell-output-stdout}
```
       1        2        3        4        5        6 
2.019375 3.461531 1.776195 1.644579 2.019375 2.479587 
```
:::

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue", ylim = c(0, 7)) # Data on original scale
lines(FevChildren$height, y_hat, type = "p", col = "lightcoral")
legend(x = "topleft", pch = c(1, 1), col = c("cornflowerblue", "lightcoral"), legend=c("Data", "Predicted"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-32-1.png){width=672}
:::
:::


Notera att till skillnad fr친n n칛r vi anpassade `fev ~ height` s친 anv칛nder vi h칛r inte `abline()` (som ritar en r칛t linje), eftersom regressionen 칛r icke-linj칛r. Vi n칬jer oss med att markera ut de enskilda prediktionsv칛rden, men se rutan nedanf칬r p친 hur man kan g칬ra om man vill rita en kurva.

::: {.callout-note icon="false"}
## Extra: Rita den anpassade kurvan i icke-linj칛r regression

Notera att eftersom observationerna inte ligger i ordning f칬r $x$ variabeln s친 kan vi inte binda ihop de r칬da punkterna ovan med en linje. Det ser konstigt ut som f칬ljande figur visar:


::: {.cell}

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue", ylim = c(0, 7), main = "Strange looking plot") # Data on original scale
lines(FevChildren$height, y_hat, type = "p", col = "lightcoral") # Prediction of data points
lines(FevChildren$height, y_hat, type = "l", col = "lightcoral") # line
legend(x = "topleft", pch = c(1, 1), col = c("cornflowerblue", "lightcoral"), legend=c("Data", "Predicted"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-33-1.png){width=672}
:::
:::


Man skulle kunna sortera datasetet i stigande ordning p친 height och sedan binda ihop varje punkt med en linje. Men om punkterna ligger med en bit avst친nd i $x$-led s친 칛r inte det h칛r en bra l칬sning, eftersom det dras en r칛t linje mellan punkterna och kurvan vi plottar 칛r inte r칛t. En b칛ttre l칬sning 칛r att skapa ett rutn칛t (grid p친 engelska) med m친nga punkter i $x$-led och sedan prediktera f칬r varje punkt i rutn칛tet. Ett rutn칛t 칛r en indelning av ett intervall $[a,b]$ i $N$ punkter med lika stort avst친nd mellan varandra. Anropet `seq(a, b, length.out = N)` skapar ett rutn칛t.


::: {.cell}

```{.r .cell-code}
grid <- seq(0.1, 1, length.out = 10) # a = 0.1, b = 1 and N = 10.
grid
```

::: {.cell-output .cell-output-stdout}
```
 [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
```
:::
:::


Vi kan nu skapa en dataframe som inneh친ller ett rutn칛t mellan det minsta $x$-v칛rdet och det st칬rsta $x$-v칛rdet med s칛g $N=1000$ punkter och prediktera responsen f칬r dessa 1000 $x$-v칛rden. Funktionen 'lines()' kommer att binda ihop dessa punkter med r칛ta linjer emellan --- men punkterna ligger s친 t칛tt att v친ra 칬gon kommer uppfatta resultatet som en fin och j칛mn kurva. F칬ljande kod anpassar kurvan p친 s칛ttet som beskrivits ovan och plottar den tillsammans med data och de enskilda prediktionerna vi skapade ovan.


::: {.cell}

```{.r .cell-code}
plot(fev ~ height, data = FevChildren, col = "cornflowerblue", ylim = c(0, 7)) # Data on original scale
x_min <- min(FevChildren$height) # Min height
x_max <- max(FevChildren$height) # Max height
N <- 1000 # Number of grid points to predict
new_x <- data.frame(height = seq(x_min, x_max, length.out = N)) # The grid in a dataframe
logy_hat_grid <- predict(lm_logfev_vs_height, newdata = new_x)
yhat_grid <- exp(logy_hat_grid) # Inverse transform
lines(FevChildren$height, y_hat, type = "p", col = "lightcoral") # Prediction of data points
lines(new_x$height, yhat_grid, type = "l", col = "lightcoral") # Prediction on grid
legend(x = "topleft", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c("cornflowerblue", "lightcoral", "lightcoral"), legend=c("Data", "Predicted", "Fitted curve"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-35-1.png){width=672}
:::
:::

:::

#### 游눩 Uppgift 3.1

Prediktera responsen f칬r $x=180$ och $x=190$ med den icke-linj칛ra regressionen. J칛mf칬r resultaten med den linj칛ra regressionen i Uppgift 2.1.


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


Slutligen g칬r vi en residualanalys.


::: {.cell}

```{.r .cell-code}
resid_logfev <- residuals(lm_logfev_vs_height)
head(resid_logfev)
```

::: {.cell-output .cell-output-stdout}
```
          1           2           3           4           5           6 
-0.16746509 -0.69706393 -0.03214892 -0.05408127 -0.06356935 -0.05965209 
```
:::

```{.r .cell-code}
plot(FevChildren$height, resid_logfev, xlab= "height", ylab='Residuals', col = "cornflowerblue") 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-37-1.png){width=672}
:::

```{.r .cell-code}
qqnorm(resid_logfev, col = "cornflowerblue") # Create normal probability plot for residuals
qqline(resid_logfev, col = "red") # Add a straight line to normal plot 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-37-2.png){width=672}
:::
:::


#### 游눩 Uppgift 3.2

Kommentera residualanalysen f칬r den nya modellen. J칛mf칬r resultaten mot residualanalysen f칬r den otransformerade responsen (dvs `fev ~ height`). Vilken modell 칛r att f칬redra?

#### 游눩 Uppgift 3.3

Anpassa modellen $$\widehat{fev^{1/2}} = b_0 + b_1height.$$ och utf칬r en liknande analys som f칬r modellen ovan, dvs $$\widehat{\log(fev)} = b_0 + b_1height.$$ Vilken utav dessa 칛r mest l칛mplig f칬r det h칛r exemplet?


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


## 4. Multipel linj칛r samt icke-linj칛r regression

En multipel linj칛r regression till친ter fler f칬rklarande variabler. Att implementera multipel linj칛r regression i R kr칛ver inte mycket mer kunskap 칛n det vi har g친tt igenom ovan.

Vi analyserar 친terigen `FevChildren.RData` och inkluderar nu ocks친 `smoking` (som 칛r en dummy-variabel) f칬r att f칬rklara `fev`, dvs $$\widehat{fev}=b_0 + b_1height + b_2smoking$$


::: {.cell}

```{.r .cell-code}
lm_fev_vs_height_smoking <- lm(fev ~ height + smoking, data = FevChildren)
summary(lm_fev_vs_height_smoking)
```

::: {.cell-output .cell-output-stdout}
```

Call:
lm(formula = fev ~ height + smoking, data = FevChildren)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.76487 -0.25513  0.00027  0.23445  2.09853 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -5.763158   0.216872 -26.574   <2e-16 ***
height       0.053963   0.001388  38.865   <2e-16 ***
smoking1    -0.025260   0.060666  -0.416    0.677    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.433 on 603 degrees of freedom
Multiple R-squared:  0.7285,	Adjusted R-squared:  0.7276 
F-statistic: 808.9 on 2 and 603 DF,  p-value: < 2.2e-16
```
:::
:::


Fr친n utskriften kan vi utl칛sa att $b_0 = -5.763$, $b_1 = 0.054$ och $b_2=-0.025$. Vidare kan vi utl칛sa att ca 73 av variationen i `fev` f칬rklaras av `height` och `smoking` Notera att R har kallat variabeln `smoking1` ist칛llet f칬r `smoking` f칬r att betona att $b_2$ 칛r effekten av gruppen som r칬ker (vi kodade r칬kning som 1). I en multipel regression s친 tolkar vi alltid de skattade effektena av en variabel givet att alla andra variablerna h친lls konstanta. Till exempel, givet barn och ungdomar av samma l칛ngd s친 칛r $b_2$ f칬r칛ndringen (h칛r negativt d친 $b_2 < 0$) i `fev` mellan r칬kare och inte r칬kare. Dvs, givet att l칛ngden 칛r densamma, s친 tenderar r칬kare att ha mindre forcerad utandningsvolym j칛mf칬rt med icke-r칬kare. Koefficienten $b_1$ tolkas givet att smoking h친lls konstant, dvs barn och ungdomar som 칛r 1 cm l칛ngre tenderar att i genomsnitt ha $b_1=0.054$ fler enheter forcerad utandningsvolym (칛n de som 칛r 1 cm kortare) givet att de tillh칬r samma grupp (antingen r칬kare eller icke-r칬kare).

I multipel regression 칛r det vanligt att plotta residualerna mot de predikterade v칛rdena, snarare 칛n mot varje f칬rklarande variabel. Detta beror p친 att man potentiellt kan ha m친nga f칬rklarande variabler och d친 칛r det mer praktiskt att ist칛llet g칬ra residualanalysen utifr친n en enda figur.


::: {.cell}

```{.r .cell-code}
resid_fev_multiplereg <- residuals(lm_fev_vs_height_smoking)
head(resid_fev_multiplereg)
```

::: {.cell-output .cell-output-stdout}
```
          1           2           3           4           5           6 
-0.34166549 -1.76486977  0.01300219  0.05660280 -0.15466549 -0.26193379 
```
:::

```{.r .cell-code}
plot(lm_fev_vs_height_smoking$fitted.values, resid_fev_multiplereg, xlab= "y_hat", ylab='Residuals', col = "cornflowerblue") 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-40-1.png){width=672}
:::

```{.r .cell-code}
qqnorm(resid_fev_multiplereg, col = "cornflowerblue") # Create normal probability plot for residuals
qqline(resid_fev_multiplereg, col = "red") # Add a straight line to normal 
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-40-2.png){width=672}
:::
:::


Vi ser liknande problem med residualplottarna som i Avsnitt 2.

Antag att vi vill prediktera den genomsnittliga forcerade utandningsvolymen f칬r barn och ungdomar som 칛r 164.5 cm l친nga och r칬ker. Eftersom `smoking` 칛r en s친kallad `factor` variabel (Rs s칛tt att koda kategoriska variabler) beh칬ver vi anv칛nda `as.factor()` funktionen n칛r vi skapar `new_x`.


::: {.cell}

```{.r .cell-code}
new_x <- data.frame(height = 164.5, smoking = as.factor(1))
predict(lm_fev_vs_height_smoking, newdata = new_x)
```

::: {.cell-output .cell-output-stdout}
```
       1 
3.088564 
```
:::
:::


V친r prediktion 칛r att den genomsnittliga forcerade utandningsvolymen 칛r 3.088 f칬r r칬kande barn och ungdomar som 칛r $164.5$ cm l친nga.

#### 游눩 Uppgift 4.1

Anpassa modellen $$\widehat{\log(fev)}=b_0 + b_1height + b_2smoking.$$ Tolka koefficienterna och utf칬r en residualanalys samt g칬r en prediktion enligt ovan. Ser resultaten b칛ttre ut?


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


#### 游눩 Uppgift 4.2

Filen `real_estate.RData` inneh친ller f칬rs칛ljningspriser `SalesPrice` samt f칬rklarande variabler f칬r 521 s친lda objekt. En m칛klarfirma anlitar er som statistiker med f칬ljande uppdrag.

M칛klarfirman vill att ni utvecklar en prognosmodell f칬r f칬rs칛ljningspriset. F칬r enkelhets skull ska ni anpassa en multipel linj칛r regression (dvs inga transformationer!) med f칬ljande f칬rklarande variabler:

-   `SqFeet`: Area i kvadratfot (enhet 1000 sqft).
-   `Lot`: Tomtarea i kvadratfot (enhet 1000 sqft).
-   `Air`: Dummy-variabel som anger om objektet har luftkonditionering (1 kodat som ja, 0 kodat som nej).

M칛klarfirman undrar f칬ljande utifr친n den multipla linj칛ra regressionen:

-   Vad kan man s칛ga om sambandet mellan `SqFeet` och f칬rs칛ljningspriset?
-   Vad kan man s칛ga om sambandet mellan `Lot` och f칬rs칛ljningspriset?
-   Verkar det finnas n친got samband f칬rs칛ljningspriset och `Air`? Hur ska sambandet tolkas?
-   En visning 칛ger rum snart f칬r en l칛genhet som har en area p친 2.311 kvadratfot, en tomtarea p친 17.312 kvadratfot och luftkonditionering. Vad kan den s칛ljas f칬r? Kommunicera er prediktion med en tydlig tolkning.\
-   Har er modell n친gra brister?


::: {.cell}

```{.r .cell-code}
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/RealEstate.RData?raw=true"))
# Write your code here
```
:::


## 5. Modellval genom Korsvalidering

I det h칛r avsnittet ska vi g친 igenom hur man v칛ljer en modell med hj칛lp av korsvalidering.

Datasetet `Penguins.RData` inneh친ller dykpuls (DHR) (`dive_heart_rate`) och tid f칬r dykning (`duration`) f칬r 125 pingviner. Vi vill modellera dykpulsen f칬r en pingvin som en funktion av tiden f칬r dykningen. Ett punktdiagram visar att en linj칛r regression inte kommer att anpassa data v칛l.


::: {.cell}

```{.r .cell-code}
load(file = url("https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/Penguins.RData?raw=true"))
plot(dive_heart_rate ~ duration, data = penguins, col = "cornflowerblue")
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-44-1.png){width=672}
:::
:::


Vi befinner oss i tredje kvadranten p친 Tukeys cirkel och f칬resl친r f칬ljande tv친 modeller

-   **Modell 1**: $\widehat{DHR^{1/2}} = b_0 + b_1duration$.

-   **Modell 2**: $\widehat{DHR^{1/2}} = b_0 + b_1duration^{1/2}$.

Vi anpassar Modell 1 och plottar de predikterade v칛rdena tillsammans med data i originalskala som vi gjorde i Avsnitt 3. Skillnaden 칛r att n칛r vi predikterar p친 originalskala s친 anv칛nder vi en annan inverstransformation, $\left(\widehat{y^{1/2}}\right)^2$ enligt tabellen ovan.


::: {.cell}

```{.r .cell-code}
lm_sqrtDHR_vs_duration <- lm(sqrt(dive_heart_rate) ~ duration, data = penguins)
sqrty_hat <- predict(lm_sqrtDHR_vs_duration) # sqrt scale prediction
y_hat <- sqrty_hat^2 # original scale prediction
plot(dive_heart_rate ~ duration, data = penguins, col = "cornflowerblue", ylim = c(0, 140), main = "Model 1") # Data on original scale
lines(penguins$duration, y_hat, type = "p", col = "lightcoral")
legend(x = "topright", pch = c(1, 1), col = c("cornflowerblue", "lightcoral"), legend=c("Data", "Predicted"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-45-1.png){width=672}
:::
:::


::: {.callout-note icon="false"}
## Extra: Rita den anpassade kurvan

I Avsnitt 3 l칛rde vi oss (extra-rutan) hur man ritar in den anpassade kurvan. Vi kan g칬ra samma sak f칬r Modell 1.


::: {.cell}

```{.r .cell-code}
plot(dive_heart_rate ~ duration, data = penguins, col = "cornflowerblue", ylim = c(0, 140), main = "Model 1") # Data on original scale
x_min <- min(penguins$duration) # Min duration 
x_max <- max(penguins$duration) # Max duration
N <- 1000 # Number of grid points to predict
new_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe
sqrty_hat_grid <- predict(lm_sqrtDHR_vs_duration, newdata = new_x)
yhat_grid <- sqrty_hat_grid^2 # Inverse transform
lines(penguins$duration, y_hat, type = "p", col = "lightcoral") # Prediction of data points
lines(new_x$duration, yhat_grid, type = "l", col = "lightcoral") # Prediction on grid
legend(x = "topright", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c("cornflowerblue", "lightcoral", "lightcoral"), legend=c("Data", "Predicted", "Fitted curve"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-46-1.png){width=672}
:::
:::

:::

Vi anpassar Modell 2 med f칬ljande kod. Notera att Modell 2 ocks친 transformerar den f칬rklarande variabeln. R h친ller reda p친 det 친t oss om vi anger `I(sqrt(duration))` i formula-syntaxen och vi beh칬ver inte g칬ra n친got extra.


::: {.cell}

```{.r .cell-code}
lm_sqrtDHR_vs_sqrtduration <- lm(sqrt(dive_heart_rate) ~ I(sqrt(duration)), data = penguins)
sqrty_hat <- predict(lm_sqrtDHR_vs_sqrtduration) # sqrt scale prediction
y_hat <- sqrty_hat^2 # original scale prediction
plot(dive_heart_rate ~ duration, data = penguins, col = "cornflowerblue", ylim = c(0, 140), main ="Model 2") # Data on original scale
lines(penguins$duration, y_hat, type = "p", col = "lightcoral")
legend(x = "topright", pch = c(1, 1), col = c("cornflowerblue", "lightcoral"), legend=c("Data", "Predicted"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-47-1.png){width=672}
:::
:::


::: {.callout-note icon="false"}
## Extra: Rita den anpassade kurvan

Kod som ocks친 ritar den anpassade kurvan f칬r Modell 2.


::: {.cell}

```{.r .cell-code}
plot(dive_heart_rate ~ duration, data = penguins, col = "cornflowerblue", ylim = c(0, 140), main = "Model 2") # Data on original scale
x_min <- min(penguins$duration) # Min duration 
x_max <- max(penguins$duration) # Max duration
N <- 1000 # Number of grid points to predict
new_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe
sqrty_hat_grid <- predict(lm_sqrtDHR_vs_sqrtduration, newdata = new_x)
yhat_grid <- sqrty_hat_grid^2 # Inverse transform
lines(penguins$duration, y_hat, type = "p", col = "lightcoral") # Prediction of data points
lines(new_x$duration, yhat_grid, type = "l", col = "lightcoral") # Prediction on grid
legend(x = "topright", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c("cornflowerblue", "lightcoral", "lightcoral"), legend=c("Data", "Predicted", "Fitted curve"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-48-1.png){width=672}
:::
:::

:::

Vi ska nu v칛lja vilken av Modell 1 eller Modell 2 칛r att f칬redra med hj칛lp av korsvalidering. P친 f칬rel칛sningen gick vi genom korsvalidering med $K = 4$ folds. H칛r har vi 125 pingviner som 칛r j칛mnt delbart med 5, s친 vi anv칛nder $K = 5$ folds ist칛llet. Vi f친r d친 80% tr칛ningsdata och 20% testdata f칬r varje fold enligt figuren nedan.

![Korsvalidering med $K=5$ folds.](https://github.com/StatisticsSU/SDA1/blob/main/datorlab/lab4/Crossvalidation_5fold.png?raw=true){fig-align="center" width="500"}

F칬r varje modell beh칬ver vi anropa funktionen `lm()` $K=5$ g친nger med olika tr칛ningsdata enligt uppdelningen ovan. Funktionen `lm()` har ett argument `subset` som best칛mmer vilka observationer (pingviner) som ska anv칛ndes f칬r att anpassa modellen, dvs tr칛ningsdata. N칛r `lm()` har anpassats till fold $k$ anv칛nder vi funktionen `predict()` f칬r att prediktera testdatan f칬r fold $k$ och r칛kna ut dess residualkvadratsumma (SSE, sum of squared errors). Koden nedan demonstrerar proceduren f칬r f칬rsta folden, dvs $k=1$, och f칬rklaras lite mer detaljerad efter kodsnutten.


::: {.cell}

```{.r .cell-code}
n <- 125 # Number of observations
# Fold 1:
obs_index <- c(1:n) # Keeps track of the indices of  the dataset (1, 2, 3, ...., n = 125)
test_fold_index <- obs_index[c(1:25)] # Subsets indices 1:25 (test data fold 1) 
training_fold_index <- obs_index[-c(1:25)] # Takes out the complement
lm_modell1_fold1 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 1
test_data <- penguins[test_fold_index, ] # Create test data for fold
sqrty_hat_fold1 <- predict(lm_modell1_fold1, newdata = test_data) # Predict test data in sqrt scale
y_hat_fold1 <- (sqrty_hat_fold1)^2 # Predict test data ordinary scale
SSE_fold1 <- sum((test_data$dive_heart_rate - y_hat_fold1)^2) 
```
:::


Notera att datasetet `penguins.RData` redan ligger i slumpm칛ssig ordning och d칛rf칬r kan `obs_index` inneh친lla observationerna i stigande ordning. Ett exempel p친 ett dataset som ligger i ordning (dvs inte slumpm칛ssigt ordning) 칛r `FevChildren.RData` d칛r barnen i den l칛gsta 친ldersgruppen kommer f칬rst, d칛refter mittersta 친ldersgruppen f칬ljt av 칛ldsta 친ldersgruppen (ni kan se det genom att klicka p친 datasetet i Environment-fliken). F칬r ett dataset som ligger i ordning kan man ist칛llet definiera `obs_index <- sample(c(1:n))`. D친 inneh친ller `obs_index` indexen $1, 2, \dots, n$ i slumpm칛ssig ordning.

#### 游눩 Uppgift 5.1

Skriv ut `test_fold_index` och bekr칛fta att den inneh친ller indexen f칬r testdata i fold 1, dvs de f칬rsta 25 observationerna.


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


N칛r vi skapar `training_fold_index` ovan, notera att `-c(1:25)` skapar en vektor med v칛rden $-1, -2, \dots, -25$. N칛r vi skriver `obs_index[-c(1:25)]` f칬rs칬ker vi allts친 plocka ut negativa index ur vektorn `obs_index`! Negativ indexering i R har en speciell betydelse: Ett negativt index h칛mtar ut alla andra observationer f칬rutom den som har ett negerat index (negativt index). F칬r att illustrera detta betrakta f칬ljande exempel:


::: {.cell}

```{.r .cell-code}
my_vector <- c(3, 2, 1, 20, 3)
my_vector[-4]
```

::: {.cell-output .cell-output-stdout}
```
[1] 3 2 1 3
```
:::

```{.r .cell-code}
my_vector[-2]
```

::: {.cell-output .cell-output-stdout}
```
[1]  3  1 20  3
```
:::

```{.r .cell-code}
my_vector[c(-1, -3)]
```

::: {.cell-output .cell-output-stdout}
```
[1]  2 20  3
```
:::
:::


`my_vector[-4]` h칛mtar ut alla observationer f칬rutom den som 칛r p친 index 4. `my_vector[-2]` h칛mtar ut alla observationer f칬rutom den som 칛r p친 index 2. `my_vector[c(-1, -3)]` h칛mtar ut alla observationer f칬rutom de som 칛r p친 index 1 och 3.

#### 游눩 Uppgift 5.2

Vilka observationer h칛mtas ut om man skriver:

-   `my_vector[-1]`?

-   `my_vector[-c(3, 1)]`?

-   `my_vector[-c(1, 2, 4, 5)]`?

Fundera p친 svaret innan ni bekr칛ftar med hj칛lp av kod.


::: {.cell}

```{.r .cell-code}
# Write your code here
```
:::


F칬r att tydligt illustrera vad som h칛nder, l친t oss g칬ra en figur som inneh친ller:

-   Tr칛ningsdata.

-   Testdata.

-   Modellens anpassning (baserat p친 tr칛ningsdata) som inkluderar prediktion av testdata.


::: {.cell}

```{.r .cell-code}
plot(dive_heart_rate ~ duration, subset = training_fold_index,  data = penguins, col = "cornflower blue", ylim = c(0, 140), main = "Crossvalidation Model 1: Fold 1 results") # Training data
lines(penguins$duration[test_fold_index], penguins$dive_heart_rate[test_fold_index], type = "p", col = "lightgreen") # Test data
x_min <- min(penguins$duration) # Min duration 
x_max <- max(penguins$duration) # Max duration
N <- 1000 # Number of grid points to predict
new_x <- data.frame(duration = seq(x_min, x_max, length.out = N)) # The grid in a dataframe
sqrty_hat_grid_fold1 <- predict(lm_modell1_fold1, newdata = new_x)
yhat_grid_fold1 <- sqrty_hat_grid_fold1^2 # Inverse transform
lines(new_x$duration, yhat_grid_fold1, type = "l", col = "lightcoral") # Prediction on grid
legend(x = "topright", pch = c(1, 1, NA), lty = c(NA, NA, 1), col = c("cornflowerblue", "lightgreen", "lightcoral"), legend=c("Training data", "Test data", "Fitted curve"))
```

::: {.cell-output-display}
![](DatorLab4_files/figure-html/unnamed-chunk-53-1.png){width=672}
:::
:::


Variabeln `yhat_grid_fold1` inneh친ller prediktionerna f칬r testdata. En s친dan prediktion ges av kurvans $y$-v칛rde f칬r en gr칬n punkts (testdata) $x$-v칛rde.

#### 游눩 Uppgift 5.3

Identifiera testobservationen som har st칬rst prediktionsfel i plotten ovan.

Ovan har vi grafiskt illustrerat hur korsvalideringsproceduren fungerar inom en given fold i pedagogiskt syfte. Normalt utf칬r man korsvalidering utan en grafisk illustration. F칬ljande kod utf칬r korsvalideringen f칬r fold 2, 3, 4. Den sista folden (fold 5) l칛mnas som en uppgift (se nedan).


::: {.cell}

```{.r .cell-code}
# Fold 2:
test_fold_index <- obs_index[c(26:50)] # Subsets indices 26:50 (test data fold 2) 
training_fold_index <- obs_index[-c(26:50)] # Takes out the complement
lm_modell1_fold2 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 2
test_data <- penguins[test_fold_index, ] # Create test data for fold
sqrty_hat_fold2 <- predict(lm_modell1_fold2, newdata = test_data) # Predict test data in sqrt scale
y_hat_fold2 <- (sqrty_hat_fold2)^2 # Predict test data ordinary scale
SSE_fold2 <- sum((test_data$dive_heart_rate - y_hat_fold2)^2)

# Fold 3:
test_fold_index <- obs_index[c(51:75)] # Subsets indices 51:75 (test data fold 3) 
training_fold_index <- obs_index[-c(51:75)] # Takes out the complement
lm_modell1_fold3 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 3
test_data <- penguins[test_fold_index, ] # Create test data for fold
sqrty_hat_fold3 <- predict(lm_modell1_fold3, newdata = test_data) # Predict test data in sqrt scale
y_hat_fold3 <- (sqrty_hat_fold3)^2 # Predict test data ordinary scale
SSE_fold3 <- sum((test_data$dive_heart_rate - y_hat_fold3)^2)

# Fold 4:
test_fold_index <- obs_index[c(76:100)] # Subsets indices 76:100 (test data fold 4) 
training_fold_index <- obs_index[-c(76:100)] # Takes out the complement
lm_modell1_fold4 <- lm(sqrt(dive_heart_rate) ~ duration, subset = training_fold_index, data = penguins) # Estimate fold 4
test_data <- penguins[test_fold_index, ] # Create test data for fold
sqrty_hat_fold4 <- predict(lm_modell1_fold4, newdata = test_data) # Predict test data in sqrt scale
y_hat_fold4 <- (sqrty_hat_fold4)^2 # Predict test data ordinary scale
SSE_fold4 <- sum((test_data$dive_heart_rate - y_hat_fold4)^2)
```
:::


#### 游눩 Uppgift 5.4

Utf칬r de ber칛kningar som kr칛vs att r칛kna ut SSE f칬r fold 5.


::: {.cell}

```{.r .cell-code}
# Write your code here.
```
:::


Den korsvaliderade root mean squared error (RMSE) ges av $$\mathrm{RMSE}_{\mathrm{cv}} = \sqrt{\frac{1}{n} \sum_{k=1}^K \mathrm{SSE}_k},$$ d칛r $K=5$, $n=125$ (totala antalet observationer) och $\mathrm{SSE}_k$ 칛r SSE f칬r fold $k$.

#### 游눩 Uppgift 5.5

Ber칛kna $\mathrm{RMSE}_{\mathrm{cv}}$ f칬r Modell 1.


::: {.cell}

```{.r .cell-code}
# Write your code here.
```
:::


#### 游눩 Uppgift 5.6

Utf칬r korsvalidering f칬r Modell 2 och ber칛kna dess $\mathrm{RMSE}_{\mathrm{cv}}$. Vilken modell 칛r b칛st?


::: {.cell}

```{.r .cell-code}
# Write your code here.
```
:::


## 6. Sammanfattning {#sammanfattning}

::: callout-info
## I den h칛r laborationen har du l칛rt dig:

-   Korrelation f칬r att beskriva ett linj칛rt samband mellan tv친 numeriska variabler.

-   Hur man tolkar en enkel och multipel linj칛r regression.

-   Hur man anv칛nder R f칬r att anpassa linj칛ra och icke-linj칛ra regressionsmodeller.

-   Hur man anv칛nder R f칬r att prediktera linj칛ra och icke-linj칛ra regressionsmodeller.

-   Hur man validerar en modell via en residualanalys.

-   Hur man v칛ljer modeller med hj칛lp av korsvalidering.
:::

## A. Appendix

Lista 칬ver n친gra vanliga argument i grafer

-   col = f칛rg, kan markeras med siffror eller med namnet p친 f칛rgen, oftast med sm친 bokst칛ver. Gl칬m ej att texten m친ste ligga inom citattecken.

-   main = rubrik p친 plotten, detta s칛tts till en textstr칛ng, allts친 en text inom citattecken.

-   xlab = rubrik p친 x-axeln, detta s칛tts till en textstr칛ng, allts친 en text inom citattecken.

-   ylab = rubrik p친 y-axeln, detta s칛tts till en textstr칛ng, allts친 en text inom citattecken.

-   xlim = definitionsomr친de f칬r x-axeln. Exempelvis betyder xlim = c(0, 14.3) att det l칛gsta v칛rdet som ritas kommer att vara 0 och det h칬gsta v칛rdet kommer att vara 14.3 (p친 x-axeln).

-   ylim = definitionsomr친de f칬r y-axeln. Exempelvis betyder ylim = c(-2, 20.7) att det l칛gsta v칛rdet som ritas kommer att vara -2 och det h칬gsta v칛rdet kommer att vara 20.7 (p친 y-axeln).

-   lwd = tjocklecken p친 linjer (eller prickar) i ett linjediagram (spridningsdiagram), anges med ett nummer.

-   lty = typ av linje (rak, streckad, prickad etc) i ett linjediagram, anges med ett nummer.

-   pch = typ av prick (rund, fyrkantig + \* etc), s칛tts till ett nummer.

-   breaks = antal staplar i ett histogram.

-   cex = justering av etiketternas storlek i en figur (exempelvis cex = 0.5 i en `legend()` funktion minskar storleken som "legend-texten" tar upp i en figur med h칛lften). Finns 칛ven exempelvis cex.axis, cex.main f칬r att justera storleken av texter p친 axlar respektive rubrik.

-   bg = bakgrundsf칛rg i en figur.

-   col.main = rubrikens f칛rg.

-   col.lab = f칛rger f칬r rubrikerna p친 axlarna.

-   font = specificerar vilken typ av text man vill ha, exempelvis ger font = 3 kursiv text.

